[["Map",1,2,9,10],"meta::meta",["Map",3,4,5,6,7,8],"astro-version","5.16.11","content-config-digest","5bf629dcfc603257","astro-config-digest","{\"root\":{},\"srcDir\":{},\"publicDir\":{},\"outDir\":{},\"cacheDir\":{},\"site\":\"https://scripttospeech.com\",\"compressHTML\":true,\"base\":\"/\",\"trailingSlash\":\"ignore\",\"output\":\"static\",\"scopedStyleStrategy\":\"attribute\",\"build\":{\"format\":\"directory\",\"client\":{},\"server\":{},\"assets\":\"_astro\",\"serverEntry\":\"entry.mjs\",\"redirects\":true,\"inlineStylesheets\":\"auto\",\"concurrency\":1},\"server\":{\"open\":false,\"host\":false,\"port\":4321,\"streaming\":true,\"allowedHosts\":[]},\"redirects\":{},\"image\":{\"endpoint\":{\"route\":\"/_image\"},\"service\":{\"entrypoint\":\"astro/assets/services/sharp\",\"config\":{}},\"domains\":[],\"remotePatterns\":[],\"responsiveStyles\":false},\"devToolbar\":{\"enabled\":true},\"markdown\":{\"syntaxHighlight\":{\"type\":\"shiki\",\"excludeLangs\":[\"math\"]},\"shikiConfig\":{\"langs\":[],\"langAlias\":{},\"theme\":\"github-dark\",\"themes\":{},\"wrap\":false,\"transformers\":[]},\"remarkPlugins\":[],\"rehypePlugins\":[],\"remarkRehype\":{},\"gfm\":true,\"smartypants\":true},\"security\":{\"checkOrigin\":true,\"allowedDomains\":[]},\"env\":{\"schema\":{},\"validateSecrets\":false},\"experimental\":{\"clientPrerender\":false,\"contentIntellisense\":false,\"headingIdCompat\":false,\"preserveScriptOrder\":false,\"liveContentCollections\":false,\"csp\":false,\"staticImportMetaEnv\":false,\"chromeDevtoolsWorkspace\":false,\"failOnPrerenderConflict\":false,\"svgo\":false},\"legacy\":{\"collections\":false}}","docs",["Map",11,12,86,87,164,165,304,305,64,440],"guide",{"id":11,"data":13,"body":14,"filePath":15,"digest":16,"rendered":17,"legacyId":85},{},"# Script to Speech GUI User Guide\n\nThe Script to Speech GUI provides a user-friendly interface for generating audiobooks from screenplays. It wraps the powerful CLI tools in a modern, intuitive desktop application.\n\n## Getting Started\n\n### Installation\n\nThe GUI is distributed as a standalone desktop application.\n\n**Building from Source:**\n\nTo build the application yourself, see the [Building for Production](GUI_TECHNICAL.md#building-for-production) section in the technical documentation.\n\n**Locating Built Applications:**\n\nAfter building, you can find the application at:\n- **macOS**: `gui/frontend/src-tauri/target/release/bundle/macos/Script to Speech.app`\n- **macOS Installer**: `gui/frontend/src-tauri/target/release/bundle/dmg/Script to Speech_0.1.0_aarch64.dmg`\n\nSimply double-click the `.app` file or install via the `.dmg` to launch the application.\n\n### Launching the App\n\nUpon opening the application, you will be greeted by the Project Selection screen. Here you can:\n- **Open an existing project**: Select a previous project folder\n- **Create a new project**: Start fresh with a new screenplay.\n\n## Workflow\n\n### 1. Creating a Project & Importing a Screenplay\n\n1. Click **\"New Project\"**.\n2. Use the file picker to select your screenplay PDF or text file.\n3. The application will automatically parse the screenplay and identify characters.\n\n### 2. Configuring API Keys\n\nBefore you can use voice casting or generation features, you must configure your API keys.\n\n1. Click on the **Settings** icon (gear icon).\n2. Enter your API keys for the providers you intend to use (e.g., OpenAI, ElevenLabs).\n3. Keys are stored securely on your local machine.\n\n### 3. Project Overview\n\nThe **Project Overview** tab provides a high-level summary of your current project.\n\n- **Project Status**: Shows the current state (e.g., \"Ready to Generate\") and input/output paths.\n- **Quick Links**: Cards to quickly navigate to key tools like Screenplay Info, Voice Casting, and Voice Testing.\n\n### 4. Screenplay Information\n\nThe **Screenplay Info** screen offers a detailed analysis of your parsed script.\n\n- **Statistics**: View total chunks, speakers, and other metrics.\n- **Actions**:\n    - **Re-parse**: Re-run the parser if you've modified the source file.\n    - **Download JSON/Text**: Export the parsed data for inspection or manual editing.\n\n### 5. Voice Casting\n\nThe **Voice Casting** interface allows you to assign voices to each character found in your script.\n\n- **Character List**: List of characters, along with information on number of lines and total characters of dialogue. \n- **Voice Selection**: Click on \"assign voice\" on a character to assign a voice. You can filter voices by provider (OpenAI, ElevenLabs, etc.) using the tabs at the top of the selection screen\n- **Audition**: Click the \"Play\" button next to a voice to hear a sample.\n- **Custom Voice**: You can also configure a custom voice if supported by the provider.\n- **LLM-Assisted Features**: Use the \"Character Analysis\" and \"Voice Suggestions\" buttons to enter flows to populate character analysis, and then suggest voices based on character descriptions.\n\n### 6. Test Voices\n\nThe **Test Voices** tab is a playground for experimenting with different TTS providers and voices.\n\n- **Text Input**: Type any text you want to hear.\n- **Provider & Voice**: Select any configured provider and voice to test.\n- **Parameters**: Adjust specific parameters (if supported by the provider).\n- **History**: Play back previously generated test clips.\n\n### 7. Audio Generation & Exporting (Coming Soon)\n\n*Note: Full audio generation and exporting features are currently in development. The \"Text Processing\" and \"Generate Audio\" sections in the sidebar are currently placeholders.*\n\nOnce implemented, you will be able to:\n- Configure text processing rules.\n- Generate audio for the entire script.\n- Export the final audiobook as an MP3 file.\n\n## Manual Mode\n\n**Manual Mode** allows you to use the GUI's tools independently of a specific project. This is particularly useful for CLI users who want to use specific GUI features (like the Voice Caster or Test Voices playground) to assist their command-line workflow.\n\n**To enable Manual Mode:**\n1. Toggle the **Manual Mode** switch in the bottom-left corner of the sidebar.\n\n**Available Tools:**\n- **Voice Casting**: Create a voice configuration file from scratch or edit an existing one.\n- **Test Voices**: Experiment with TTS providers without affecting any project files.\n\n## Troubleshooting\n\n### API Errors\n\nIf you encounter errors when trying to use TTS providers:\n1. **Configure API Keys**: Open Settings (gear icon) and enter your API keys for the providers you want to use.\n2. **Verify Keys**: Ensure the keys are valid and have sufficient credits/quota.\n3. **Check Provider Status**: Verify the provider's service is operational (check their status page).\n\n### Backend Connection Issues\n\nIf the app launches but features don't work:\n1. **Check Backend Status**: The app should show a connection indicator if the backend is running.\n2. **Port Conflicts**: Another application might be using port 58735. Close other applications and restart.\n3. **Permissions**: Ensure the app has necessary file system permissions on macOS.\n\n### Audio Playback Issues\n\nIf voice samples don't play in the Voice Casting or Test Voices screens:\n1. **Check Volume**: Ensure your system volume is not muted.\n2. **Audio Codec**: Verify your system supports MP3 playback (should work on all modern systems).\n3. **Reload**: Try refreshing the voice library or restarting the app.\n\n### Performance Issues\n\nIf the app feels slow or unresponsive:\n1. **Large Projects**: Processing very long screenplays may take time. Be patient during parsing operations.\n2. **Memory**: Ensure sufficient free RAM is available (recommended: 4GB+).\n3. **Close Other Apps**: Free up system resources by closing unnecessary applications.\n\n### Getting More Help\n\nFor advanced troubleshooting and technical details, see the [Technical Documentation](GUI_TECHNICAL.md#troubleshooting).\n\nIf you encounter bugs or have feature requests, please report them at the [GitHub Issues](https://github.com/tmbdev/script-to-speech/issues) page.","src/content/docs/guide.md","b169849d9fc868c2",{"html":18,"metadata":19},"\u003Ch1 id=\"script-to-speech-gui-user-guide\">Script to Speech GUI User Guide\u003C/h1>\n\u003Cp>The Script to Speech GUI provides a user-friendly interface for generating audiobooks from screenplays. It wraps the powerful CLI tools in a modern, intuitive desktop application.\u003C/p>\n\u003Ch2 id=\"getting-started\">Getting Started\u003C/h2>\n\u003Ch3 id=\"installation\">Installation\u003C/h3>\n\u003Cp>The GUI is distributed as a standalone desktop application.\u003C/p>\n\u003Cp>\u003Cstrong>Building from Source:\u003C/strong>\u003C/p>\n\u003Cp>To build the application yourself, see the \u003Ca href=\"GUI_TECHNICAL.md#building-for-production\">Building for Production\u003C/a> section in the technical documentation.\u003C/p>\n\u003Cp>\u003Cstrong>Locating Built Applications:\u003C/strong>\u003C/p>\n\u003Cp>After building, you can find the application at:\u003C/p>\n\u003Cul>\n\u003Cli>\u003Cstrong>macOS\u003C/strong>: \u003Ccode>gui/frontend/src-tauri/target/release/bundle/macos/Script to Speech.app\u003C/code>\u003C/li>\n\u003Cli>\u003Cstrong>macOS Installer\u003C/strong>: \u003Ccode>gui/frontend/src-tauri/target/release/bundle/dmg/Script to Speech_0.1.0_aarch64.dmg\u003C/code>\u003C/li>\n\u003C/ul>\n\u003Cp>Simply double-click the \u003Ccode>.app\u003C/code> file or install via the \u003Ccode>.dmg\u003C/code> to launch the application.\u003C/p>\n\u003Ch3 id=\"launching-the-app\">Launching the App\u003C/h3>\n\u003Cp>Upon opening the application, you will be greeted by the Project Selection screen. Here you can:\u003C/p>\n\u003Cul>\n\u003Cli>\u003Cstrong>Open an existing project\u003C/strong>: Select a previous project folder\u003C/li>\n\u003Cli>\u003Cstrong>Create a new project\u003C/strong>: Start fresh with a new screenplay.\u003C/li>\n\u003C/ul>\n\u003Ch2 id=\"workflow\">Workflow\u003C/h2>\n\u003Ch3 id=\"1-creating-a-project--importing-a-screenplay\">1. Creating a Project &#x26; Importing a Screenplay\u003C/h3>\n\u003Col>\n\u003Cli>Click \u003Cstrong>“New Project”\u003C/strong>.\u003C/li>\n\u003Cli>Use the file picker to select your screenplay PDF or text file.\u003C/li>\n\u003Cli>The application will automatically parse the screenplay and identify characters.\u003C/li>\n\u003C/ol>\n\u003Ch3 id=\"2-configuring-api-keys\">2. Configuring API Keys\u003C/h3>\n\u003Cp>Before you can use voice casting or generation features, you must configure your API keys.\u003C/p>\n\u003Col>\n\u003Cli>Click on the \u003Cstrong>Settings\u003C/strong> icon (gear icon).\u003C/li>\n\u003Cli>Enter your API keys for the providers you intend to use (e.g., OpenAI, ElevenLabs).\u003C/li>\n\u003Cli>Keys are stored securely on your local machine.\u003C/li>\n\u003C/ol>\n\u003Ch3 id=\"3-project-overview\">3. Project Overview\u003C/h3>\n\u003Cp>The \u003Cstrong>Project Overview\u003C/strong> tab provides a high-level summary of your current project.\u003C/p>\n\u003Cul>\n\u003Cli>\u003Cstrong>Project Status\u003C/strong>: Shows the current state (e.g., “Ready to Generate”) and input/output paths.\u003C/li>\n\u003Cli>\u003Cstrong>Quick Links\u003C/strong>: Cards to quickly navigate to key tools like Screenplay Info, Voice Casting, and Voice Testing.\u003C/li>\n\u003C/ul>\n\u003Ch3 id=\"4-screenplay-information\">4. Screenplay Information\u003C/h3>\n\u003Cp>The \u003Cstrong>Screenplay Info\u003C/strong> screen offers a detailed analysis of your parsed script.\u003C/p>\n\u003Cul>\n\u003Cli>\u003Cstrong>Statistics\u003C/strong>: View total chunks, speakers, and other metrics.\u003C/li>\n\u003Cli>\u003Cstrong>Actions\u003C/strong>:\n\u003Cul>\n\u003Cli>\u003Cstrong>Re-parse\u003C/strong>: Re-run the parser if you’ve modified the source file.\u003C/li>\n\u003Cli>\u003Cstrong>Download JSON/Text\u003C/strong>: Export the parsed data for inspection or manual editing.\u003C/li>\n\u003C/ul>\n\u003C/li>\n\u003C/ul>\n\u003Ch3 id=\"5-voice-casting\">5. Voice Casting\u003C/h3>\n\u003Cp>The \u003Cstrong>Voice Casting\u003C/strong> interface allows you to assign voices to each character found in your script.\u003C/p>\n\u003Cul>\n\u003Cli>\u003Cstrong>Character List\u003C/strong>: List of characters, along with information on number of lines and total characters of dialogue.\u003C/li>\n\u003Cli>\u003Cstrong>Voice Selection\u003C/strong>: Click on “assign voice” on a character to assign a voice. You can filter voices by provider (OpenAI, ElevenLabs, etc.) using the tabs at the top of the selection screen\u003C/li>\n\u003Cli>\u003Cstrong>Audition\u003C/strong>: Click the “Play” button next to a voice to hear a sample.\u003C/li>\n\u003Cli>\u003Cstrong>Custom Voice\u003C/strong>: You can also configure a custom voice if supported by the provider.\u003C/li>\n\u003Cli>\u003Cstrong>LLM-Assisted Features\u003C/strong>: Use the “Character Analysis” and “Voice Suggestions” buttons to enter flows to populate character analysis, and then suggest voices based on character descriptions.\u003C/li>\n\u003C/ul>\n\u003Ch3 id=\"6-test-voices\">6. Test Voices\u003C/h3>\n\u003Cp>The \u003Cstrong>Test Voices\u003C/strong> tab is a playground for experimenting with different TTS providers and voices.\u003C/p>\n\u003Cul>\n\u003Cli>\u003Cstrong>Text Input\u003C/strong>: Type any text you want to hear.\u003C/li>\n\u003Cli>\u003Cstrong>Provider &#x26; Voice\u003C/strong>: Select any configured provider and voice to test.\u003C/li>\n\u003Cli>\u003Cstrong>Parameters\u003C/strong>: Adjust specific parameters (if supported by the provider).\u003C/li>\n\u003Cli>\u003Cstrong>History\u003C/strong>: Play back previously generated test clips.\u003C/li>\n\u003C/ul>\n\u003Ch3 id=\"7-audio-generation--exporting-coming-soon\">7. Audio Generation &#x26; Exporting (Coming Soon)\u003C/h3>\n\u003Cp>\u003Cem>Note: Full audio generation and exporting features are currently in development. The “Text Processing” and “Generate Audio” sections in the sidebar are currently placeholders.\u003C/em>\u003C/p>\n\u003Cp>Once implemented, you will be able to:\u003C/p>\n\u003Cul>\n\u003Cli>Configure text processing rules.\u003C/li>\n\u003Cli>Generate audio for the entire script.\u003C/li>\n\u003Cli>Export the final audiobook as an MP3 file.\u003C/li>\n\u003C/ul>\n\u003Ch2 id=\"manual-mode\">Manual Mode\u003C/h2>\n\u003Cp>\u003Cstrong>Manual Mode\u003C/strong> allows you to use the GUI’s tools independently of a specific project. This is particularly useful for CLI users who want to use specific GUI features (like the Voice Caster or Test Voices playground) to assist their command-line workflow.\u003C/p>\n\u003Cp>\u003Cstrong>To enable Manual Mode:\u003C/strong>\u003C/p>\n\u003Col>\n\u003Cli>Toggle the \u003Cstrong>Manual Mode\u003C/strong> switch in the bottom-left corner of the sidebar.\u003C/li>\n\u003C/ol>\n\u003Cp>\u003Cstrong>Available Tools:\u003C/strong>\u003C/p>\n\u003Cul>\n\u003Cli>\u003Cstrong>Voice Casting\u003C/strong>: Create a voice configuration file from scratch or edit an existing one.\u003C/li>\n\u003Cli>\u003Cstrong>Test Voices\u003C/strong>: Experiment with TTS providers without affecting any project files.\u003C/li>\n\u003C/ul>\n\u003Ch2 id=\"troubleshooting\">Troubleshooting\u003C/h2>\n\u003Ch3 id=\"api-errors\">API Errors\u003C/h3>\n\u003Cp>If you encounter errors when trying to use TTS providers:\u003C/p>\n\u003Col>\n\u003Cli>\u003Cstrong>Configure API Keys\u003C/strong>: Open Settings (gear icon) and enter your API keys for the providers you want to use.\u003C/li>\n\u003Cli>\u003Cstrong>Verify Keys\u003C/strong>: Ensure the keys are valid and have sufficient credits/quota.\u003C/li>\n\u003Cli>\u003Cstrong>Check Provider Status\u003C/strong>: Verify the provider’s service is operational (check their status page).\u003C/li>\n\u003C/ol>\n\u003Ch3 id=\"backend-connection-issues\">Backend Connection Issues\u003C/h3>\n\u003Cp>If the app launches but features don’t work:\u003C/p>\n\u003Col>\n\u003Cli>\u003Cstrong>Check Backend Status\u003C/strong>: The app should show a connection indicator if the backend is running.\u003C/li>\n\u003Cli>\u003Cstrong>Port Conflicts\u003C/strong>: Another application might be using port 58735. Close other applications and restart.\u003C/li>\n\u003Cli>\u003Cstrong>Permissions\u003C/strong>: Ensure the app has necessary file system permissions on macOS.\u003C/li>\n\u003C/ol>\n\u003Ch3 id=\"audio-playback-issues\">Audio Playback Issues\u003C/h3>\n\u003Cp>If voice samples don’t play in the Voice Casting or Test Voices screens:\u003C/p>\n\u003Col>\n\u003Cli>\u003Cstrong>Check Volume\u003C/strong>: Ensure your system volume is not muted.\u003C/li>\n\u003Cli>\u003Cstrong>Audio Codec\u003C/strong>: Verify your system supports MP3 playback (should work on all modern systems).\u003C/li>\n\u003Cli>\u003Cstrong>Reload\u003C/strong>: Try refreshing the voice library or restarting the app.\u003C/li>\n\u003C/ol>\n\u003Ch3 id=\"performance-issues\">Performance Issues\u003C/h3>\n\u003Cp>If the app feels slow or unresponsive:\u003C/p>\n\u003Col>\n\u003Cli>\u003Cstrong>Large Projects\u003C/strong>: Processing very long screenplays may take time. Be patient during parsing operations.\u003C/li>\n\u003Cli>\u003Cstrong>Memory\u003C/strong>: Ensure sufficient free RAM is available (recommended: 4GB+).\u003C/li>\n\u003Cli>\u003Cstrong>Close Other Apps\u003C/strong>: Free up system resources by closing unnecessary applications.\u003C/li>\n\u003C/ol>\n\u003Ch3 id=\"getting-more-help\">Getting More Help\u003C/h3>\n\u003Cp>For advanced troubleshooting and technical details, see the \u003Ca href=\"GUI_TECHNICAL.md#troubleshooting\">Technical Documentation\u003C/a>.\u003C/p>\n\u003Cp>If you encounter bugs or have feature requests, please report them at the \u003Ca href=\"https://github.com/tmbdev/script-to-speech/issues\">GitHub Issues\u003C/a> page.\u003C/p>",{"headings":20,"localImagePaths":81,"remoteImagePaths":82,"frontmatter":83,"imagePaths":84},[21,25,29,33,36,39,42,45,48,51,54,57,60,63,66,69,72,75,78],{"depth":22,"slug":23,"text":24},1,"script-to-speech-gui-user-guide","Script to Speech GUI User Guide",{"depth":26,"slug":27,"text":28},2,"getting-started","Getting Started",{"depth":30,"slug":31,"text":32},3,"installation","Installation",{"depth":30,"slug":34,"text":35},"launching-the-app","Launching the App",{"depth":26,"slug":37,"text":38},"workflow","Workflow",{"depth":30,"slug":40,"text":41},"1-creating-a-project--importing-a-screenplay","1. Creating a Project & Importing a Screenplay",{"depth":30,"slug":43,"text":44},"2-configuring-api-keys","2. Configuring API Keys",{"depth":30,"slug":46,"text":47},"3-project-overview","3. Project Overview",{"depth":30,"slug":49,"text":50},"4-screenplay-information","4. Screenplay Information",{"depth":30,"slug":52,"text":53},"5-voice-casting","5. Voice Casting",{"depth":30,"slug":55,"text":56},"6-test-voices","6. Test Voices",{"depth":30,"slug":58,"text":59},"7-audio-generation--exporting-coming-soon","7. Audio Generation & Exporting (Coming Soon)",{"depth":26,"slug":61,"text":62},"manual-mode","Manual Mode",{"depth":26,"slug":64,"text":65},"troubleshooting","Troubleshooting",{"depth":30,"slug":67,"text":68},"api-errors","API Errors",{"depth":30,"slug":70,"text":71},"backend-connection-issues","Backend Connection Issues",{"depth":30,"slug":73,"text":74},"audio-playback-issues","Audio Playback Issues",{"depth":30,"slug":76,"text":77},"performance-issues","Performance Issues",{"depth":30,"slug":79,"text":80},"getting-more-help","Getting More Help",[],[],{},[],"guide.md","privacy",{"id":86,"data":88,"body":89,"filePath":90,"digest":91,"rendered":92,"legacyId":163},{},"# Privacy Policy\n\nScript to Speech is committed to protecting your privacy and data. This document explains what data is collected, how it's used, and what you should know about third-party services when using this tool.\n\n## Data Collection by Script to Speech\n\n**Script to Speech collects NO user data.** Specifically:\n\n- **No telemetry or analytics**: The application does not send usage statistics, error reports, or any other data about your usage\n- **No tracking**: No user behavior is monitored or recorded\n- **No advertisements**: No ads are displayed or user data sold to advertisers\n- **No data sharing**: Script to Speech does not share any user data with third parties\n- **No network requests**: The application only makes network requests to services required for functionality that you explicitly configure\n- **No remote logging**: All logs are stored locally on your machine\n- **No user accounts**: No registration, login, or user account system exists\n\n## Local Data Storage\n\nScript to Speech stores data locally on your machine:\n\n- **Input files**: Screenplay PDFs/TXT files are copied to `input/[screenplay_name]/` directory\n- **Generated files**: Parsed JSON, voice configurations, and audio files are stored in `input/` and `output/` directories\n- **Cache files**: Audio clips are cached locally in `output/[screenplay_name]/cache/`\n- **Log files**: Processing logs are stored in `output/[screenplay_name]/logs/`\n\n**You have full control** over all local data and can delete any files at any time.\n\n## Data Sent to External Services for Functionality\n\nScript to Speech requires external services to provide its core functionality. Here's what data is sent and why:\n\n### Audio Generation (Required for TTS Functionality)\n\nTo convert your screenplay text into speech, Script to Speech sends individual dialogue chunks to TTS (text-to-speech) providers you configure. Support for local, self-hosted, TTS providers is on teh Script to Speech roadmap.\n\n**TTS Providers that may receive your content, if configured:**\n- OpenAI\n- ElevenLabs\n- Cartesia\n- Minimax\n- Zonos\n\n**Data sent**: Individual dialogue chunks (typically single lines of dialogue or scene descriptions) are sent one at a time to generate audio. Your screenplay is not sent as a complete document to TTS providers.\n\n### Character Notes Creation (Optional Feature)\n\nIf you choose to use the LLM-assisted character note creation feature (`sts-generate-character-notes-prompt`), this is entirely optional and can be skipped.\n\n**LLM Services (when you choose to use voice casting):**\n\n**Data sent**: \n- Your complete screenplay text\n- Your current voice configuration\n- Instructions for voice casting analysis\n\n**Important**: This optional feature sends your ENTIRE screenplay to the LLM service. Only use this feature with LLM providers whose privacy policies you trust, or skip this feature entirely and configure voices manually.\n\n### Voice Library Casting (Optional Feature)\n\nIf you choose to use the LLM-assisted voice library casting feature (`sts-generate-voice-library-casting-prompt`), this is entirely optional and can be skipped.\n\n**LLM Services (when you choose to use voice library casting):**\n\n**Data sent**: \n- Your voice configuration including character names and any casting notes\n- Voice library data for the specified providers\n- Instructions for voice selection\n\n**Important**: This optional feature sends your character list and casting notes (but **NOT** your screenplay text) to the LLM service. This is more privacy-conscious than character notes generation, but still shares information about your project's characters.\n\n**Privacy-conscious approach**: For maximum privacy, manually configure voices without using either LLM-assisted feature. For moderate privacy, manually add casting notes to your configuration, then use only voice library casting (avoiding screenplay text sharing).\n\n## What You Should Know About Third-Party Services\n\nEach service has different policies regarding:\n\n- **Data retention**: How long they keep your content\n- **Data usage**: Whether your content is used for training AI models\n- **Data sharing**: Whether your content is shared with other parties\n- **Geographic storage**: Where your data is processed and stored\n\n### Recommended Actions\n\nBefore using any service:\n\n1. **Read their privacy policy**: Understand how your data will be handled\n2. **Check training data policies**: Determine if your content will be used to train AI models\n3. **Review data retention**: Understand how long your content is stored\n4. **Consider data sensitivity**: Evaluate whether you're comfortable sharing your screenplay content\n\n### Service-Specific Resources\n\n- **OpenAI**: [Privacy Policy](https://openai.com/privacy/) | [Consumer Privacy / Data use](https://openai.com/consumer-privacy/)\n- **ElevenLabs**: [Privacy Policy](https://elevenlabs.io/privacy)\n- **Cartesia**: [Privacy Policy](https://cartesia.ai/legal/privacy.html)\n- **Minimax**: [Privacy Policy](https://www.minimax.io/audio/doc/privacy-policy.html)\n- **Zonos**: [Privacy Policy](https://playground.zyphra.com/settings/data-management)\n\n## Recommendations for Privacy-Conscious Usage\n\n### Minimize Data Exposure\n\n1. **Test with sample content**: Use non-sensitive text for initial testing and voice sampling\n2. **Use dummy providers**: Test configurations with `--dummy-tts-provider-override` flag\n\n### Read Privacy / Data Usage Policies\n1. Different TTS and LLM providers have different stances on data privacy and usage. Understand which providers use user supplied content for LLM training\n2. \"Free\" tiers for providers often give up privacy and data usage rights in exchange for free usage\n\n### LLM Voice Casting Considerations (Optional Features)\n\n1. **Manual approach**: Skip LLM assistance entirely and configure voices manually - these features are completely optional\n2. **Use local LLMs**: Consider running local language models instead of cloud services\n3. **Custom prompts**: Create your own voice casting prompts without including screenplay text\n4. **Avoid sensitive content**: Don't use voice casting features for confidential screenplays\n\n### API Key Security\n\n1. **Use .env files**: Store API keys locally rather than in environment variables\n2. **Rotate keys regularly**: Generate new API keys periodically\n3. **Limit key permissions**: Use API keys with minimal required permissions where possible\n4. **Monitor usage**: Check provider dashboards for unexpected API usage\n\n### Data Management\n\n1. **Clean up regularly**: Delete cached audio and logs you no longer need\n2. **Backup configurations**: Keep voice configurations but consider removing screenplay content from backups\n3. **Secure storage**: Store sensitive screenplay files in encrypted directories\n4. **Version control**: Avoid committing screenplay content or API keys to version control\n\n## International Users\n\nDifferent countries have different privacy laws (GDPR, CCPA, etc.). Consider:\n\n- **Data residency**: Where your data is processed by third-party services\n- **Legal compliance**: Whether service providers comply with your local privacy laws\n- **Data transfer**: How data moves between countries when using cloud services\n\n## Changes to This Policy\n\nThis privacy policy may be updated to reflect changes in:\n\n- How Script to Speech operates\n- New third-party service integrations\n- Legal requirements\n- User feedback\n\nCheck this file periodically for updates. The last update date is shown at the bottom of this document.\n\n## Contact Information\n\nFor privacy-related questions or concerns about Script to Speech:\n\n- **GitHub Issues**: [Create an issue](https://github.com/trentw/script-to-speech/issues) for privacy questions\n- **Email**: Contact the maintainer at the email address listed in the project's `pyproject.toml`\n\nFor questions about third-party service privacy policies, contact those services directly using the links provided above.\n\n## Your Responsibility\n\nAs a user of Script to Speech, you are responsible for:\n\n- Understanding the privacy policies of services you choose to use\n- Making informed decisions about what content to process\n- Complying with any applicable laws regarding data processing\n- Protecting your API keys and sensitive content\n\n## Summary\n\n- **Script to Speech**: Collects no data, operates locally, fully under your control\n- **TTS Providers**: Receive individual text lines for audio generation\n- **LLM Services**: May receive complete screenplay content when using voice casting features\n- **Your choice**: You decide which services to use and what content to process\n\n---\n\n*Last updated: June 25, 2025*","src/content/docs/privacy.md","ca940c4ef065a74c",{"html":93,"metadata":94},"\u003Ch1 id=\"privacy-policy\">Privacy Policy\u003C/h1>\n\u003Cp>Script to Speech is committed to protecting your privacy and data. This document explains what data is collected, how it’s used, and what you should know about third-party services when using this tool.\u003C/p>\n\u003Ch2 id=\"data-collection-by-script-to-speech\">Data Collection by Script to Speech\u003C/h2>\n\u003Cp>\u003Cstrong>Script to Speech collects NO user data.\u003C/strong> Specifically:\u003C/p>\n\u003Cul>\n\u003Cli>\u003Cstrong>No telemetry or analytics\u003C/strong>: The application does not send usage statistics, error reports, or any other data about your usage\u003C/li>\n\u003Cli>\u003Cstrong>No tracking\u003C/strong>: No user behavior is monitored or recorded\u003C/li>\n\u003Cli>\u003Cstrong>No advertisements\u003C/strong>: No ads are displayed or user data sold to advertisers\u003C/li>\n\u003Cli>\u003Cstrong>No data sharing\u003C/strong>: Script to Speech does not share any user data with third parties\u003C/li>\n\u003Cli>\u003Cstrong>No network requests\u003C/strong>: The application only makes network requests to services required for functionality that you explicitly configure\u003C/li>\n\u003Cli>\u003Cstrong>No remote logging\u003C/strong>: All logs are stored locally on your machine\u003C/li>\n\u003Cli>\u003Cstrong>No user accounts\u003C/strong>: No registration, login, or user account system exists\u003C/li>\n\u003C/ul>\n\u003Ch2 id=\"local-data-storage\">Local Data Storage\u003C/h2>\n\u003Cp>Script to Speech stores data locally on your machine:\u003C/p>\n\u003Cul>\n\u003Cli>\u003Cstrong>Input files\u003C/strong>: Screenplay PDFs/TXT files are copied to \u003Ccode>input/[screenplay_name]/\u003C/code> directory\u003C/li>\n\u003Cli>\u003Cstrong>Generated files\u003C/strong>: Parsed JSON, voice configurations, and audio files are stored in \u003Ccode>input/\u003C/code> and \u003Ccode>output/\u003C/code> directories\u003C/li>\n\u003Cli>\u003Cstrong>Cache files\u003C/strong>: Audio clips are cached locally in \u003Ccode>output/[screenplay_name]/cache/\u003C/code>\u003C/li>\n\u003Cli>\u003Cstrong>Log files\u003C/strong>: Processing logs are stored in \u003Ccode>output/[screenplay_name]/logs/\u003C/code>\u003C/li>\n\u003C/ul>\n\u003Cp>\u003Cstrong>You have full control\u003C/strong> over all local data and can delete any files at any time.\u003C/p>\n\u003Ch2 id=\"data-sent-to-external-services-for-functionality\">Data Sent to External Services for Functionality\u003C/h2>\n\u003Cp>Script to Speech requires external services to provide its core functionality. Here’s what data is sent and why:\u003C/p>\n\u003Ch3 id=\"audio-generation-required-for-tts-functionality\">Audio Generation (Required for TTS Functionality)\u003C/h3>\n\u003Cp>To convert your screenplay text into speech, Script to Speech sends individual dialogue chunks to TTS (text-to-speech) providers you configure. Support for local, self-hosted, TTS providers is on teh Script to Speech roadmap.\u003C/p>\n\u003Cp>\u003Cstrong>TTS Providers that may receive your content, if configured:\u003C/strong>\u003C/p>\n\u003Cul>\n\u003Cli>OpenAI\u003C/li>\n\u003Cli>ElevenLabs\u003C/li>\n\u003Cli>Cartesia\u003C/li>\n\u003Cli>Minimax\u003C/li>\n\u003Cli>Zonos\u003C/li>\n\u003C/ul>\n\u003Cp>\u003Cstrong>Data sent\u003C/strong>: Individual dialogue chunks (typically single lines of dialogue or scene descriptions) are sent one at a time to generate audio. Your screenplay is not sent as a complete document to TTS providers.\u003C/p>\n\u003Ch3 id=\"character-notes-creation-optional-feature\">Character Notes Creation (Optional Feature)\u003C/h3>\n\u003Cp>If you choose to use the LLM-assisted character note creation feature (\u003Ccode>sts-generate-character-notes-prompt\u003C/code>), this is entirely optional and can be skipped.\u003C/p>\n\u003Cp>\u003Cstrong>LLM Services (when you choose to use voice casting):\u003C/strong>\u003C/p>\n\u003Cp>\u003Cstrong>Data sent\u003C/strong>:\u003C/p>\n\u003Cul>\n\u003Cli>Your complete screenplay text\u003C/li>\n\u003Cli>Your current voice configuration\u003C/li>\n\u003Cli>Instructions for voice casting analysis\u003C/li>\n\u003C/ul>\n\u003Cp>\u003Cstrong>Important\u003C/strong>: This optional feature sends your ENTIRE screenplay to the LLM service. Only use this feature with LLM providers whose privacy policies you trust, or skip this feature entirely and configure voices manually.\u003C/p>\n\u003Ch3 id=\"voice-library-casting-optional-feature\">Voice Library Casting (Optional Feature)\u003C/h3>\n\u003Cp>If you choose to use the LLM-assisted voice library casting feature (\u003Ccode>sts-generate-voice-library-casting-prompt\u003C/code>), this is entirely optional and can be skipped.\u003C/p>\n\u003Cp>\u003Cstrong>LLM Services (when you choose to use voice library casting):\u003C/strong>\u003C/p>\n\u003Cp>\u003Cstrong>Data sent\u003C/strong>:\u003C/p>\n\u003Cul>\n\u003Cli>Your voice configuration including character names and any casting notes\u003C/li>\n\u003Cli>Voice library data for the specified providers\u003C/li>\n\u003Cli>Instructions for voice selection\u003C/li>\n\u003C/ul>\n\u003Cp>\u003Cstrong>Important\u003C/strong>: This optional feature sends your character list and casting notes (but \u003Cstrong>NOT\u003C/strong> your screenplay text) to the LLM service. This is more privacy-conscious than character notes generation, but still shares information about your project’s characters.\u003C/p>\n\u003Cp>\u003Cstrong>Privacy-conscious approach\u003C/strong>: For maximum privacy, manually configure voices without using either LLM-assisted feature. For moderate privacy, manually add casting notes to your configuration, then use only voice library casting (avoiding screenplay text sharing).\u003C/p>\n\u003Ch2 id=\"what-you-should-know-about-third-party-services\">What You Should Know About Third-Party Services\u003C/h2>\n\u003Cp>Each service has different policies regarding:\u003C/p>\n\u003Cul>\n\u003Cli>\u003Cstrong>Data retention\u003C/strong>: How long they keep your content\u003C/li>\n\u003Cli>\u003Cstrong>Data usage\u003C/strong>: Whether your content is used for training AI models\u003C/li>\n\u003Cli>\u003Cstrong>Data sharing\u003C/strong>: Whether your content is shared with other parties\u003C/li>\n\u003Cli>\u003Cstrong>Geographic storage\u003C/strong>: Where your data is processed and stored\u003C/li>\n\u003C/ul>\n\u003Ch3 id=\"recommended-actions\">Recommended Actions\u003C/h3>\n\u003Cp>Before using any service:\u003C/p>\n\u003Col>\n\u003Cli>\u003Cstrong>Read their privacy policy\u003C/strong>: Understand how your data will be handled\u003C/li>\n\u003Cli>\u003Cstrong>Check training data policies\u003C/strong>: Determine if your content will be used to train AI models\u003C/li>\n\u003Cli>\u003Cstrong>Review data retention\u003C/strong>: Understand how long your content is stored\u003C/li>\n\u003Cli>\u003Cstrong>Consider data sensitivity\u003C/strong>: Evaluate whether you’re comfortable sharing your screenplay content\u003C/li>\n\u003C/ol>\n\u003Ch3 id=\"service-specific-resources\">Service-Specific Resources\u003C/h3>\n\u003Cul>\n\u003Cli>\u003Cstrong>OpenAI\u003C/strong>: \u003Ca href=\"https://openai.com/privacy/\">Privacy Policy\u003C/a> | \u003Ca href=\"https://openai.com/consumer-privacy/\">Consumer Privacy / Data use\u003C/a>\u003C/li>\n\u003Cli>\u003Cstrong>ElevenLabs\u003C/strong>: \u003Ca href=\"https://elevenlabs.io/privacy\">Privacy Policy\u003C/a>\u003C/li>\n\u003Cli>\u003Cstrong>Cartesia\u003C/strong>: \u003Ca href=\"https://cartesia.ai/legal/privacy.html\">Privacy Policy\u003C/a>\u003C/li>\n\u003Cli>\u003Cstrong>Minimax\u003C/strong>: \u003Ca href=\"https://www.minimax.io/audio/doc/privacy-policy.html\">Privacy Policy\u003C/a>\u003C/li>\n\u003Cli>\u003Cstrong>Zonos\u003C/strong>: \u003Ca href=\"https://playground.zyphra.com/settings/data-management\">Privacy Policy\u003C/a>\u003C/li>\n\u003C/ul>\n\u003Ch2 id=\"recommendations-for-privacy-conscious-usage\">Recommendations for Privacy-Conscious Usage\u003C/h2>\n\u003Ch3 id=\"minimize-data-exposure\">Minimize Data Exposure\u003C/h3>\n\u003Col>\n\u003Cli>\u003Cstrong>Test with sample content\u003C/strong>: Use non-sensitive text for initial testing and voice sampling\u003C/li>\n\u003Cli>\u003Cstrong>Use dummy providers\u003C/strong>: Test configurations with \u003Ccode>--dummy-tts-provider-override\u003C/code> flag\u003C/li>\n\u003C/ol>\n\u003Ch3 id=\"read-privacy--data-usage-policies\">Read Privacy / Data Usage Policies\u003C/h3>\n\u003Col>\n\u003Cli>Different TTS and LLM providers have different stances on data privacy and usage. Understand which providers use user supplied content for LLM training\u003C/li>\n\u003Cli>“Free” tiers for providers often give up privacy and data usage rights in exchange for free usage\u003C/li>\n\u003C/ol>\n\u003Ch3 id=\"llm-voice-casting-considerations-optional-features\">LLM Voice Casting Considerations (Optional Features)\u003C/h3>\n\u003Col>\n\u003Cli>\u003Cstrong>Manual approach\u003C/strong>: Skip LLM assistance entirely and configure voices manually - these features are completely optional\u003C/li>\n\u003Cli>\u003Cstrong>Use local LLMs\u003C/strong>: Consider running local language models instead of cloud services\u003C/li>\n\u003Cli>\u003Cstrong>Custom prompts\u003C/strong>: Create your own voice casting prompts without including screenplay text\u003C/li>\n\u003Cli>\u003Cstrong>Avoid sensitive content\u003C/strong>: Don’t use voice casting features for confidential screenplays\u003C/li>\n\u003C/ol>\n\u003Ch3 id=\"api-key-security\">API Key Security\u003C/h3>\n\u003Col>\n\u003Cli>\u003Cstrong>Use .env files\u003C/strong>: Store API keys locally rather than in environment variables\u003C/li>\n\u003Cli>\u003Cstrong>Rotate keys regularly\u003C/strong>: Generate new API keys periodically\u003C/li>\n\u003Cli>\u003Cstrong>Limit key permissions\u003C/strong>: Use API keys with minimal required permissions where possible\u003C/li>\n\u003Cli>\u003Cstrong>Monitor usage\u003C/strong>: Check provider dashboards for unexpected API usage\u003C/li>\n\u003C/ol>\n\u003Ch3 id=\"data-management\">Data Management\u003C/h3>\n\u003Col>\n\u003Cli>\u003Cstrong>Clean up regularly\u003C/strong>: Delete cached audio and logs you no longer need\u003C/li>\n\u003Cli>\u003Cstrong>Backup configurations\u003C/strong>: Keep voice configurations but consider removing screenplay content from backups\u003C/li>\n\u003Cli>\u003Cstrong>Secure storage\u003C/strong>: Store sensitive screenplay files in encrypted directories\u003C/li>\n\u003Cli>\u003Cstrong>Version control\u003C/strong>: Avoid committing screenplay content or API keys to version control\u003C/li>\n\u003C/ol>\n\u003Ch2 id=\"international-users\">International Users\u003C/h2>\n\u003Cp>Different countries have different privacy laws (GDPR, CCPA, etc.). Consider:\u003C/p>\n\u003Cul>\n\u003Cli>\u003Cstrong>Data residency\u003C/strong>: Where your data is processed by third-party services\u003C/li>\n\u003Cli>\u003Cstrong>Legal compliance\u003C/strong>: Whether service providers comply with your local privacy laws\u003C/li>\n\u003Cli>\u003Cstrong>Data transfer\u003C/strong>: How data moves between countries when using cloud services\u003C/li>\n\u003C/ul>\n\u003Ch2 id=\"changes-to-this-policy\">Changes to This Policy\u003C/h2>\n\u003Cp>This privacy policy may be updated to reflect changes in:\u003C/p>\n\u003Cul>\n\u003Cli>How Script to Speech operates\u003C/li>\n\u003Cli>New third-party service integrations\u003C/li>\n\u003Cli>Legal requirements\u003C/li>\n\u003Cli>User feedback\u003C/li>\n\u003C/ul>\n\u003Cp>Check this file periodically for updates. The last update date is shown at the bottom of this document.\u003C/p>\n\u003Ch2 id=\"contact-information\">Contact Information\u003C/h2>\n\u003Cp>For privacy-related questions or concerns about Script to Speech:\u003C/p>\n\u003Cul>\n\u003Cli>\u003Cstrong>GitHub Issues\u003C/strong>: \u003Ca href=\"https://github.com/trentw/script-to-speech/issues\">Create an issue\u003C/a> for privacy questions\u003C/li>\n\u003Cli>\u003Cstrong>Email\u003C/strong>: Contact the maintainer at the email address listed in the project’s \u003Ccode>pyproject.toml\u003C/code>\u003C/li>\n\u003C/ul>\n\u003Cp>For questions about third-party service privacy policies, contact those services directly using the links provided above.\u003C/p>\n\u003Ch2 id=\"your-responsibility\">Your Responsibility\u003C/h2>\n\u003Cp>As a user of Script to Speech, you are responsible for:\u003C/p>\n\u003Cul>\n\u003Cli>Understanding the privacy policies of services you choose to use\u003C/li>\n\u003Cli>Making informed decisions about what content to process\u003C/li>\n\u003Cli>Complying with any applicable laws regarding data processing\u003C/li>\n\u003Cli>Protecting your API keys and sensitive content\u003C/li>\n\u003C/ul>\n\u003Ch2 id=\"summary\">Summary\u003C/h2>\n\u003Cul>\n\u003Cli>\u003Cstrong>Script to Speech\u003C/strong>: Collects no data, operates locally, fully under your control\u003C/li>\n\u003Cli>\u003Cstrong>TTS Providers\u003C/strong>: Receive individual text lines for audio generation\u003C/li>\n\u003Cli>\u003Cstrong>LLM Services\u003C/strong>: May receive complete screenplay content when using voice casting features\u003C/li>\n\u003Cli>\u003Cstrong>Your choice\u003C/strong>: You decide which services to use and what content to process\u003C/li>\n\u003C/ul>\n\u003Chr>\n\u003Cp>\u003Cem>Last updated: June 25, 2025\u003C/em>\u003C/p>",{"headings":95,"localImagePaths":159,"remoteImagePaths":160,"frontmatter":161,"imagePaths":162},[96,99,102,105,108,111,114,117,120,123,126,129,132,135,138,141,144,147,150,153,156],{"depth":22,"slug":97,"text":98},"privacy-policy","Privacy Policy",{"depth":26,"slug":100,"text":101},"data-collection-by-script-to-speech","Data Collection by Script to Speech",{"depth":26,"slug":103,"text":104},"local-data-storage","Local Data Storage",{"depth":26,"slug":106,"text":107},"data-sent-to-external-services-for-functionality","Data Sent to External Services for Functionality",{"depth":30,"slug":109,"text":110},"audio-generation-required-for-tts-functionality","Audio Generation (Required for TTS Functionality)",{"depth":30,"slug":112,"text":113},"character-notes-creation-optional-feature","Character Notes Creation (Optional Feature)",{"depth":30,"slug":115,"text":116},"voice-library-casting-optional-feature","Voice Library Casting (Optional Feature)",{"depth":26,"slug":118,"text":119},"what-you-should-know-about-third-party-services","What You Should Know About Third-Party Services",{"depth":30,"slug":121,"text":122},"recommended-actions","Recommended Actions",{"depth":30,"slug":124,"text":125},"service-specific-resources","Service-Specific Resources",{"depth":26,"slug":127,"text":128},"recommendations-for-privacy-conscious-usage","Recommendations for Privacy-Conscious Usage",{"depth":30,"slug":130,"text":131},"minimize-data-exposure","Minimize Data Exposure",{"depth":30,"slug":133,"text":134},"read-privacy--data-usage-policies","Read Privacy / Data Usage Policies",{"depth":30,"slug":136,"text":137},"llm-voice-casting-considerations-optional-features","LLM Voice Casting Considerations (Optional Features)",{"depth":30,"slug":139,"text":140},"api-key-security","API Key Security",{"depth":30,"slug":142,"text":143},"data-management","Data Management",{"depth":26,"slug":145,"text":146},"international-users","International Users",{"depth":26,"slug":148,"text":149},"changes-to-this-policy","Changes to This Policy",{"depth":26,"slug":151,"text":152},"contact-information","Contact Information",{"depth":26,"slug":154,"text":155},"your-responsibility","Your Responsibility",{"depth":26,"slug":157,"text":158},"summary","Summary",[],[],{},[],"privacy.md","providers",{"id":164,"data":166,"body":167,"filePath":168,"digest":169,"rendered":170,"legacyId":303},{},"# TTS Provider Guide\n\nScript to Speech supports multiple Text-to-Speech providers. This guide covers configuration, capabilities, and provider-specific considerations.\n\n## Supported TTS Providers\n\n### [OpenAI](https://openai.com/api/)\n- **Requirements**: API key required\n- **Voice Options**: Preview available at [openai.fm](https://www.openai.fm/)\n- **Concurrent Downloads**: 7 threads\n- **Rate Limits**: Standard API rate limits apply\n- **Best For**: \n- **Considerations**\n  - **Pros**\n    - Cheap (up to 10x cheaper compared to ElevenLabs)\n    - High-quality, realistic-sounding voices\n    - Fast generation\n  - **Cons**\n    - Limited number of voices\n    - Has issues where short clips are sometimes output as silent\n  - **Best For**\n    - Characters with lots of lines (due to affordability)\n    - Characters that don't have special accent / age / etc. considerations\n    - \"default\" narrator character (given above considerations)\n### [ElevenLabs](https://elevenlabs.io/app/home)\n- **Requirements**: \n  - API key required\n  - \"Creator\" plan or higher required (other plans to be supported in future releases)\n- **Voice Library**: Uses \"public\" [library voices](https://elevenlabs.io/app/voice-library) for configuration\n- **Voice Limit**: 30 voice limit in [\"my voices\" library](https://elevenlabs.io/app/voice-lab)\n- **Voice Management**: Automatic voice addition/removal within 30 voice limit\n- **Monthly Limits**: Voice adds/removes have monthly quotas imposed by ElevenLabs\n- **Concurrent Downloads**: 5 threads\n- **Considerations**\n  - **Pros**\n    - Reliable generation: no issues with silent or otherwise mis-generated audio\n    - Wide variety of voices, across ages / accents / ethnicities / style\n    - High-quality, realistic-sounding voices\n    - Fast generation\n  - **Cons**\n    - Expensive\n    - Some voices in public library low quality\n  - **Best For**\n    - Characters where accent / age / style is important\n    - Filling out the wider world of side characters\n\n### [Cartesia](https://play.cartesia.ai/)\n- **Concurrent Downloads**: 2 threads\n- **Customization**: Language options and speaking rate (experimental)\n- **Considerations**\n  - **Pros**\n    - Free plan gives 25 minutes of generations a month\n    - Voice audio quality fairly high\n    - Fast generation\n    - Features a few dozen voices\n    - $5 / month plan gets 125 minutes of audio\n  - **Cons**\n    - Voice cadence / delivery at times inconsistent\n    - Voice less life-like than OpenAI or ElevenLabs providers\n    - Inconsistent delivery of ALL UPPERCASE text\n  - **Best For**\n    - Side characters\n    - Testing\n\n\n### [Minimax](https://www.minimax.io/audio)\n- **Requirements**: API key and Group ID required\n- **Voice Options**: 60+ system voices with voice mixing capabilities\n- **Concurrent Downloads**: 1 thread (multi-threading supported, but rate-limit generally hit)\n- **Customization**: Voice mixing, speed, volume, pitch, emotion, language boost\n- **Considerations**\n  - **Pros**\n    - Good number of high-quality voices, with a few different accents, and a number of configuration options available\n      - Voice mixing allows blending multiple voices with different weights\n      - Emotion control / pitch control for expressive speech\n    - Extensive non-english support\n    - Fast generation (but aggressive rate-limiting negates most benefit)\n    - Cheap\n  - **Cons**\n    - Some voices lack life-like expressiveness, despite being high-quality otherwise\n    - Some small quirks make for distracting dialogue\n      - Issues with reading numbers at times (e.g. \"In the year 1972\" -> \"In the year one-nine-seven-two\")\n      - Seems to pick the wrong heteronym more than providers like Elevenlabs / OpenAI (e.g. \"*close* up\" -> \"*cloz* up\" instead of \"*cloce* up\"; \"we're going *live*\" -> \"we're going *liv*\" instead of \"we're going *live*\")\n      - Some strange pronunciation for English words at times\n  - **Best For**\n    - Main and supporting characters (though maybe not narrators)\n    - Emotional dialogue with varied expressions or ones requiring a voice blend\n    - Non-english characters\n\n### [Zyphra Zonos](https://playground.zyphra.com/sign-in) (API version)\n- **Requirements**: API key required; free plan okay\n- **Voice Options**: Configurable voice from 9 options\n- **Concurrent Downloads**: 5 threads\n- **Customization**: Speaking rate and language options\n- **Considerations**\n  - **Pros**\n    - Free plan gives 100 minutes of generations a month\n  - **Cons**\n    - Few voices offered\n    - Generation comparatively slow\n    - Reliability: coherence struggles with longer dialogues\n    - Voice less life-like than other providers\n  - **Best For**\n    - One-off side characters\n    - Testing\n\n### Dummy (Testing Only)\n- **Purpose**: Testing without API calls\n- **Types**: dummy_stateful and dummy_stateless\n- **Use Case**: Development and testing\n\n\n## Environment Variables\n\nRequired environment variables by provider:\n\n```bash\n# OpenAI\nexport OPENAI_API_KEY=\"your-api-key\"\n\n# ElevenLabs\nexport ELEVEN_API_KEY=\"your-api-key\"\n\n# Cartesia\nexport CARTESIA_API_KEY=\"your-api-key\"\n\n# Minimax\nexport MINIMAX_API_KEY=\"your-api-key\"\nexport MINIMAX_GROUP_ID=\"your-group-id\"\n\n# Zonos\nexport ZONOS_API_KEY=\"your-api-key\"\n```\n\n## Configuration Structure\n\n### Provider Assignment\n\nEach speaker in your configuration must have a provider assigned, and must supply all required fields for that provider. By default, when a TTS provider configuration is generated, required fields will be generated; optional fields can be manually added. Multiple providers can be combined in a single TTS provider configuration.\n\n```yaml\ndefault:\n  provider: openai\n  voice: onyx\n\nHARRY:\n  provider: elevenlabs\n  voice_id: ErXwobaYiN019PkySvjV\n\nLUNA:\n  provider: zonos\n  default_voice_name: american_male\n```\n\n### Generated Configuration (Single Provider Workflow)\n\nThe `sts-tts-provider-yaml generate [screenplay].json --tts-provider [provider]` command creates a template with:\n1. An entry for each speaker\n2. Pre-populated `provider` field\n2. Empty entries for each required provider field\n3. Speaker statistics to aid in casting each character\n4. (optional) Use `--include-optional-fields` flag to also create empty entries for each optional field\n\n```yaml\n# default: 1556 lines - Used for all non-dialogue pieces\n# Total characters: 104244, Longest dialogue: 2082 characters\ndefault:\n  provider: openai\n  voice:\n\n# HARRY: 283 lines\n# Total characters: 12181, Longest dialogue: 365 characters\nHARRY:\n  provider: openai\n  voice:\n```\n\n## Multi-Provider Workflow\n\n### Step 1: Generate Base Configuration\n```bash\nuv run sts-tts-provider-yaml generate input/[screenplay]/[screenplay].json\n```\n\n### Step 2: Assign TTS Providers\nEdit the generated YAML to assign providers to each speaker:\n```yaml\ndefault:\n  provider: openai\nHARRY:\n  provider: elevenlabs\nLUNA:\n  provider: openai\n```\n\n### Step 3: Populate Provider Fields\n```bash\nuv run sts-tts-provider-yaml populate input/[screenplay]/[screenplay].json \\\n  input/[screenplay]/[screenplay]_voice_config.yaml\n```\n\nThis creates `[screenplay]_voice_config_populated.yaml` with provider-specific fields grouped:\n\n```yaml\n# OpenAI Configuration\ndefault:\n  provider: openai\n  voice:\n\nLUNA:\n  provider: openai\n  voice:\n\n# ElevenLabs Configuration\nHARRY:\n  provider: elevenlabs\n  voice_id:\n```\n\n### Step 4: Fill in Provider Details\nComplete the populated configuration with specific values:\n```yaml\n# OpenAI Configuration\ndefault:\n  provider: openai\n  voice: onyx\n\nLUNA:\n  provider: openai\n  voice: alloy\n\n# ElevenLabs Configuration\nHARRY:\n  provider: elevenlabs\n  voice_id: ErXwobaYiN019PkySvjV\n```\n\n### Step 5: Validate Configuration\n```bash\n# Basic validation (checks for missing/extra/duplicate speakers)\nuv run sts-tts-provider-yaml validate input/[screenplay]/[screenplay].json \\\n  input/[screenplay]/[screenplay]_voice_config.yaml\n\n# Strict validation (also validates provider-specific fields)\nuv run sts-tts-provider-yaml validate input/[screenplay]/[screenplay].json \\\n  input/[screenplay]/[screenplay]_voice_config.yaml --strict\n```\n\n## Provider-Specific Configuration\n\n### OpenAI Configuration\n\nRequired fields:\n- `voice`: Voice identifier\n\nAvailable voices:\n- alloy\n- ash\n- coral\n- echo\n- fable\n- onyx\n- nova\n- sage\n- shimmer\n\nExample:\n```yaml\ndefault:\n  provider: openai\n  voice: onyx\n\nNARRATOR:\n  provider: openai\n  voice: alloy\n```\n\n### ElevenLabs Configuration\n\nRequired fields:\n- `voice_id`: Public library voice ID\n\nImportant notes:\n- Voice IDs must be from the [public voice library](https://elevenlabs.io/app/voice-library), not the [my voices library](https://elevenlabs.io/app/voice-lab)\n- Provider manages the 30 voice limit automatically by removing voices from \"my voices\" library when limit is reached\n- Monthly add/remove operations are limited\n\nExample:\n```yaml\nMARY:\n  provider: elevenlabs\n  voice_id: IKne3meq5aSn9XLyUdCD  # Public library ID\n\nJOHN:\n  provider: elevenlabs\n  voice_id: ErXwobaYiN019PkySvjV  # Public library ID\n```\n\n### Cartesia Configuration\n\nRequired fields:\n- `voice_id`: one of 9 available voices\nVoices and theird IDs can be found at the [Cartesia Playground](https://play.cartesia.ai/)\n\nOptional fields\n- `language`: One of [en,fr,de,es,pt,zh,ja,hi,it,ko,nl,pl,ru,sv,tr]\n- `speed`: One of [\"slow\", \"normal\", \"fast\"] \n  - *note: this is an experimental feature that doesn't work for all voices*\n\nExample:\n```yaml\nBECCA:\n  provider: cartesia\n  voice_id: bf0a246a-8642-498a-9950-80c35e9276b5\n  speed: fast\n  language: fr\n\nTOM:\n  provider: cartesia\n  voice_id: 4df027cb-2920-4a1f-8c34-f21529d5c3fe\n```\n\n\n### Minimax Configuration\n\nRequired fields:\n- `voice_id`: One of 17 available system voices\n\nAvailable voices:\n- English_expressive_narrator\n- English_radiant_girl\n- English_magnetic_voiced_man\n- English_compelling_lady1\n- English_Aussie_Bloke\n- English_captivating_female1\n- English_Upbeat_Woman\n- English_Trustworth_Man\n- English_CalmWoman\n- English_UpsetGirl\n- English_Gentle-voiced_man\n- English_Whispering_girl_v3\n- English_Diligent_Man\n- English_Graceful_Lady\n- English_ReservedYoungMan\n- English_PlayfulGirl\n- English_ManWithDeepVoice\n- English_GentleTeacher\n- English_MaturePartner\n- English_FriendlyPerson\n- English_MatureBoss\n- English_Debator\n- English_Abbess\n- English_LovelyGirl\n- English_Steadymentor\n- English_Deep-VoicedGentleman\n- English_DeterminedMan\n- English_Wiselady\n- English_CaptivatingStoryteller\n- English_AttractiveGirl\n- English_DecentYoungMan\n- English_SentimentalLady\n- English_ImposingManner\n- English_SadTeen\n- English_ThoughtfulMan\n- English_PassionateWarrior\n- English_DecentBoy\n- English_WiseScholar\n- English_Soft-spokenGirl\n- English_SereneWoman\n- English_ConfidentWoman\n- English_patient_man_v1\n- English_Comedian\n- English_GorgeousLady\n- English_BossyLeader\n- English_LovelyLady\n- English_Strong-WilledBoy\n- English_Deep-tonedMan\n- English_StressedLady\n- English_AssertiveQueen\n- English_AnimeCharacter\n- English_Jovialman\n- English_WhimsicalGirl\n- English_CharmingQueen\n- English_Kind-heartedGirl\n- English_FriendlyNeighbor\n- English_Sweet_Female_4\n- English_Magnetic_Male_2\n- English_Lively_Male_11\n- English_Friendly_Female_3\n- English_Steady_Female_1\n- English_Lively_Male_10\n- English_Magnetic_Male_12\n- English_Steady_Female_5\n\nOptional fields:\n- `voice_mix`: List of voice blends (1-4 items), each with:\n  - `voice_id`: One of the 17 system voices\n  - `weight`: Integer between 1-100\n  - Note: If provided, takes precedence over the top-level `voice_id`. Only one of `voice_id` or `voice_mix` can be supplied\n- `speed`: (default: 1.0) Float between 0.5-2.0\n- `volume`: (default: 1.0) Float between >0.0-10.0\n- `pitch`: (default: 0) Integer between -12 to 12\n- `emotion`: One of [\"happy\", \"sad\", \"angry\", \"fear\", \"disgust\", \"neutral\", \"surprise\"]\n- `english_normalization`: (default: true) Boolean (true/false)\n- `language_boost`: (default: \"English\") One of [\"Chinese\", \"English\", \"Japanese\", \"Korean\", \"French\", \"Spanish\", \"German\"]\n\nExample (with voice_id):\n```yaml\nDAVID:\n  provider: minimax\n  voice_id: Calm_Woman\n  speed: 1.2\n  volume: 8.0\n  pitch: 2\n  emotion: happy\n  english_normalization: false\n  language_boost: Spanish\n```\n\nExample (with voice_mix):\n```yaml\nMARIA:\n  provider: minimax\n  voice_mix:\n    - voice_id: Patient_Man\n      weight: 70\n    - voice_id: Young_Knight\n      weight: 30\n```\n\n### Zonos Configuration\n\nRequired fields:\n- `default_voice_name`: one of 9 available voices\n\nAvailable voices:\n- american_female\n- american_male\t\n- anime_girl\n- british_female\n- british_male\n- energetic_boy\n- energetic_girl\n- japanese_female\n- japanese_male\n\nOptional fields:\n- `speaking_rate`: Float between 5 and 35\n- `language_iso_code`: One of [en-us, fr-fr, de, ja, ko, cmn]\n\nExample:\n```yaml\nROBOT:\n  provider: zonos\n  default_voice_name: american_female\n  speaking_rate: 20\n  language_iso_code: en-us\n\nALIEN:\n  provider: zonos\n  default_voice_name: american_male\n```\n\n## Rate Limiting\n\n### Automatic Handling\nThe system automatically handles rate limits with:\n- Exponential backoff\n- Provider-specific retry logic\n- Queue management\n\nWhen rate limited, the system will:\n1. Pause requests for that provider\n2. Continue with other TTS providers\n3. Retry after backoff period\n\n## Provider Architecture\n\nThe Script to Speech system supports two types of TTS providers: stateless and stateful. Understanding the difference is important for creating custom providers.\n\n### Stateless vs. Stateful TTS Providers\n\n#### Stateless TTS Providers\n- **Definition**: Providers that don't maintain state between API calls\n- **Implementation**: Use class methods to generate audio\n- **Examples**: OpenAI, Zonos\n- **Advantages**:\n  - Simpler to implement\n  - Thread-safe without additional code\n  - More predictable behavior\n  - Easier to debug\n- **When to use**: Default choice for most providers\n\n#### Stateful TTS Providers\n- **Definition**: Providers that maintain state between API calls\n- **Implementation**: Same class methods as Stateless provider, except for instance-based `__init__` and `generate_audio` methods\n- **Examples**: ElevenLabs (for voice registry management)\n- **Advantages**:\n  - Can cache / configure information between calls\n  - Can implement complex state machines\n- **When to use**: Only when required by the API or when managing complex resources\n\n### Provider Management\n\nThe `TTSProviderManager` handles:\n- **Lazy Initialization**: TTS providers are only initialized when needed\n- **Thread Safety**: Thread locks protect provider initialization and state\n- **Client Caching**: API clients are reused across calls\n- **Multi-threading**: Each provider has its own download concurrency settings\n\n## Creating Custom TTS Providers\n\n### Base Classes\n\nAll TTS providers implement one of two base classes:\n\n1. `StatelessTTSProviderBase`\n   - For TTS providers without state\n   - Uses class methods\n\n2. `StatefulTTSProviderBase`\n   - For TTS providers with state\n   - Uses instance methods and `__init__`\n\nBoth inherit from `TTSProviderCommonMixin` which defines common requirements.\n\n### Adding a New Provider\n1. Create a directory in `src/script_to_speech/tts_providers/` with your provider name\n2. Create a `tts_provider.py` file in that directory\n3. Implement the appropriate base class\n4. Return the correct provider identifier via `get_provider_identifier()`\n\nThe provider will be automatically discovered and available in configurations.\n\n### Examples\n- For an example of a stateless provider, see the [OpenAI TTS Provider](../src/script_to_speech/tts_providers/openai/tts_provider.py)\n- For an example of a stateful provider, see the [ElevenLabs TTS Provider](../src/script_to_speech/tts_providers/elevenlabs/tts_provider.py) and accompanying [ElevenLabs Voice Registry Manager](src/script_to_speech/tts_providers/elevenlabs/voice_registry_manager.py)\n\n### Provider Requirements\n\nRequired methods:\n- `get_provider_identifier()`: Unique identifier for this provider; will be used in YAML configuration and whenever this provider is being called on the command line\n- `get_speaker_identifier()`: Unique identifier for a given speaker, given a speaker configuration. This is used in caching, so **changing any configuration option for a speaker (e.g. optional fields) should also change the returned `speaker_identifier`**\n- `instantiate_client()`: Create the API client that will be passed to `generate_audio` method by the `TTSProviderManager`\n- `generate_audio()`: Request the audio from the TTS Provider API; return bytes representing the audio\n- `get_required_fields()`: Required configuration fields\n- `validate_speaker_config()`: Logic to validate configuration (checking for required fields, that they're the right type, etc.)\n- `get_yaml_instructions()`: Configuration help text outlining required / optional fields, best practices, etc.\n\nOptional methods:\n- `get_optional_fields()`: Optional configuration fields\n- `get_max_download_threads()`: Concurrent thread limit; defaults to 1\n\n## Best Practices\n\n### Configuration Management\n1. Use the generate → assign → populate workflow\n2. Keep backup configurations for different voice setups\n3. Consider character type when assigning TTS providers\n4. Validate configurations with `sts-tts-provider-yaml validate`\n\n### Multi-Provider Benefits\n1. **Speed**: Parallel processing across TTS providers\n2. **Cost**: Optimize per-provider pricing\n3. **Quality**: Match voice types to character needs\n\n## Troubleshooting\n\n### Common Issues\n\n1. **API Key Errors**\n   ```bash\n   # Check environment variables\n   echo $OPENAI_API_KEY\n   echo $ELEVEN_API_KEY\n   echo $CARTESIA_API_KEY\n   echo $MINIMAX_API_KEY\n   echo $MINIMAX_GROUP_ID\n   echo $ZONOS_API_KEY\n   ```\n\n2. **Voice Configuration Validation**\n   ```bash\n   # Check for missing/extra/duplicate speakers\n   uv run sts-tts-provider-yaml validate script.json config.yaml\n   \n   # Strict validation including provider field validation\n   uv run sts-tts-provider-yaml validate script.json config.yaml --strict\n   ```\n\n3. **Voice Not Found**\n    - ElevenLabs: Ensure voice ID is from public library\n    - OpenAI: Verify voice name matches available options\n    - Minimax: Verify voice_id is one of the specified system voices\n    - Minimax: Check voice_mix structure if using voice mixing\n    - Zonos: Check default_voice_name is a valid voice\n\n4. **Rate Limiting**\n   - Check provider-specific rate limits\n   - Limit global concurrent downloads with `--max-workers` run mode modifier\n   - Distribute voices across TTS providers\n   - Monitor monthly quotas for voice adds / removes (ElevenLabs)\n\n5. **Quality Issues**\n    - OpenAI: Try different voices for different character types\n    - ElevenLabs: Use \"narrative\"/\"conversational\" tagged voices\n    - Minimax: Experiment with voice_mix for unique character voices\n    - Minimax: Adjust emotion, speed, and pitch parameters for expressiveness\n    - Zonos: Adjust speaking rate parameter\n\n### Debugging\n```bash\n# Test single line of dialogue\nuv run sts-generate-standalone-speech openai --voice echo \"Test text\"\n\n# Validate voice configuration against script\nuv run sts-tts-provider-yaml validate input/script.json config.yaml\n\n# Strict validation including provider field validation\nuv run sts-tts-provider-yaml validate input/script.json config.yaml --strict\n```","src/content/docs/providers.md","6eb20c94e7bb30a3",{"html":171,"metadata":172},"\u003Ch1 id=\"tts-provider-guide\">TTS Provider Guide\u003C/h1>\n\u003Cp>Script to Speech supports multiple Text-to-Speech providers. This guide covers configuration, capabilities, and provider-specific considerations.\u003C/p>\n\u003Ch2 id=\"supported-tts-providers\">Supported TTS Providers\u003C/h2>\n\u003Ch3 id=\"openai\">\u003Ca href=\"https://openai.com/api/\">OpenAI\u003C/a>\u003C/h3>\n\u003Cul>\n\u003Cli>\u003Cstrong>Requirements\u003C/strong>: API key required\u003C/li>\n\u003Cli>\u003Cstrong>Voice Options\u003C/strong>: Preview available at \u003Ca href=\"https://www.openai.fm/\">openai.fm\u003C/a>\u003C/li>\n\u003Cli>\u003Cstrong>Concurrent Downloads\u003C/strong>: 7 threads\u003C/li>\n\u003Cli>\u003Cstrong>Rate Limits\u003C/strong>: Standard API rate limits apply\u003C/li>\n\u003Cli>\u003Cstrong>Best For\u003C/strong>:\u003C/li>\n\u003Cli>\u003Cstrong>Considerations\u003C/strong>\n\u003Cul>\n\u003Cli>\u003Cstrong>Pros\u003C/strong>\n\u003Cul>\n\u003Cli>Cheap (up to 10x cheaper compared to ElevenLabs)\u003C/li>\n\u003Cli>High-quality, realistic-sounding voices\u003C/li>\n\u003Cli>Fast generation\u003C/li>\n\u003C/ul>\n\u003C/li>\n\u003Cli>\u003Cstrong>Cons\u003C/strong>\n\u003Cul>\n\u003Cli>Limited number of voices\u003C/li>\n\u003Cli>Has issues where short clips are sometimes output as silent\u003C/li>\n\u003C/ul>\n\u003C/li>\n\u003Cli>\u003Cstrong>Best For\u003C/strong>\n\u003Cul>\n\u003Cli>Characters with lots of lines (due to affordability)\u003C/li>\n\u003Cli>Characters that don’t have special accent / age / etc. considerations\u003C/li>\n\u003Cli>“default” narrator character (given above considerations)\u003C/li>\n\u003C/ul>\n\u003C/li>\n\u003C/ul>\n\u003C/li>\n\u003C/ul>\n\u003Ch3 id=\"elevenlabs\">\u003Ca href=\"https://elevenlabs.io/app/home\">ElevenLabs\u003C/a>\u003C/h3>\n\u003Cul>\n\u003Cli>\u003Cstrong>Requirements\u003C/strong>:\n\u003Cul>\n\u003Cli>API key required\u003C/li>\n\u003Cli>“Creator” plan or higher required (other plans to be supported in future releases)\u003C/li>\n\u003C/ul>\n\u003C/li>\n\u003Cli>\u003Cstrong>Voice Library\u003C/strong>: Uses “public” \u003Ca href=\"https://elevenlabs.io/app/voice-library\">library voices\u003C/a> for configuration\u003C/li>\n\u003Cli>\u003Cstrong>Voice Limit\u003C/strong>: 30 voice limit in \u003Ca href=\"https://elevenlabs.io/app/voice-lab\">“my voices” library\u003C/a>\u003C/li>\n\u003Cli>\u003Cstrong>Voice Management\u003C/strong>: Automatic voice addition/removal within 30 voice limit\u003C/li>\n\u003Cli>\u003Cstrong>Monthly Limits\u003C/strong>: Voice adds/removes have monthly quotas imposed by ElevenLabs\u003C/li>\n\u003Cli>\u003Cstrong>Concurrent Downloads\u003C/strong>: 5 threads\u003C/li>\n\u003Cli>\u003Cstrong>Considerations\u003C/strong>\n\u003Cul>\n\u003Cli>\u003Cstrong>Pros\u003C/strong>\n\u003Cul>\n\u003Cli>Reliable generation: no issues with silent or otherwise mis-generated audio\u003C/li>\n\u003Cli>Wide variety of voices, across ages / accents / ethnicities / style\u003C/li>\n\u003Cli>High-quality, realistic-sounding voices\u003C/li>\n\u003Cli>Fast generation\u003C/li>\n\u003C/ul>\n\u003C/li>\n\u003Cli>\u003Cstrong>Cons\u003C/strong>\n\u003Cul>\n\u003Cli>Expensive\u003C/li>\n\u003Cli>Some voices in public library low quality\u003C/li>\n\u003C/ul>\n\u003C/li>\n\u003Cli>\u003Cstrong>Best For\u003C/strong>\n\u003Cul>\n\u003Cli>Characters where accent / age / style is important\u003C/li>\n\u003Cli>Filling out the wider world of side characters\u003C/li>\n\u003C/ul>\n\u003C/li>\n\u003C/ul>\n\u003C/li>\n\u003C/ul>\n\u003Ch3 id=\"cartesia\">\u003Ca href=\"https://play.cartesia.ai/\">Cartesia\u003C/a>\u003C/h3>\n\u003Cul>\n\u003Cli>\u003Cstrong>Concurrent Downloads\u003C/strong>: 2 threads\u003C/li>\n\u003Cli>\u003Cstrong>Customization\u003C/strong>: Language options and speaking rate (experimental)\u003C/li>\n\u003Cli>\u003Cstrong>Considerations\u003C/strong>\n\u003Cul>\n\u003Cli>\u003Cstrong>Pros\u003C/strong>\n\u003Cul>\n\u003Cli>Free plan gives 25 minutes of generations a month\u003C/li>\n\u003Cli>Voice audio quality fairly high\u003C/li>\n\u003Cli>Fast generation\u003C/li>\n\u003Cli>Features a few dozen voices\u003C/li>\n\u003Cli>$5 / month plan gets 125 minutes of audio\u003C/li>\n\u003C/ul>\n\u003C/li>\n\u003Cli>\u003Cstrong>Cons\u003C/strong>\n\u003Cul>\n\u003Cli>Voice cadence / delivery at times inconsistent\u003C/li>\n\u003Cli>Voice less life-like than OpenAI or ElevenLabs providers\u003C/li>\n\u003Cli>Inconsistent delivery of ALL UPPERCASE text\u003C/li>\n\u003C/ul>\n\u003C/li>\n\u003Cli>\u003Cstrong>Best For\u003C/strong>\n\u003Cul>\n\u003Cli>Side characters\u003C/li>\n\u003Cli>Testing\u003C/li>\n\u003C/ul>\n\u003C/li>\n\u003C/ul>\n\u003C/li>\n\u003C/ul>\n\u003Ch3 id=\"minimax\">\u003Ca href=\"https://www.minimax.io/audio\">Minimax\u003C/a>\u003C/h3>\n\u003Cul>\n\u003Cli>\u003Cstrong>Requirements\u003C/strong>: API key and Group ID required\u003C/li>\n\u003Cli>\u003Cstrong>Voice Options\u003C/strong>: 60+ system voices with voice mixing capabilities\u003C/li>\n\u003Cli>\u003Cstrong>Concurrent Downloads\u003C/strong>: 1 thread (multi-threading supported, but rate-limit generally hit)\u003C/li>\n\u003Cli>\u003Cstrong>Customization\u003C/strong>: Voice mixing, speed, volume, pitch, emotion, language boost\u003C/li>\n\u003Cli>\u003Cstrong>Considerations\u003C/strong>\n\u003Cul>\n\u003Cli>\u003Cstrong>Pros\u003C/strong>\n\u003Cul>\n\u003Cli>Good number of high-quality voices, with a few different accents, and a number of configuration options available\n\u003Cul>\n\u003Cli>Voice mixing allows blending multiple voices with different weights\u003C/li>\n\u003Cli>Emotion control / pitch control for expressive speech\u003C/li>\n\u003C/ul>\n\u003C/li>\n\u003Cli>Extensive non-english support\u003C/li>\n\u003Cli>Fast generation (but aggressive rate-limiting negates most benefit)\u003C/li>\n\u003Cli>Cheap\u003C/li>\n\u003C/ul>\n\u003C/li>\n\u003Cli>\u003Cstrong>Cons\u003C/strong>\n\u003Cul>\n\u003Cli>Some voices lack life-like expressiveness, despite being high-quality otherwise\u003C/li>\n\u003Cli>Some small quirks make for distracting dialogue\n\u003Cul>\n\u003Cli>Issues with reading numbers at times (e.g. “In the year 1972” -> “In the year one-nine-seven-two”)\u003C/li>\n\u003Cli>Seems to pick the wrong heteronym more than providers like Elevenlabs / OpenAI (e.g. “\u003Cem>close\u003C/em> up” -> “\u003Cem>cloz\u003C/em> up” instead of “\u003Cem>cloce\u003C/em> up”; “we’re going \u003Cem>live\u003C/em>” -> “we’re going \u003Cem>liv\u003C/em>” instead of “we’re going \u003Cem>live\u003C/em>”)\u003C/li>\n\u003Cli>Some strange pronunciation for English words at times\u003C/li>\n\u003C/ul>\n\u003C/li>\n\u003C/ul>\n\u003C/li>\n\u003Cli>\u003Cstrong>Best For\u003C/strong>\n\u003Cul>\n\u003Cli>Main and supporting characters (though maybe not narrators)\u003C/li>\n\u003Cli>Emotional dialogue with varied expressions or ones requiring a voice blend\u003C/li>\n\u003Cli>Non-english characters\u003C/li>\n\u003C/ul>\n\u003C/li>\n\u003C/ul>\n\u003C/li>\n\u003C/ul>\n\u003Ch3 id=\"zyphra-zonos-api-version\">\u003Ca href=\"https://playground.zyphra.com/sign-in\">Zyphra Zonos\u003C/a> (API version)\u003C/h3>\n\u003Cul>\n\u003Cli>\u003Cstrong>Requirements\u003C/strong>: API key required; free plan okay\u003C/li>\n\u003Cli>\u003Cstrong>Voice Options\u003C/strong>: Configurable voice from 9 options\u003C/li>\n\u003Cli>\u003Cstrong>Concurrent Downloads\u003C/strong>: 5 threads\u003C/li>\n\u003Cli>\u003Cstrong>Customization\u003C/strong>: Speaking rate and language options\u003C/li>\n\u003Cli>\u003Cstrong>Considerations\u003C/strong>\n\u003Cul>\n\u003Cli>\u003Cstrong>Pros\u003C/strong>\n\u003Cul>\n\u003Cli>Free plan gives 100 minutes of generations a month\u003C/li>\n\u003C/ul>\n\u003C/li>\n\u003Cli>\u003Cstrong>Cons\u003C/strong>\n\u003Cul>\n\u003Cli>Few voices offered\u003C/li>\n\u003Cli>Generation comparatively slow\u003C/li>\n\u003Cli>Reliability: coherence struggles with longer dialogues\u003C/li>\n\u003Cli>Voice less life-like than other providers\u003C/li>\n\u003C/ul>\n\u003C/li>\n\u003Cli>\u003Cstrong>Best For\u003C/strong>\n\u003Cul>\n\u003Cli>One-off side characters\u003C/li>\n\u003Cli>Testing\u003C/li>\n\u003C/ul>\n\u003C/li>\n\u003C/ul>\n\u003C/li>\n\u003C/ul>\n\u003Ch3 id=\"dummy-testing-only\">Dummy (Testing Only)\u003C/h3>\n\u003Cul>\n\u003Cli>\u003Cstrong>Purpose\u003C/strong>: Testing without API calls\u003C/li>\n\u003Cli>\u003Cstrong>Types\u003C/strong>: dummy_stateful and dummy_stateless\u003C/li>\n\u003Cli>\u003Cstrong>Use Case\u003C/strong>: Development and testing\u003C/li>\n\u003C/ul>\n\u003Ch2 id=\"environment-variables\">Environment Variables\u003C/h2>\n\u003Cp>Required environment variables by provider:\u003C/p>\n\u003Cpre class=\"astro-code github-dark\" style=\"background-color:#24292e;color:#e1e4e8; overflow-x: auto;\" tabindex=\"0\" data-language=\"bash\">\u003Ccode>\u003Cspan class=\"line\">\u003Cspan style=\"color:#6A737D\"># OpenAI\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F97583\">export\u003C/span>\u003Cspan style=\"color:#E1E4E8\"> OPENAI_API_KEY\u003C/span>\u003Cspan style=\"color:#F97583\">=\u003C/span>\u003Cspan style=\"color:#9ECBFF\">\"your-api-key\"\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#6A737D\"># ElevenLabs\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F97583\">export\u003C/span>\u003Cspan style=\"color:#E1E4E8\"> ELEVEN_API_KEY\u003C/span>\u003Cspan style=\"color:#F97583\">=\u003C/span>\u003Cspan style=\"color:#9ECBFF\">\"your-api-key\"\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#6A737D\"># Cartesia\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F97583\">export\u003C/span>\u003Cspan style=\"color:#E1E4E8\"> CARTESIA_API_KEY\u003C/span>\u003Cspan style=\"color:#F97583\">=\u003C/span>\u003Cspan style=\"color:#9ECBFF\">\"your-api-key\"\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#6A737D\"># Minimax\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F97583\">export\u003C/span>\u003Cspan style=\"color:#E1E4E8\"> MINIMAX_API_KEY\u003C/span>\u003Cspan style=\"color:#F97583\">=\u003C/span>\u003Cspan style=\"color:#9ECBFF\">\"your-api-key\"\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F97583\">export\u003C/span>\u003Cspan style=\"color:#E1E4E8\"> MINIMAX_GROUP_ID\u003C/span>\u003Cspan style=\"color:#F97583\">=\u003C/span>\u003Cspan style=\"color:#9ECBFF\">\"your-group-id\"\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#6A737D\"># Zonos\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F97583\">export\u003C/span>\u003Cspan style=\"color:#E1E4E8\"> ZONOS_API_KEY\u003C/span>\u003Cspan style=\"color:#F97583\">=\u003C/span>\u003Cspan style=\"color:#9ECBFF\">\"your-api-key\"\u003C/span>\u003C/span>\u003C/code>\u003C/pre>\n\u003Ch2 id=\"configuration-structure\">Configuration Structure\u003C/h2>\n\u003Ch3 id=\"provider-assignment\">Provider Assignment\u003C/h3>\n\u003Cp>Each speaker in your configuration must have a provider assigned, and must supply all required fields for that provider. By default, when a TTS provider configuration is generated, required fields will be generated; optional fields can be manually added. Multiple providers can be combined in a single TTS provider configuration.\u003C/p>\n\u003Cpre class=\"astro-code github-dark\" style=\"background-color:#24292e;color:#e1e4e8; overflow-x: auto;\" tabindex=\"0\" data-language=\"yaml\">\u003Ccode>\u003Cspan class=\"line\">\u003Cspan style=\"color:#85E89D\">default\u003C/span>\u003Cspan style=\"color:#E1E4E8\">:\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#85E89D\">  provider\u003C/span>\u003Cspan style=\"color:#E1E4E8\">: \u003C/span>\u003Cspan style=\"color:#9ECBFF\">openai\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#85E89D\">  voice\u003C/span>\u003Cspan style=\"color:#E1E4E8\">: \u003C/span>\u003Cspan style=\"color:#9ECBFF\">onyx\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#85E89D\">HARRY\u003C/span>\u003Cspan style=\"color:#E1E4E8\">:\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#85E89D\">  provider\u003C/span>\u003Cspan style=\"color:#E1E4E8\">: \u003C/span>\u003Cspan style=\"color:#9ECBFF\">elevenlabs\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#85E89D\">  voice_id\u003C/span>\u003Cspan style=\"color:#E1E4E8\">: \u003C/span>\u003Cspan style=\"color:#9ECBFF\">ErXwobaYiN019PkySvjV\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#85E89D\">LUNA\u003C/span>\u003Cspan style=\"color:#E1E4E8\">:\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#85E89D\">  provider\u003C/span>\u003Cspan style=\"color:#E1E4E8\">: \u003C/span>\u003Cspan style=\"color:#9ECBFF\">zonos\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#85E89D\">  default_voice_name\u003C/span>\u003Cspan style=\"color:#E1E4E8\">: \u003C/span>\u003Cspan style=\"color:#9ECBFF\">american_male\u003C/span>\u003C/span>\u003C/code>\u003C/pre>\n\u003Ch3 id=\"generated-configuration-single-provider-workflow\">Generated Configuration (Single Provider Workflow)\u003C/h3>\n\u003Cp>The \u003Ccode>sts-tts-provider-yaml generate [screenplay].json --tts-provider [provider]\u003C/code> command creates a template with:\u003C/p>\n\u003Col>\n\u003Cli>An entry for each speaker\u003C/li>\n\u003Cli>Pre-populated \u003Ccode>provider\u003C/code> field\u003C/li>\n\u003Cli>Empty entries for each required provider field\u003C/li>\n\u003Cli>Speaker statistics to aid in casting each character\u003C/li>\n\u003Cli>(optional) Use \u003Ccode>--include-optional-fields\u003C/code> flag to also create empty entries for each optional field\u003C/li>\n\u003C/ol>\n\u003Cpre class=\"astro-code github-dark\" style=\"background-color:#24292e;color:#e1e4e8; overflow-x: auto;\" tabindex=\"0\" data-language=\"yaml\">\u003Ccode>\u003Cspan class=\"line\">\u003Cspan style=\"color:#6A737D\"># default: 1556 lines - Used for all non-dialogue pieces\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#6A737D\"># Total characters: 104244, Longest dialogue: 2082 characters\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#85E89D\">default\u003C/span>\u003Cspan style=\"color:#E1E4E8\">:\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#85E89D\">  provider\u003C/span>\u003Cspan style=\"color:#E1E4E8\">: \u003C/span>\u003Cspan style=\"color:#9ECBFF\">openai\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#85E89D\">  voice\u003C/span>\u003Cspan style=\"color:#E1E4E8\">:\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#6A737D\"># HARRY: 283 lines\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#6A737D\"># Total characters: 12181, Longest dialogue: 365 characters\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#85E89D\">HARRY\u003C/span>\u003Cspan style=\"color:#E1E4E8\">:\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#85E89D\">  provider\u003C/span>\u003Cspan style=\"color:#E1E4E8\">: \u003C/span>\u003Cspan style=\"color:#9ECBFF\">openai\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#85E89D\">  voice\u003C/span>\u003Cspan style=\"color:#E1E4E8\">:\u003C/span>\u003C/span>\u003C/code>\u003C/pre>\n\u003Ch2 id=\"multi-provider-workflow\">Multi-Provider Workflow\u003C/h2>\n\u003Ch3 id=\"step-1-generate-base-configuration\">Step 1: Generate Base Configuration\u003C/h3>\n\u003Cpre class=\"astro-code github-dark\" style=\"background-color:#24292e;color:#e1e4e8; overflow-x: auto;\" tabindex=\"0\" data-language=\"bash\">\u003Ccode>\u003Cspan class=\"line\">\u003Cspan style=\"color:#B392F0\">uv\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> run\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> sts-tts-provider-yaml\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> generate\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> input/[screenplay]/[screenplay].json\u003C/span>\u003C/span>\u003C/code>\u003C/pre>\n\u003Ch3 id=\"step-2-assign-tts-providers\">Step 2: Assign TTS Providers\u003C/h3>\n\u003Cp>Edit the generated YAML to assign providers to each speaker:\u003C/p>\n\u003Cpre class=\"astro-code github-dark\" style=\"background-color:#24292e;color:#e1e4e8; overflow-x: auto;\" tabindex=\"0\" data-language=\"yaml\">\u003Ccode>\u003Cspan class=\"line\">\u003Cspan style=\"color:#85E89D\">default\u003C/span>\u003Cspan style=\"color:#E1E4E8\">:\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#85E89D\">  provider\u003C/span>\u003Cspan style=\"color:#E1E4E8\">: \u003C/span>\u003Cspan style=\"color:#9ECBFF\">openai\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#85E89D\">HARRY\u003C/span>\u003Cspan style=\"color:#E1E4E8\">:\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#85E89D\">  provider\u003C/span>\u003Cspan style=\"color:#E1E4E8\">: \u003C/span>\u003Cspan style=\"color:#9ECBFF\">elevenlabs\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#85E89D\">LUNA\u003C/span>\u003Cspan style=\"color:#E1E4E8\">:\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#85E89D\">  provider\u003C/span>\u003Cspan style=\"color:#E1E4E8\">: \u003C/span>\u003Cspan style=\"color:#9ECBFF\">openai\u003C/span>\u003C/span>\u003C/code>\u003C/pre>\n\u003Ch3 id=\"step-3-populate-provider-fields\">Step 3: Populate Provider Fields\u003C/h3>\n\u003Cpre class=\"astro-code github-dark\" style=\"background-color:#24292e;color:#e1e4e8; overflow-x: auto;\" tabindex=\"0\" data-language=\"bash\">\u003Ccode>\u003Cspan class=\"line\">\u003Cspan style=\"color:#B392F0\">uv\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> run\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> sts-tts-provider-yaml\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> populate\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> input/[screenplay]/[screenplay].json\u003C/span>\u003Cspan style=\"color:#79B8FF\"> \\\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#9ECBFF\">  input/[screenplay]/[screenplay]_voice_config.yaml\u003C/span>\u003C/span>\u003C/code>\u003C/pre>\n\u003Cp>This creates \u003Ccode>[screenplay]_voice_config_populated.yaml\u003C/code> with provider-specific fields grouped:\u003C/p>\n\u003Cpre class=\"astro-code github-dark\" style=\"background-color:#24292e;color:#e1e4e8; overflow-x: auto;\" tabindex=\"0\" data-language=\"yaml\">\u003Ccode>\u003Cspan class=\"line\">\u003Cspan style=\"color:#6A737D\"># OpenAI Configuration\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#85E89D\">default\u003C/span>\u003Cspan style=\"color:#E1E4E8\">:\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#85E89D\">  provider\u003C/span>\u003Cspan style=\"color:#E1E4E8\">: \u003C/span>\u003Cspan style=\"color:#9ECBFF\">openai\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#85E89D\">  voice\u003C/span>\u003Cspan style=\"color:#E1E4E8\">:\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#85E89D\">LUNA\u003C/span>\u003Cspan style=\"color:#E1E4E8\">:\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#85E89D\">  provider\u003C/span>\u003Cspan style=\"color:#E1E4E8\">: \u003C/span>\u003Cspan style=\"color:#9ECBFF\">openai\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#85E89D\">  voice\u003C/span>\u003Cspan style=\"color:#E1E4E8\">:\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#6A737D\"># ElevenLabs Configuration\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#85E89D\">HARRY\u003C/span>\u003Cspan style=\"color:#E1E4E8\">:\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#85E89D\">  provider\u003C/span>\u003Cspan style=\"color:#E1E4E8\">: \u003C/span>\u003Cspan style=\"color:#9ECBFF\">elevenlabs\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#85E89D\">  voice_id\u003C/span>\u003Cspan style=\"color:#E1E4E8\">:\u003C/span>\u003C/span>\u003C/code>\u003C/pre>\n\u003Ch3 id=\"step-4-fill-in-provider-details\">Step 4: Fill in Provider Details\u003C/h3>\n\u003Cp>Complete the populated configuration with specific values:\u003C/p>\n\u003Cpre class=\"astro-code github-dark\" style=\"background-color:#24292e;color:#e1e4e8; overflow-x: auto;\" tabindex=\"0\" data-language=\"yaml\">\u003Ccode>\u003Cspan class=\"line\">\u003Cspan style=\"color:#6A737D\"># OpenAI Configuration\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#85E89D\">default\u003C/span>\u003Cspan style=\"color:#E1E4E8\">:\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#85E89D\">  provider\u003C/span>\u003Cspan style=\"color:#E1E4E8\">: \u003C/span>\u003Cspan style=\"color:#9ECBFF\">openai\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#85E89D\">  voice\u003C/span>\u003Cspan style=\"color:#E1E4E8\">: \u003C/span>\u003Cspan style=\"color:#9ECBFF\">onyx\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#85E89D\">LUNA\u003C/span>\u003Cspan style=\"color:#E1E4E8\">:\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#85E89D\">  provider\u003C/span>\u003Cspan style=\"color:#E1E4E8\">: \u003C/span>\u003Cspan style=\"color:#9ECBFF\">openai\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#85E89D\">  voice\u003C/span>\u003Cspan style=\"color:#E1E4E8\">: \u003C/span>\u003Cspan style=\"color:#9ECBFF\">alloy\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#6A737D\"># ElevenLabs Configuration\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#85E89D\">HARRY\u003C/span>\u003Cspan style=\"color:#E1E4E8\">:\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#85E89D\">  provider\u003C/span>\u003Cspan style=\"color:#E1E4E8\">: \u003C/span>\u003Cspan style=\"color:#9ECBFF\">elevenlabs\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#85E89D\">  voice_id\u003C/span>\u003Cspan style=\"color:#E1E4E8\">: \u003C/span>\u003Cspan style=\"color:#9ECBFF\">ErXwobaYiN019PkySvjV\u003C/span>\u003C/span>\u003C/code>\u003C/pre>\n\u003Ch3 id=\"step-5-validate-configuration\">Step 5: Validate Configuration\u003C/h3>\n\u003Cpre class=\"astro-code github-dark\" style=\"background-color:#24292e;color:#e1e4e8; overflow-x: auto;\" tabindex=\"0\" data-language=\"bash\">\u003Ccode>\u003Cspan class=\"line\">\u003Cspan style=\"color:#6A737D\"># Basic validation (checks for missing/extra/duplicate speakers)\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#B392F0\">uv\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> run\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> sts-tts-provider-yaml\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> validate\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> input/[screenplay]/[screenplay].json\u003C/span>\u003Cspan style=\"color:#79B8FF\"> \\\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#9ECBFF\">  input/[screenplay]/[screenplay]_voice_config.yaml\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#6A737D\"># Strict validation (also validates provider-specific fields)\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#B392F0\">uv\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> run\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> sts-tts-provider-yaml\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> validate\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> input/[screenplay]/[screenplay].json\u003C/span>\u003Cspan style=\"color:#79B8FF\"> \\\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#9ECBFF\">  input/[screenplay]/[screenplay]_voice_config.yaml\u003C/span>\u003Cspan style=\"color:#79B8FF\"> --strict\u003C/span>\u003C/span>\u003C/code>\u003C/pre>\n\u003Ch2 id=\"provider-specific-configuration\">Provider-Specific Configuration\u003C/h2>\n\u003Ch3 id=\"openai-configuration\">OpenAI Configuration\u003C/h3>\n\u003Cp>Required fields:\u003C/p>\n\u003Cul>\n\u003Cli>\u003Ccode>voice\u003C/code>: Voice identifier\u003C/li>\n\u003C/ul>\n\u003Cp>Available voices:\u003C/p>\n\u003Cul>\n\u003Cli>alloy\u003C/li>\n\u003Cli>ash\u003C/li>\n\u003Cli>coral\u003C/li>\n\u003Cli>echo\u003C/li>\n\u003Cli>fable\u003C/li>\n\u003Cli>onyx\u003C/li>\n\u003Cli>nova\u003C/li>\n\u003Cli>sage\u003C/li>\n\u003Cli>shimmer\u003C/li>\n\u003C/ul>\n\u003Cp>Example:\u003C/p>\n\u003Cpre class=\"astro-code github-dark\" style=\"background-color:#24292e;color:#e1e4e8; overflow-x: auto;\" tabindex=\"0\" data-language=\"yaml\">\u003Ccode>\u003Cspan class=\"line\">\u003Cspan style=\"color:#85E89D\">default\u003C/span>\u003Cspan style=\"color:#E1E4E8\">:\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#85E89D\">  provider\u003C/span>\u003Cspan style=\"color:#E1E4E8\">: \u003C/span>\u003Cspan style=\"color:#9ECBFF\">openai\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#85E89D\">  voice\u003C/span>\u003Cspan style=\"color:#E1E4E8\">: \u003C/span>\u003Cspan style=\"color:#9ECBFF\">onyx\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#85E89D\">NARRATOR\u003C/span>\u003Cspan style=\"color:#E1E4E8\">:\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#85E89D\">  provider\u003C/span>\u003Cspan style=\"color:#E1E4E8\">: \u003C/span>\u003Cspan style=\"color:#9ECBFF\">openai\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#85E89D\">  voice\u003C/span>\u003Cspan style=\"color:#E1E4E8\">: \u003C/span>\u003Cspan style=\"color:#9ECBFF\">alloy\u003C/span>\u003C/span>\u003C/code>\u003C/pre>\n\u003Ch3 id=\"elevenlabs-configuration\">ElevenLabs Configuration\u003C/h3>\n\u003Cp>Required fields:\u003C/p>\n\u003Cul>\n\u003Cli>\u003Ccode>voice_id\u003C/code>: Public library voice ID\u003C/li>\n\u003C/ul>\n\u003Cp>Important notes:\u003C/p>\n\u003Cul>\n\u003Cli>Voice IDs must be from the \u003Ca href=\"https://elevenlabs.io/app/voice-library\">public voice library\u003C/a>, not the \u003Ca href=\"https://elevenlabs.io/app/voice-lab\">my voices library\u003C/a>\u003C/li>\n\u003Cli>Provider manages the 30 voice limit automatically by removing voices from “my voices” library when limit is reached\u003C/li>\n\u003Cli>Monthly add/remove operations are limited\u003C/li>\n\u003C/ul>\n\u003Cp>Example:\u003C/p>\n\u003Cpre class=\"astro-code github-dark\" style=\"background-color:#24292e;color:#e1e4e8; overflow-x: auto;\" tabindex=\"0\" data-language=\"yaml\">\u003Ccode>\u003Cspan class=\"line\">\u003Cspan style=\"color:#85E89D\">MARY\u003C/span>\u003Cspan style=\"color:#E1E4E8\">:\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#85E89D\">  provider\u003C/span>\u003Cspan style=\"color:#E1E4E8\">: \u003C/span>\u003Cspan style=\"color:#9ECBFF\">elevenlabs\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#85E89D\">  voice_id\u003C/span>\u003Cspan style=\"color:#E1E4E8\">: \u003C/span>\u003Cspan style=\"color:#9ECBFF\">IKne3meq5aSn9XLyUdCD\u003C/span>\u003Cspan style=\"color:#6A737D\">  # Public library ID\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#85E89D\">JOHN\u003C/span>\u003Cspan style=\"color:#E1E4E8\">:\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#85E89D\">  provider\u003C/span>\u003Cspan style=\"color:#E1E4E8\">: \u003C/span>\u003Cspan style=\"color:#9ECBFF\">elevenlabs\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#85E89D\">  voice_id\u003C/span>\u003Cspan style=\"color:#E1E4E8\">: \u003C/span>\u003Cspan style=\"color:#9ECBFF\">ErXwobaYiN019PkySvjV\u003C/span>\u003Cspan style=\"color:#6A737D\">  # Public library ID\u003C/span>\u003C/span>\u003C/code>\u003C/pre>\n\u003Ch3 id=\"cartesia-configuration\">Cartesia Configuration\u003C/h3>\n\u003Cp>Required fields:\u003C/p>\n\u003Cul>\n\u003Cli>\u003Ccode>voice_id\u003C/code>: one of 9 available voices\nVoices and theird IDs can be found at the \u003Ca href=\"https://play.cartesia.ai/\">Cartesia Playground\u003C/a>\u003C/li>\n\u003C/ul>\n\u003Cp>Optional fields\u003C/p>\n\u003Cul>\n\u003Cli>\u003Ccode>language\u003C/code>: One of [en,fr,de,es,pt,zh,ja,hi,it,ko,nl,pl,ru,sv,tr]\u003C/li>\n\u003Cli>\u003Ccode>speed\u003C/code>: One of [“slow”, “normal”, “fast”]\n\u003Cul>\n\u003Cli>\u003Cem>note: this is an experimental feature that doesn’t work for all voices\u003C/em>\u003C/li>\n\u003C/ul>\n\u003C/li>\n\u003C/ul>\n\u003Cp>Example:\u003C/p>\n\u003Cpre class=\"astro-code github-dark\" style=\"background-color:#24292e;color:#e1e4e8; overflow-x: auto;\" tabindex=\"0\" data-language=\"yaml\">\u003Ccode>\u003Cspan class=\"line\">\u003Cspan style=\"color:#85E89D\">BECCA\u003C/span>\u003Cspan style=\"color:#E1E4E8\">:\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#85E89D\">  provider\u003C/span>\u003Cspan style=\"color:#E1E4E8\">: \u003C/span>\u003Cspan style=\"color:#9ECBFF\">cartesia\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#85E89D\">  voice_id\u003C/span>\u003Cspan style=\"color:#E1E4E8\">: \u003C/span>\u003Cspan style=\"color:#9ECBFF\">bf0a246a-8642-498a-9950-80c35e9276b5\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#85E89D\">  speed\u003C/span>\u003Cspan style=\"color:#E1E4E8\">: \u003C/span>\u003Cspan style=\"color:#9ECBFF\">fast\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#85E89D\">  language\u003C/span>\u003Cspan style=\"color:#E1E4E8\">: \u003C/span>\u003Cspan style=\"color:#9ECBFF\">fr\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#85E89D\">TOM\u003C/span>\u003Cspan style=\"color:#E1E4E8\">:\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#85E89D\">  provider\u003C/span>\u003Cspan style=\"color:#E1E4E8\">: \u003C/span>\u003Cspan style=\"color:#9ECBFF\">cartesia\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#85E89D\">  voice_id\u003C/span>\u003Cspan style=\"color:#E1E4E8\">: \u003C/span>\u003Cspan style=\"color:#9ECBFF\">4df027cb-2920-4a1f-8c34-f21529d5c3fe\u003C/span>\u003C/span>\u003C/code>\u003C/pre>\n\u003Ch3 id=\"minimax-configuration\">Minimax Configuration\u003C/h3>\n\u003Cp>Required fields:\u003C/p>\n\u003Cul>\n\u003Cli>\u003Ccode>voice_id\u003C/code>: One of 17 available system voices\u003C/li>\n\u003C/ul>\n\u003Cp>Available voices:\u003C/p>\n\u003Cul>\n\u003Cli>English_expressive_narrator\u003C/li>\n\u003Cli>English_radiant_girl\u003C/li>\n\u003Cli>English_magnetic_voiced_man\u003C/li>\n\u003Cli>English_compelling_lady1\u003C/li>\n\u003Cli>English_Aussie_Bloke\u003C/li>\n\u003Cli>English_captivating_female1\u003C/li>\n\u003Cli>English_Upbeat_Woman\u003C/li>\n\u003Cli>English_Trustworth_Man\u003C/li>\n\u003Cli>English_CalmWoman\u003C/li>\n\u003Cli>English_UpsetGirl\u003C/li>\n\u003Cli>English_Gentle-voiced_man\u003C/li>\n\u003Cli>English_Whispering_girl_v3\u003C/li>\n\u003Cli>English_Diligent_Man\u003C/li>\n\u003Cli>English_Graceful_Lady\u003C/li>\n\u003Cli>English_ReservedYoungMan\u003C/li>\n\u003Cli>English_PlayfulGirl\u003C/li>\n\u003Cli>English_ManWithDeepVoice\u003C/li>\n\u003Cli>English_GentleTeacher\u003C/li>\n\u003Cli>English_MaturePartner\u003C/li>\n\u003Cli>English_FriendlyPerson\u003C/li>\n\u003Cli>English_MatureBoss\u003C/li>\n\u003Cli>English_Debator\u003C/li>\n\u003Cli>English_Abbess\u003C/li>\n\u003Cli>English_LovelyGirl\u003C/li>\n\u003Cli>English_Steadymentor\u003C/li>\n\u003Cli>English_Deep-VoicedGentleman\u003C/li>\n\u003Cli>English_DeterminedMan\u003C/li>\n\u003Cli>English_Wiselady\u003C/li>\n\u003Cli>English_CaptivatingStoryteller\u003C/li>\n\u003Cli>English_AttractiveGirl\u003C/li>\n\u003Cli>English_DecentYoungMan\u003C/li>\n\u003Cli>English_SentimentalLady\u003C/li>\n\u003Cli>English_ImposingManner\u003C/li>\n\u003Cli>English_SadTeen\u003C/li>\n\u003Cli>English_ThoughtfulMan\u003C/li>\n\u003Cli>English_PassionateWarrior\u003C/li>\n\u003Cli>English_DecentBoy\u003C/li>\n\u003Cli>English_WiseScholar\u003C/li>\n\u003Cli>English_Soft-spokenGirl\u003C/li>\n\u003Cli>English_SereneWoman\u003C/li>\n\u003Cli>English_ConfidentWoman\u003C/li>\n\u003Cli>English_patient_man_v1\u003C/li>\n\u003Cli>English_Comedian\u003C/li>\n\u003Cli>English_GorgeousLady\u003C/li>\n\u003Cli>English_BossyLeader\u003C/li>\n\u003Cli>English_LovelyLady\u003C/li>\n\u003Cli>English_Strong-WilledBoy\u003C/li>\n\u003Cli>English_Deep-tonedMan\u003C/li>\n\u003Cli>English_StressedLady\u003C/li>\n\u003Cli>English_AssertiveQueen\u003C/li>\n\u003Cli>English_AnimeCharacter\u003C/li>\n\u003Cli>English_Jovialman\u003C/li>\n\u003Cli>English_WhimsicalGirl\u003C/li>\n\u003Cli>English_CharmingQueen\u003C/li>\n\u003Cli>English_Kind-heartedGirl\u003C/li>\n\u003Cli>English_FriendlyNeighbor\u003C/li>\n\u003Cli>English_Sweet_Female_4\u003C/li>\n\u003Cli>English_Magnetic_Male_2\u003C/li>\n\u003Cli>English_Lively_Male_11\u003C/li>\n\u003Cli>English_Friendly_Female_3\u003C/li>\n\u003Cli>English_Steady_Female_1\u003C/li>\n\u003Cli>English_Lively_Male_10\u003C/li>\n\u003Cli>English_Magnetic_Male_12\u003C/li>\n\u003Cli>English_Steady_Female_5\u003C/li>\n\u003C/ul>\n\u003Cp>Optional fields:\u003C/p>\n\u003Cul>\n\u003Cli>\u003Ccode>voice_mix\u003C/code>: List of voice blends (1-4 items), each with:\n\u003Cul>\n\u003Cli>\u003Ccode>voice_id\u003C/code>: One of the 17 system voices\u003C/li>\n\u003Cli>\u003Ccode>weight\u003C/code>: Integer between 1-100\u003C/li>\n\u003Cli>Note: If provided, takes precedence over the top-level \u003Ccode>voice_id\u003C/code>. Only one of \u003Ccode>voice_id\u003C/code> or \u003Ccode>voice_mix\u003C/code> can be supplied\u003C/li>\n\u003C/ul>\n\u003C/li>\n\u003Cli>\u003Ccode>speed\u003C/code>: (default: 1.0) Float between 0.5-2.0\u003C/li>\n\u003Cli>\u003Ccode>volume\u003C/code>: (default: 1.0) Float between >0.0-10.0\u003C/li>\n\u003Cli>\u003Ccode>pitch\u003C/code>: (default: 0) Integer between -12 to 12\u003C/li>\n\u003Cli>\u003Ccode>emotion\u003C/code>: One of [“happy”, “sad”, “angry”, “fear”, “disgust”, “neutral”, “surprise”]\u003C/li>\n\u003Cli>\u003Ccode>english_normalization\u003C/code>: (default: true) Boolean (true/false)\u003C/li>\n\u003Cli>\u003Ccode>language_boost\u003C/code>: (default: “English”) One of [“Chinese”, “English”, “Japanese”, “Korean”, “French”, “Spanish”, “German”]\u003C/li>\n\u003C/ul>\n\u003Cp>Example (with voice_id):\u003C/p>\n\u003Cpre class=\"astro-code github-dark\" style=\"background-color:#24292e;color:#e1e4e8; overflow-x: auto;\" tabindex=\"0\" data-language=\"yaml\">\u003Ccode>\u003Cspan class=\"line\">\u003Cspan style=\"color:#85E89D\">DAVID\u003C/span>\u003Cspan style=\"color:#E1E4E8\">:\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#85E89D\">  provider\u003C/span>\u003Cspan style=\"color:#E1E4E8\">: \u003C/span>\u003Cspan style=\"color:#9ECBFF\">minimax\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#85E89D\">  voice_id\u003C/span>\u003Cspan style=\"color:#E1E4E8\">: \u003C/span>\u003Cspan style=\"color:#9ECBFF\">Calm_Woman\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#85E89D\">  speed\u003C/span>\u003Cspan style=\"color:#E1E4E8\">: \u003C/span>\u003Cspan style=\"color:#79B8FF\">1.2\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#85E89D\">  volume\u003C/span>\u003Cspan style=\"color:#E1E4E8\">: \u003C/span>\u003Cspan style=\"color:#79B8FF\">8.0\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#85E89D\">  pitch\u003C/span>\u003Cspan style=\"color:#E1E4E8\">: \u003C/span>\u003Cspan style=\"color:#79B8FF\">2\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#85E89D\">  emotion\u003C/span>\u003Cspan style=\"color:#E1E4E8\">: \u003C/span>\u003Cspan style=\"color:#9ECBFF\">happy\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#85E89D\">  english_normalization\u003C/span>\u003Cspan style=\"color:#E1E4E8\">: \u003C/span>\u003Cspan style=\"color:#79B8FF\">false\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#85E89D\">  language_boost\u003C/span>\u003Cspan style=\"color:#E1E4E8\">: \u003C/span>\u003Cspan style=\"color:#9ECBFF\">Spanish\u003C/span>\u003C/span>\u003C/code>\u003C/pre>\n\u003Cp>Example (with voice_mix):\u003C/p>\n\u003Cpre class=\"astro-code github-dark\" style=\"background-color:#24292e;color:#e1e4e8; overflow-x: auto;\" tabindex=\"0\" data-language=\"yaml\">\u003Ccode>\u003Cspan class=\"line\">\u003Cspan style=\"color:#85E89D\">MARIA\u003C/span>\u003Cspan style=\"color:#E1E4E8\">:\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#85E89D\">  provider\u003C/span>\u003Cspan style=\"color:#E1E4E8\">: \u003C/span>\u003Cspan style=\"color:#9ECBFF\">minimax\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#85E89D\">  voice_mix\u003C/span>\u003Cspan style=\"color:#E1E4E8\">:\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#E1E4E8\">    - \u003C/span>\u003Cspan style=\"color:#85E89D\">voice_id\u003C/span>\u003Cspan style=\"color:#E1E4E8\">: \u003C/span>\u003Cspan style=\"color:#9ECBFF\">Patient_Man\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#85E89D\">      weight\u003C/span>\u003Cspan style=\"color:#E1E4E8\">: \u003C/span>\u003Cspan style=\"color:#79B8FF\">70\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#E1E4E8\">    - \u003C/span>\u003Cspan style=\"color:#85E89D\">voice_id\u003C/span>\u003Cspan style=\"color:#E1E4E8\">: \u003C/span>\u003Cspan style=\"color:#9ECBFF\">Young_Knight\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#85E89D\">      weight\u003C/span>\u003Cspan style=\"color:#E1E4E8\">: \u003C/span>\u003Cspan style=\"color:#79B8FF\">30\u003C/span>\u003C/span>\u003C/code>\u003C/pre>\n\u003Ch3 id=\"zonos-configuration\">Zonos Configuration\u003C/h3>\n\u003Cp>Required fields:\u003C/p>\n\u003Cul>\n\u003Cli>\u003Ccode>default_voice_name\u003C/code>: one of 9 available voices\u003C/li>\n\u003C/ul>\n\u003Cp>Available voices:\u003C/p>\n\u003Cul>\n\u003Cli>american_female\u003C/li>\n\u003Cli>american_male\u003C/li>\n\u003Cli>anime_girl\u003C/li>\n\u003Cli>british_female\u003C/li>\n\u003Cli>british_male\u003C/li>\n\u003Cli>energetic_boy\u003C/li>\n\u003Cli>energetic_girl\u003C/li>\n\u003Cli>japanese_female\u003C/li>\n\u003Cli>japanese_male\u003C/li>\n\u003C/ul>\n\u003Cp>Optional fields:\u003C/p>\n\u003Cul>\n\u003Cli>\u003Ccode>speaking_rate\u003C/code>: Float between 5 and 35\u003C/li>\n\u003Cli>\u003Ccode>language_iso_code\u003C/code>: One of [en-us, fr-fr, de, ja, ko, cmn]\u003C/li>\n\u003C/ul>\n\u003Cp>Example:\u003C/p>\n\u003Cpre class=\"astro-code github-dark\" style=\"background-color:#24292e;color:#e1e4e8; overflow-x: auto;\" tabindex=\"0\" data-language=\"yaml\">\u003Ccode>\u003Cspan class=\"line\">\u003Cspan style=\"color:#85E89D\">ROBOT\u003C/span>\u003Cspan style=\"color:#E1E4E8\">:\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#85E89D\">  provider\u003C/span>\u003Cspan style=\"color:#E1E4E8\">: \u003C/span>\u003Cspan style=\"color:#9ECBFF\">zonos\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#85E89D\">  default_voice_name\u003C/span>\u003Cspan style=\"color:#E1E4E8\">: \u003C/span>\u003Cspan style=\"color:#9ECBFF\">american_female\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#85E89D\">  speaking_rate\u003C/span>\u003Cspan style=\"color:#E1E4E8\">: \u003C/span>\u003Cspan style=\"color:#79B8FF\">20\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#85E89D\">  language_iso_code\u003C/span>\u003Cspan style=\"color:#E1E4E8\">: \u003C/span>\u003Cspan style=\"color:#9ECBFF\">en-us\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#85E89D\">ALIEN\u003C/span>\u003Cspan style=\"color:#E1E4E8\">:\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#85E89D\">  provider\u003C/span>\u003Cspan style=\"color:#E1E4E8\">: \u003C/span>\u003Cspan style=\"color:#9ECBFF\">zonos\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#85E89D\">  default_voice_name\u003C/span>\u003Cspan style=\"color:#E1E4E8\">: \u003C/span>\u003Cspan style=\"color:#9ECBFF\">american_male\u003C/span>\u003C/span>\u003C/code>\u003C/pre>\n\u003Ch2 id=\"rate-limiting\">Rate Limiting\u003C/h2>\n\u003Ch3 id=\"automatic-handling\">Automatic Handling\u003C/h3>\n\u003Cp>The system automatically handles rate limits with:\u003C/p>\n\u003Cul>\n\u003Cli>Exponential backoff\u003C/li>\n\u003Cli>Provider-specific retry logic\u003C/li>\n\u003Cli>Queue management\u003C/li>\n\u003C/ul>\n\u003Cp>When rate limited, the system will:\u003C/p>\n\u003Col>\n\u003Cli>Pause requests for that provider\u003C/li>\n\u003Cli>Continue with other TTS providers\u003C/li>\n\u003Cli>Retry after backoff period\u003C/li>\n\u003C/ol>\n\u003Ch2 id=\"provider-architecture\">Provider Architecture\u003C/h2>\n\u003Cp>The Script to Speech system supports two types of TTS providers: stateless and stateful. Understanding the difference is important for creating custom providers.\u003C/p>\n\u003Ch3 id=\"stateless-vs-stateful-tts-providers\">Stateless vs. Stateful TTS Providers\u003C/h3>\n\u003Ch4 id=\"stateless-tts-providers\">Stateless TTS Providers\u003C/h4>\n\u003Cul>\n\u003Cli>\u003Cstrong>Definition\u003C/strong>: Providers that don’t maintain state between API calls\u003C/li>\n\u003Cli>\u003Cstrong>Implementation\u003C/strong>: Use class methods to generate audio\u003C/li>\n\u003Cli>\u003Cstrong>Examples\u003C/strong>: OpenAI, Zonos\u003C/li>\n\u003Cli>\u003Cstrong>Advantages\u003C/strong>:\n\u003Cul>\n\u003Cli>Simpler to implement\u003C/li>\n\u003Cli>Thread-safe without additional code\u003C/li>\n\u003Cli>More predictable behavior\u003C/li>\n\u003Cli>Easier to debug\u003C/li>\n\u003C/ul>\n\u003C/li>\n\u003Cli>\u003Cstrong>When to use\u003C/strong>: Default choice for most providers\u003C/li>\n\u003C/ul>\n\u003Ch4 id=\"stateful-tts-providers\">Stateful TTS Providers\u003C/h4>\n\u003Cul>\n\u003Cli>\u003Cstrong>Definition\u003C/strong>: Providers that maintain state between API calls\u003C/li>\n\u003Cli>\u003Cstrong>Implementation\u003C/strong>: Same class methods as Stateless provider, except for instance-based \u003Ccode>__init__\u003C/code> and \u003Ccode>generate_audio\u003C/code> methods\u003C/li>\n\u003Cli>\u003Cstrong>Examples\u003C/strong>: ElevenLabs (for voice registry management)\u003C/li>\n\u003Cli>\u003Cstrong>Advantages\u003C/strong>:\n\u003Cul>\n\u003Cli>Can cache / configure information between calls\u003C/li>\n\u003Cli>Can implement complex state machines\u003C/li>\n\u003C/ul>\n\u003C/li>\n\u003Cli>\u003Cstrong>When to use\u003C/strong>: Only when required by the API or when managing complex resources\u003C/li>\n\u003C/ul>\n\u003Ch3 id=\"provider-management\">Provider Management\u003C/h3>\n\u003Cp>The \u003Ccode>TTSProviderManager\u003C/code> handles:\u003C/p>\n\u003Cul>\n\u003Cli>\u003Cstrong>Lazy Initialization\u003C/strong>: TTS providers are only initialized when needed\u003C/li>\n\u003Cli>\u003Cstrong>Thread Safety\u003C/strong>: Thread locks protect provider initialization and state\u003C/li>\n\u003Cli>\u003Cstrong>Client Caching\u003C/strong>: API clients are reused across calls\u003C/li>\n\u003Cli>\u003Cstrong>Multi-threading\u003C/strong>: Each provider has its own download concurrency settings\u003C/li>\n\u003C/ul>\n\u003Ch2 id=\"creating-custom-tts-providers\">Creating Custom TTS Providers\u003C/h2>\n\u003Ch3 id=\"base-classes\">Base Classes\u003C/h3>\n\u003Cp>All TTS providers implement one of two base classes:\u003C/p>\n\u003Col>\n\u003Cli>\n\u003Cp>\u003Ccode>StatelessTTSProviderBase\u003C/code>\u003C/p>\n\u003Cul>\n\u003Cli>For TTS providers without state\u003C/li>\n\u003Cli>Uses class methods\u003C/li>\n\u003C/ul>\n\u003C/li>\n\u003Cli>\n\u003Cp>\u003Ccode>StatefulTTSProviderBase\u003C/code>\u003C/p>\n\u003Cul>\n\u003Cli>For TTS providers with state\u003C/li>\n\u003Cli>Uses instance methods and \u003Ccode>__init__\u003C/code>\u003C/li>\n\u003C/ul>\n\u003C/li>\n\u003C/ol>\n\u003Cp>Both inherit from \u003Ccode>TTSProviderCommonMixin\u003C/code> which defines common requirements.\u003C/p>\n\u003Ch3 id=\"adding-a-new-provider\">Adding a New Provider\u003C/h3>\n\u003Col>\n\u003Cli>Create a directory in \u003Ccode>src/script_to_speech/tts_providers/\u003C/code> with your provider name\u003C/li>\n\u003Cli>Create a \u003Ccode>tts_provider.py\u003C/code> file in that directory\u003C/li>\n\u003Cli>Implement the appropriate base class\u003C/li>\n\u003Cli>Return the correct provider identifier via \u003Ccode>get_provider_identifier()\u003C/code>\u003C/li>\n\u003C/ol>\n\u003Cp>The provider will be automatically discovered and available in configurations.\u003C/p>\n\u003Ch3 id=\"examples\">Examples\u003C/h3>\n\u003Cul>\n\u003Cli>For an example of a stateless provider, see the \u003Ca href=\"../src/script_to_speech/tts_providers/openai/tts_provider.py\">OpenAI TTS Provider\u003C/a>\u003C/li>\n\u003Cli>For an example of a stateful provider, see the \u003Ca href=\"../src/script_to_speech/tts_providers/elevenlabs/tts_provider.py\">ElevenLabs TTS Provider\u003C/a> and accompanying \u003Ca href=\"src/script_to_speech/tts_providers/elevenlabs/voice_registry_manager.py\">ElevenLabs Voice Registry Manager\u003C/a>\u003C/li>\n\u003C/ul>\n\u003Ch3 id=\"provider-requirements\">Provider Requirements\u003C/h3>\n\u003Cp>Required methods:\u003C/p>\n\u003Cul>\n\u003Cli>\u003Ccode>get_provider_identifier()\u003C/code>: Unique identifier for this provider; will be used in YAML configuration and whenever this provider is being called on the command line\u003C/li>\n\u003Cli>\u003Ccode>get_speaker_identifier()\u003C/code>: Unique identifier for a given speaker, given a speaker configuration. This is used in caching, so \u003Cstrong>changing any configuration option for a speaker (e.g. optional fields) should also change the returned \u003Ccode>speaker_identifier\u003C/code>\u003C/strong>\u003C/li>\n\u003Cli>\u003Ccode>instantiate_client()\u003C/code>: Create the API client that will be passed to \u003Ccode>generate_audio\u003C/code> method by the \u003Ccode>TTSProviderManager\u003C/code>\u003C/li>\n\u003Cli>\u003Ccode>generate_audio()\u003C/code>: Request the audio from the TTS Provider API; return bytes representing the audio\u003C/li>\n\u003Cli>\u003Ccode>get_required_fields()\u003C/code>: Required configuration fields\u003C/li>\n\u003Cli>\u003Ccode>validate_speaker_config()\u003C/code>: Logic to validate configuration (checking for required fields, that they’re the right type, etc.)\u003C/li>\n\u003Cli>\u003Ccode>get_yaml_instructions()\u003C/code>: Configuration help text outlining required / optional fields, best practices, etc.\u003C/li>\n\u003C/ul>\n\u003Cp>Optional methods:\u003C/p>\n\u003Cul>\n\u003Cli>\u003Ccode>get_optional_fields()\u003C/code>: Optional configuration fields\u003C/li>\n\u003Cli>\u003Ccode>get_max_download_threads()\u003C/code>: Concurrent thread limit; defaults to 1\u003C/li>\n\u003C/ul>\n\u003Ch2 id=\"best-practices\">Best Practices\u003C/h2>\n\u003Ch3 id=\"configuration-management\">Configuration Management\u003C/h3>\n\u003Col>\n\u003Cli>Use the generate → assign → populate workflow\u003C/li>\n\u003Cli>Keep backup configurations for different voice setups\u003C/li>\n\u003Cli>Consider character type when assigning TTS providers\u003C/li>\n\u003Cli>Validate configurations with \u003Ccode>sts-tts-provider-yaml validate\u003C/code>\u003C/li>\n\u003C/ol>\n\u003Ch3 id=\"multi-provider-benefits\">Multi-Provider Benefits\u003C/h3>\n\u003Col>\n\u003Cli>\u003Cstrong>Speed\u003C/strong>: Parallel processing across TTS providers\u003C/li>\n\u003Cli>\u003Cstrong>Cost\u003C/strong>: Optimize per-provider pricing\u003C/li>\n\u003Cli>\u003Cstrong>Quality\u003C/strong>: Match voice types to character needs\u003C/li>\n\u003C/ol>\n\u003Ch2 id=\"troubleshooting\">Troubleshooting\u003C/h2>\n\u003Ch3 id=\"common-issues\">Common Issues\u003C/h3>\n\u003Col>\n\u003Cli>\n\u003Cp>\u003Cstrong>API Key Errors\u003C/strong>\u003C/p>\n\u003Cpre class=\"astro-code github-dark\" style=\"background-color:#24292e;color:#e1e4e8; overflow-x: auto;\" tabindex=\"0\" data-language=\"bash\">\u003Ccode>\u003Cspan class=\"line\">\u003Cspan style=\"color:#6A737D\"># Check environment variables\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#79B8FF\">echo\u003C/span>\u003Cspan style=\"color:#E1E4E8\"> $OPENAI_API_KEY\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#79B8FF\">echo\u003C/span>\u003Cspan style=\"color:#E1E4E8\"> $ELEVEN_API_KEY\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#79B8FF\">echo\u003C/span>\u003Cspan style=\"color:#E1E4E8\"> $CARTESIA_API_KEY\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#79B8FF\">echo\u003C/span>\u003Cspan style=\"color:#E1E4E8\"> $MINIMAX_API_KEY\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#79B8FF\">echo\u003C/span>\u003Cspan style=\"color:#E1E4E8\"> $MINIMAX_GROUP_ID\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#79B8FF\">echo\u003C/span>\u003Cspan style=\"color:#E1E4E8\"> $ZONOS_API_KEY\u003C/span>\u003C/span>\u003C/code>\u003C/pre>\n\u003C/li>\n\u003Cli>\n\u003Cp>\u003Cstrong>Voice Configuration Validation\u003C/strong>\u003C/p>\n\u003Cpre class=\"astro-code github-dark\" style=\"background-color:#24292e;color:#e1e4e8; overflow-x: auto;\" tabindex=\"0\" data-language=\"bash\">\u003Ccode>\u003Cspan class=\"line\">\u003Cspan style=\"color:#6A737D\"># Check for missing/extra/duplicate speakers\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#B392F0\">uv\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> run\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> sts-tts-provider-yaml\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> validate\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> script.json\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> config.yaml\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#6A737D\"># Strict validation including provider field validation\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#B392F0\">uv\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> run\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> sts-tts-provider-yaml\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> validate\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> script.json\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> config.yaml\u003C/span>\u003Cspan style=\"color:#79B8FF\"> --strict\u003C/span>\u003C/span>\u003C/code>\u003C/pre>\n\u003C/li>\n\u003Cli>\n\u003Cp>\u003Cstrong>Voice Not Found\u003C/strong>\u003C/p>\n\u003Cul>\n\u003Cli>ElevenLabs: Ensure voice ID is from public library\u003C/li>\n\u003Cli>OpenAI: Verify voice name matches available options\u003C/li>\n\u003Cli>Minimax: Verify voice_id is one of the specified system voices\u003C/li>\n\u003Cli>Minimax: Check voice_mix structure if using voice mixing\u003C/li>\n\u003Cli>Zonos: Check default_voice_name is a valid voice\u003C/li>\n\u003C/ul>\n\u003C/li>\n\u003Cli>\n\u003Cp>\u003Cstrong>Rate Limiting\u003C/strong>\u003C/p>\n\u003Cul>\n\u003Cli>Check provider-specific rate limits\u003C/li>\n\u003Cli>Limit global concurrent downloads with \u003Ccode>--max-workers\u003C/code> run mode modifier\u003C/li>\n\u003Cli>Distribute voices across TTS providers\u003C/li>\n\u003Cli>Monitor monthly quotas for voice adds / removes (ElevenLabs)\u003C/li>\n\u003C/ul>\n\u003C/li>\n\u003Cli>\n\u003Cp>\u003Cstrong>Quality Issues\u003C/strong>\u003C/p>\n\u003Cul>\n\u003Cli>OpenAI: Try different voices for different character types\u003C/li>\n\u003Cli>ElevenLabs: Use “narrative”/“conversational” tagged voices\u003C/li>\n\u003Cli>Minimax: Experiment with voice_mix for unique character voices\u003C/li>\n\u003Cli>Minimax: Adjust emotion, speed, and pitch parameters for expressiveness\u003C/li>\n\u003Cli>Zonos: Adjust speaking rate parameter\u003C/li>\n\u003C/ul>\n\u003C/li>\n\u003C/ol>\n\u003Ch3 id=\"debugging\">Debugging\u003C/h3>\n\u003Cpre class=\"astro-code github-dark\" style=\"background-color:#24292e;color:#e1e4e8; overflow-x: auto;\" tabindex=\"0\" data-language=\"bash\">\u003Ccode>\u003Cspan class=\"line\">\u003Cspan style=\"color:#6A737D\"># Test single line of dialogue\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#B392F0\">uv\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> run\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> sts-generate-standalone-speech\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> openai\u003C/span>\u003Cspan style=\"color:#79B8FF\"> --voice\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> echo\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> \"Test text\"\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#6A737D\"># Validate voice configuration against script\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#B392F0\">uv\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> run\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> sts-tts-provider-yaml\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> validate\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> input/script.json\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> config.yaml\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#6A737D\"># Strict validation including provider field validation\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#B392F0\">uv\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> run\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> sts-tts-provider-yaml\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> validate\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> input/script.json\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> config.yaml\u003C/span>\u003Cspan style=\"color:#79B8FF\"> --strict\u003C/span>\u003C/span>\u003C/code>\u003C/pre>",{"headings":173,"localImagePaths":299,"remoteImagePaths":300,"frontmatter":301,"imagePaths":302},[174,177,180,183,186,189,192,195,198,201,204,207,210,213,216,219,222,225,228,231,234,237,240,243,246,249,252,255,258,262,265,268,271,274,277,280,283,286,289,292,293,296],{"depth":22,"slug":175,"text":176},"tts-provider-guide","TTS Provider Guide",{"depth":26,"slug":178,"text":179},"supported-tts-providers","Supported TTS Providers",{"depth":30,"slug":181,"text":182},"openai","OpenAI",{"depth":30,"slug":184,"text":185},"elevenlabs","ElevenLabs",{"depth":30,"slug":187,"text":188},"cartesia","Cartesia",{"depth":30,"slug":190,"text":191},"minimax","Minimax",{"depth":30,"slug":193,"text":194},"zyphra-zonos-api-version","Zyphra Zonos (API version)",{"depth":30,"slug":196,"text":197},"dummy-testing-only","Dummy (Testing Only)",{"depth":26,"slug":199,"text":200},"environment-variables","Environment Variables",{"depth":26,"slug":202,"text":203},"configuration-structure","Configuration Structure",{"depth":30,"slug":205,"text":206},"provider-assignment","Provider Assignment",{"depth":30,"slug":208,"text":209},"generated-configuration-single-provider-workflow","Generated Configuration (Single Provider Workflow)",{"depth":26,"slug":211,"text":212},"multi-provider-workflow","Multi-Provider Workflow",{"depth":30,"slug":214,"text":215},"step-1-generate-base-configuration","Step 1: Generate Base Configuration",{"depth":30,"slug":217,"text":218},"step-2-assign-tts-providers","Step 2: Assign TTS Providers",{"depth":30,"slug":220,"text":221},"step-3-populate-provider-fields","Step 3: Populate Provider Fields",{"depth":30,"slug":223,"text":224},"step-4-fill-in-provider-details","Step 4: Fill in Provider Details",{"depth":30,"slug":226,"text":227},"step-5-validate-configuration","Step 5: Validate Configuration",{"depth":26,"slug":229,"text":230},"provider-specific-configuration","Provider-Specific Configuration",{"depth":30,"slug":232,"text":233},"openai-configuration","OpenAI Configuration",{"depth":30,"slug":235,"text":236},"elevenlabs-configuration","ElevenLabs Configuration",{"depth":30,"slug":238,"text":239},"cartesia-configuration","Cartesia Configuration",{"depth":30,"slug":241,"text":242},"minimax-configuration","Minimax Configuration",{"depth":30,"slug":244,"text":245},"zonos-configuration","Zonos Configuration",{"depth":26,"slug":247,"text":248},"rate-limiting","Rate Limiting",{"depth":30,"slug":250,"text":251},"automatic-handling","Automatic Handling",{"depth":26,"slug":253,"text":254},"provider-architecture","Provider Architecture",{"depth":30,"slug":256,"text":257},"stateless-vs-stateful-tts-providers","Stateless vs. Stateful TTS Providers",{"depth":259,"slug":260,"text":261},4,"stateless-tts-providers","Stateless TTS Providers",{"depth":259,"slug":263,"text":264},"stateful-tts-providers","Stateful TTS Providers",{"depth":30,"slug":266,"text":267},"provider-management","Provider Management",{"depth":26,"slug":269,"text":270},"creating-custom-tts-providers","Creating Custom TTS Providers",{"depth":30,"slug":272,"text":273},"base-classes","Base Classes",{"depth":30,"slug":275,"text":276},"adding-a-new-provider","Adding a New Provider",{"depth":30,"slug":278,"text":279},"examples","Examples",{"depth":30,"slug":281,"text":282},"provider-requirements","Provider Requirements",{"depth":26,"slug":284,"text":285},"best-practices","Best Practices",{"depth":30,"slug":287,"text":288},"configuration-management","Configuration Management",{"depth":30,"slug":290,"text":291},"multi-provider-benefits","Multi-Provider Benefits",{"depth":26,"slug":64,"text":65},{"depth":30,"slug":294,"text":295},"common-issues","Common Issues",{"depth":30,"slug":297,"text":298},"debugging","Debugging",[],[],{},[],"providers.md","readme",{"id":304,"data":306,"body":307,"filePath":308,"digest":309,"rendered":310,"legacyId":439},{},"# Script to Speech\n\nConvert screenplays into multi-voiced audiobooks using various Text-to-Speech (TTS) providers.\n\nScript to Speech is available in two versions:\n\n1.  **Desktop GUI (Experimental)**: A modern, easy-to-use desktop application. Recommended for new users.\n2.  **Command Line Interface (CLI)**: The core, feature-complete tool. Recommended for advanced users and automation.\n\n| Feature | Desktop GUI | CLI |\n| :--- | :--- | :--- |\n| **Ease of Use** | ⭐⭐⭐⭐⭐ | ⭐⭐ |\n| **Features** | Core Features | All Features |\n| **Stability** | Experimental | Stable |\n| **Documentation** | [GUI User Guide](docs/GUI_USER_GUIDE.md) | [CLI Documentation](#cli-usage) |\n\n---\n\n## Key Features\n\n- **Multi-provider support**: Use OpenAI, ElevenLabs, Cartesia, Minimax, Zonos, or custom TTS providers. TTS providers can be set at a per-speaker level\n- **Text processing pipeline**: Customize how text is processed before audio generation\n- **Multi-threaded downloads**: With separate queues per provider for faster generation\n- **Silence detection**: Identify and replace silent audio clips\n- **Cache system**: Resume interrupted generations and reuse audio. Change text / speaker assignments and only regenerte that specific audio\n- **Voice casting assistance**: Generate prompts for LLM-assisted character notes and voice library casting\n\n## Privacy & Data Handling\n\n**Script to Speech Privacy**: This tool operates entirely locally on your machine and collects no user data, has no telemetry, tracking, or analytics, and makes no network requests except to the services required for its core functionality.\n\n**Audio Generation**: To convert your screenplay text into speech, Script to Speech sends individual dialogue chunks to TTS providers (OpenAI, ElevenLabs, etc.) you configure. Each provider receives only the specific text being converted to audio.\n\n**Voice Casting (Optional)**: If you choose to use the LLM-assisted voice casting feature, your complete screenplay text and voice configuration are sent to the LLM service you select to generate casting recommendations.\n\n**Important**: Before using any TTS provider or LLM service, review their privacy policies, data retention practices, and training data policies to ensure they align with your privacy requirements.\n\nSee our [Privacy Policy](PRIVACY.md) for detailed information about data flows, recommendations for privacy-conscious usage, and contact information.\n\n---\n\n## CLI Usage\n\nThe following documentation covers the **Command Line Interface**. For GUI instructions, please see the [GUI User Guide](docs/GUI_USER_GUIDE.md).\n\n## CLI Commands\n\n| Command                           | Description                        |\n| --------------------------------- | ---------------------------------- |\n| `sts-parse-screenplay`            | Parse PDF/TXT to JSON chunks       |\n| `sts-detect-headers`              | Detect header/footer patterns in PDFs |\n| `sts-generate-audio`              | Generate audiobook from JSON       |\n| `sts-generate-standalone-speech`  | Create individual audio clips. See [Standalone Speech Generation](docs/STANDALONE_SPEECH.md) for more details. |\n| `sts-tts-provider-yaml`           | Generate/populate provider configs |\n| `sts-analyze-json`                | Analyze screenplay structure       |\n| `sts-apply-text-processors-json`  | Apply text transformations         |\n| `sts-parse-regression-check-json` | Validate parser output             |\n| `sts-generate-character-notes-prompt` | Generate LLM casting prompts   |\n| `sts-generate-voice-library-casting-prompt` | Generate voice library casting prompts |\n| `sts-copy-to-clipboard`           | Copy file contents to clipboard    |\n\n## Quick Start\n\n### Installation\n\n1. **Install UV** (package manager)\n\n   ```bash\n   pip install uv\n   ```\n\n   For alternate / more detailed UV installation instructions, see [UV's documentation](https://docs.astral.sh/uv/getting-started/installation/).\n\n2. **Create a copy of the project**\n   Either [download](https://github.com/trentw/script-to-speech/archive/refs/heads/master.zip) the project, or use git to clone it:\n   ```bash\n   git clone https://github.com/trentw/script-to-speech.git\n   cd script-to-speech\n   ```\n\n### For Basic Usage\n\nNo additional installation needed! UV will automatically install dependencies on first use.\n\n### For Development\n\nInstall the package in editable mode:\n\n```bash\nuv pip install -e \".[dev]\"\n```\n\n## Basic Workflow\n\n### Step 1: Setup Accounts with TTS Services and Configure\nGet an API key from at least one of the supported providers listed in the [TTS Providers documentation](docs/TTS_PROVIDERS.md) and add it to the project\n\n```bash\n# OpenAI\nexport OPENAI_API_KEY=\"your-api-key\"\n\n# ElevenLabs\nexport ELEVEN_API_KEY=\"your-api-key\"\n\n# Cartesia\nexport CARTESIA_API_KEY=\"your-api-key\"\n\n# Minimax\nexport MINIMAX_API_KEY=\"your-api-key\"\nexport MINIMAX_GROUP_ID=\"your-group-id\"\n\n# Zonos\nexport ZONOS_API_KEY=\"your-api-key\"\n```\n\n### Step 2: Add Screenplay\n\nPlace your screenplay PDF in the `source_screenplays` directory.\n\n### Step 3: Parse Screenplay\n\n```bash\n# Parse PDF to JSON dialogue chunks\nuv run sts-parse-screenplay source_screenplays/your_script.pdf\n```\n\nThis creates:\n\n- `input/your_script/your_script.pdf` (copy of original)\n- `input/your_script/your_script.json` (parsed dialogue chunks)\n- `input/your_script/your_script_optional_config.yaml` (configuration file to set values like ID3 tags for .mp3 file)\n\n### Step 4: Generate TTS Provider Configuration\n\n```bash\n# Generate YAML config for a single provider\nuv run sts-tts-provider-yaml generate input/your_script/your_script.json --tts-provider openai\n```\n\nThis creates `input/your_script/your_script_voice_config.yaml`\n\n### Step 5: Configure Voices\n\nEdit the generated YAML file to assign voices to speakers (note that \"default\" is used for any items without an explicit speaker defined, such as scene headers, action lines, etc.):\n\n```yaml\ndefault:\n  provider: openai\n  voice: onyx\nALICE:\n  provider: openai\n  voice: echo\n```\n\n### Step 6: Configure ID3 Tags (Optional)\n\nEdit `input/your_script/your_script_optional_config.yaml`:\n\n```yaml\nid3_tag_config:\n  title: \"My Audiobook\"\n  screenplay_author: \"Your Name\"\n  date: \"2024\"\n```\n\nThese tags will be added to the output .mp3 file, and are displayed in audio / audio book player apps\n\n### Step 7: Generate Audio\n\n```bash\n# Generate the audiobook\nuv run sts-generate-audio input/your_script/your_script.json \\\n  input/your_script/your_script_voice_config.yaml\n```\n\nYour audiobook will be output at: `output/your_script/your_script.mp3`\n\n## Advanced Workflow\n\nThe basic workflow will handle most screenplay-to-audiobook conversions, but Script to Speech offers many advanced features for complex projects, quality optimization, and fine-tuned control. This section covers advanced techniques you can use as needed:\n\n- **Advanced parsing** for non-standard screenplays\n- **Multi-provider setups** to optimize cost and voice variety\n- **LLM-assisted casting** for complex character rosters\n- **Custom text processing** for screenplay-specific formatting\n- **Iterative generation** to ensure quality before final output\n\nEach technique can be used independently based on your project's needs.\n\n### Advanced Screenplay Parsing\n\nSometimes you'll need more control over the parsing process, especially when dealing with non-standard screenplay formats or PDFs with headers/footers that interfere with parsing.\n\n**Modifying screenplay PDFs to remove unwanted elements:**\n\n```bash\n# Parse screenplay .pdf to text\nuv run sts-parse-screenplay source_screenplays/your_script.pdf --text-only\n```\n\nManually edit `input/your_script/your_script.txt` to remove headers, footers, page numbers, or any other elements that shouldn't be part of the audio, then:\n\n```bash\n# Create JSON dialogue chunks from edited text\nuv run sts-parse-screenplay input/your_script/your_script.txt\n```\n\n**Detecting headers/footers automatically:**\n\nUse `sts-detect-headers` to identify recurring header/footer patterns before parsing:\n\n```bash\n# Detect patterns in a PDF\nuv run sts-detect-headers source_screenplays/your_script.pdf\n```\n\nThe tool outputs detected patterns with occurrence percentages and a copy-paste `--remove` string:\n\n```\nHEADERS (sorted by occurrence):\n-----------------------------------\n[100.0%] \"MY SCREENPLAY - Rev. 10/\"\n        Found on 120/120 pages\n        Variations (2):\n          - \"MY SCREENPLAY - Rev. 10/15/24\"\n          - \"MY SCREENPLAY - Rev. 10/22/24\"\n\nCopy-paste for sts-parse-screenplay:\n----------------------------------------\n--remove 'MY SCREENPLAY - Rev. 10/15/24' --remove 'MY SCREENPLAY - Rev. 10/22/24'\n```\n\nApply the detected patterns during parsing:\n\n```bash\nuv run sts-parse-screenplay source_screenplays/your_script.pdf \\\n  --remove 'MY SCREENPLAY - Rev. 10/15/24' --remove 'MY SCREENPLAY - Rev. 10/22/24'\n```\n\nOptions:\n- `--threshold PCT`: Minimum occurrence percentage to display (default: 30%)\n- `--lines N`: Lines to scan from top/bottom of each page (default: 2)\n- `--json`: Output as JSON for programmatic use\n- `--include-blacklisted`: Include patterns like \"CONTINUED\" in output\n\n**Analyzing the parsed screenplay:**\n\nAfter parsing, it's good practice to verify the results:\n\n```bash\n# Check speakers and dialogue types\nuv run sts-analyze-json input/your_script/your_script.json\n```\n\nThis helps ensure the screenplay parsing worked as expected:\n- Do the speakers look correct?\n- Is there the right number of scene headers?\n- Are there corresponding numbers of dual-dialogue headers and bodies?\n- Are any characters being split incorrectly (e.g., \"BOB\" vs \"BOB (O.S.)\")?\n\n### Multi-Provider Voice Configuration\n\nFor larger projects, you may want to use different TTS providers for different characters to optimize cost, quality, or voice variety.\n\n**Generate a multi-provider template:**\n\nStart by generating a configuration file that shows statistics for each speaker:\n\n```bash\n# Generate multi-provider configuration\nuv run sts-tts-provider-yaml generate input/your_script/your_script.json\n```\n\nThis creates a config with speaker statistics at `input/your_script/your_script_voice_config.yaml`:\n\n```yaml\n# default: 1556 lines - Used for all non-dialogue pieces\n# Total characters: 104244, Longest dialogue: 2082 characters\ndefault:\n  provider:\n\n# ALICE: 283 lines\n# Total characters: 12181, Longest dialogue: 365 characters\nALICE:\n  provider:\n\n# BOB: 120 lines\n# Total characters: 9123, Longest dialogue: 253 characters\nBOB:\n  provider:\n```\n\n**Assign providers to speakers:**\n\nEdit the file to assign TTS providers based on character importance, line count, and voice requirements. You can also add provider-specific fields at this stage:\n\n```yaml\n# default: 1556 lines - Used for all non-dialogue pieces\n# Total characters: 104244, Longest dialogue: 2082 characters\ndefault:\n  provider: openai\n\n# ALICE: 283 lines\n# Total characters: 12181, Longest dialogue: 365 characters\nALICE:\n  provider: openai\n  voice: alloy\n\n# BOB: 120 lines\n# Total characters: 9123, Longest dialogue: 253 characters\nBOB:\n  provider: elevenlabs\n```\n\n**Populate provider-specific fields:**\n\nOnce providers are assigned, populate the remaining provider-specific fields:\n\n```bash\nuv run sts-tts-provider-yaml populate input/your_script/your_script.json \\\n  input/your_script/your_script_voice_config.yaml\n```\n\nThis creates `input/your_script/your_script_voice_config_populated.yaml` with provider-specific fields grouped by provider. Fill in the required fields for each provider according to the instructions at the top of each section. For detailed provider information, see the [TTS Providers documentation](docs/TTS_PROVIDERS.md).\n\n### (Optional) LLM-Assisted Voice Casting \n\nScript to Speech provides two LLM-assisted tools that work together to help cast voices for your screenplay characters:\n\n1. **Character Notes Generation** - Analyzes your screenplay to create casting notes for each character\n2. **Voice Library Casting** - Uses those notes to select specific voices from provider voice libraries\n\n> **⚠️ PRIVACY WARNING**: \n> - `sts-generate-character-notes-prompt` creates a prompt containing the **full text** of your screenplay\n> - `sts-generate-voice-library-casting-prompt` creates a prompt containing your character list and any casting notes (but not the screenplay text)\n> \n> Before using any cloud-based LLM service:\n> - Review their privacy policy and data usage practices\n> - Ensure you're comfortable sharing your content\n> - Consider whether the LLM provider uses uploaded content for training\n> - For sensitive content, consider using local LLM solutions or manually configuring voices\n> \n> See our [Privacy Policy](PRIVACY.md) for detailed guidance on privacy-conscious usage.\n\n#### Step 1: Generate Character Notes (Optional)\n\nFor complex scripts with many characters, you can use an LLM to generate casting notes (gender, vocal qualities, role summary, etc.) for each speaker:\n\n```bash\n# Generate a prompt file for LLM-assisted character analysis\nuv run sts-generate-character-notes-prompt \\\n  source_screenplays/your_script.pdf \\\n  input/your_script/your_script_voice_config.yaml\n```\n\nThis creates `input/your_script/your_script_character_notes_prompt.txt` containing:\n- Instructions for the LLM to provide casting notes for each character\n- Your current voice configuration\n- The full screenplay text\n\n#### Step 2: Copy Prompt to Clipboard\n\n```bash\n# Copy the generated prompt to your clipboard for easy pasting into an LLM\nuv run sts-copy-to-clipboard input/your_script/your_script_character_notes_prompt.txt\n```\n\n#### Step 3: Update Configuration with Character Notes\n\nAfter receiving the LLM's output with character notes added as YAML comments, save the updated configuration back to your voice config file.\n\n#### Step 4: Cast Voices from Library (Optional)\n\nOnce you have character notes (either from the LLM or manually added), you can use voice library casting to automatically select appropriate voices:\n\n```bash\n# Generate a prompt for voice library casting\nuv run sts-generate-voice-library-casting-prompt \\\n  input/your_script/your_script_voice_config.yaml \\\n  openai elevenlabs\n```\n\nThis creates `input/your_script/your_script_voice_config_voice_library_casting_prompt.txt` containing:\n- Instructions for the LLM to select voices from the specified provider libraries\n- Your voice configuration with character notes\n- Voice library data for the specified providers\n\nNote: You can specify multiple providers (e.g., `openai elevenlabs cartesia`) to cast from multiple voice libraries simultaneously.\n\n#### Step 5: Apply Voice Selections\n\nCopy the prompt to clipboard and paste into your LLM:\n\n```bash\nuv run sts-copy-to-clipboard input/your_script/your_script_voice_config_voice_library_casting_prompt.txt\n```\n\nThe LLM will return your configuration with `sts_id` fields populated with specific voice selections from the libraries.\n\n#### Step 6: Validate Configuration\n\nAfter receiving updated voice configuration from the LLM, validate it:\n\n```bash\n# Check for missing/extra/duplicate speakers and provider field issues\nuv run sts-tts-provider-yaml validate input/your_script/your_script.json \\\n  input/your_script/your_script_voice_config.yaml --strict\n```\n\n#### Privacy-Conscious Alternative Workflow\n\nFor sensitive screenplays, you can skip character notes generation and manually add casting notes:\n\n1. Manually edit your voice configuration to add character descriptions as YAML comments\n2. Use only `sts-generate-voice-library-casting-prompt` (which doesn't include screenplay text)\n3. This way, only character names and your notes are shared with the LLM, not the screenplay content\n\n### Custom Text Processing\n\nScript to Speech allows you to customize how text is processed before being sent to TTS providers. This is useful for expanding abbreviations, handling special formatting, or adjusting capitalization.\n\nCustom text processor configurations will chain with the default configuration. By default, the program looks for a file named after your dialogue chunk file with `_text_processor_config.yaml` appended.\n\nTo create a custom config, create `input/your_script/your_script_text_processor_config.yaml`:\n\n```yaml\nprocessors:\n  - name: text_substitution\n    config:\n      substitutions:\n        - from: \"CU\"\n          to: \"close up\"\n          fields:\n            - text\n        - from: \"P.O.V\"\n          to: \"point of view\"\n          fields:\n            - text\n```\n\nFor more information about text processor transformations and creating your own, see the [Text Processing Guide](docs/TEXT_PROCESSORS.md).\n\n### Iterative Audio Generation with Run Modes\n\nScript to Speech supports various run modes to test and iteratively refine your audiobook before generating the final output. This workflow is particularly useful for large projects where you want to ensure quality before committing to full generation.\n\n**Dry Run Testing**\n\nStart by validating your configuration without generating any audio:\n\n```bash\nuv run sts-generate-audio input/your_script/your_script.json \\\n  input/your_script/your_script_voice_config.yaml \\\n  --dry-run\n```\n\nUse cases:\n- Validating configuration files\n- Determining which audio files will be generated\n- Checking for potential issues before spending on API calls\n\n**Building the Audio Cache**\n\nGenerate all audio clips without creating the final MP3:\n\n```bash\nuv run sts-generate-audio input/your_script/your_script.json \\\n  input/your_script/your_script_voice_config.yaml \\\n  --populate-cache --check-silence\n```\n\nThis approach allows you to:\n- Check for silent or problematic clips before final generation\n- Build your cache incrementally (process can be resumed if interrupted)\n- Review individual clips for quality\n- Replace specific clips with better \"takes\"\n\n**Replacing Problem Audio**\n\nIf silent clips are detected or you want to re-record specific lines:\n\n```bash\n# Generate replacement audio\nuv run sts-generate-standalone-speech openai --voice echo \\\n  \"Replace this silent text number 1\" \\\n  \"Replace this silent text number 2\" \\\n  -v 3  # Generate 3 variations of each line\n```\n\nRename the generated file to match the cache filename (as reported in console output or logs):\n\n```bash\nmv standalone_speech/generated_file.mp3 \\\n  standalone_speech/[original_cache_filename].mp3\n```\n\nApply the replacements:\n\n```bash\nuv run sts-generate-audio input/your_script/your_script.json \\\n  input/your_script/your_script_voice_config.yaml \\\n  --populate-cache --cache-overrides --check-silence\n```\n\nSee [Standalone Speech Generation](docs/STANDALONE_SPEECH.md) for more details and usage options\n\n**Final Generation**\n\nOnce all audio is cached and verified:\n\n```bash\nuv run sts-generate-audio input/your_script/your_script.json \\\n  input/your_script/your_script_voice_config.yaml\n```\n\nThis combines all cached audio into the final audiobook with proper gaps and ID3 tags.\n\nFor detailed information about all available run modes and options, see the [Run Modes documentation](docs/RUN_MODES.md).\n\n## Directory Structure\nScript to Speech uses a number of default locations to simplify workflows. The following lists standard files you will likely encounter while running the program. Directories `input/[screenplay_name]` and `output/[screenplay_name]` will automatically be created when the screenplay is parsed. \n\n```\nsource_screenplays/                   # Original screenplay files\ninput/\n└── [screenplay_name]/\n    ├── [screenplay_name].pdf         # Copied screenplay\n    ├── [screenplay_name].txt         # Extracted text (if parser run with --text-only)\n    ├── [screenplay_name].json        # Parsed dialogue chunks\n    ├── [screenplay_name]_optional_config.yaml          # ID3 tag configuration\n    ├── [screenplay_name]_text_processor_config.yaml    # (optional) Custom text processors\n    ├── [screenplay_name]_voice_config.yaml             # TTS provider config\n    ├── [screenplay_name]_voice_config_populated.yaml   # TTS provider config populated with multi-provider options\n    ├── [screenplay_name]_character_notes_prompt.txt      # (optional) LLM character notes prompt\n    └── [screenplay_name]_voice_config_voice_library_casting_prompt.txt  # (optional) LLM voice library casting prompt\n\noutput/\n└── [screenplay_name]/\n    ├── [screenplay_name].mp3                  # Final audiobook\n    ├── [screenplay_name]-text-processed.json  # Dialogue chunks with text processors applied\n    ├── cache/                                 # Generated audio clips\n    └── logs/                                  # Parsing and generation logs\n\nstandalone_speech/                             # Override audio files\n```\n\n## Run Modes\n\n- **Default**: Generate complete audiobook\n- **--dry-run**: Test configuration without generating audio\n- **--populate-cache**: Generate and cache audio only (no final MP3)\n\nSee [RUN_MODES.md](doc/RUN_MODES.md) for detailed information.\n\n## Text Processing\n\nScript to Speech supports flexible text processing through preprocessors and processors:\n\n- **Preprocessors**: Modify the dialogue structure\n- **Processors**: Transform individual text lines\n\nSee [TEXT_PROCESSORS.md](docs/TEXT_PROCESSORS.md) for configuration details.\n\n## TTS Providers\n\nSupported TTS providers:\n\n- **OpenAI**: Preview voices at [openai.fm](https://www.openai.fm/)\n- **ElevenLabs**: Requires \"Creator\" plan, uses public library voices\n- **Cartesia**: TTS with a free plan and a number of voices\n- **Minimax**: TTS with voice mixing capabilities and emotion control\n- **Zonos**: TTS service with a free plan and a few voices\n- **Dummy**: Testing only\n\nSee [TTS_PROVIDERS.md](docs/TTS_PROVIDERS.md) for provider-specific configuration.\n\n## Advanced Topics\n\n### Sharing Cache for Re-casting\n\nThe `input` and `output` folders (including cache) can be shared between users to reuse audio when changing select voices:\n\n1. Share `input/[screenplay_name]` and `output/[screenplay_name]` folders\n2. Edit voice configuration for desired speakers\n3. Run with existing cache to preserve unchanged audio\n\n### Multi-threaded Downloads\n\nDownloads are multi-threaded with separate queues per provider. Distributing voices across TTS providers speeds up generation.\n\n### Cache Management\n\nGenerated audio is cached in `output/[screenplay_name]/cache/`. Cache files are uniquely named based on:\n\n- Speaker configuration\n- TTS provider\n- Text content\n- Processing parameters\n\nChanges in any of the above will mark just the relevant clips for regeneration upon the next run \n\n## Troubleshooting\n\n### Common Issues\n\n1. **Silent Audio Detected**\n\n   - Use `--check-silence` to identify silent clips\n   - Generate replacements with `sts-generate-standalone-speech`\n   - Apply with `--cache-overrides`\n\n2. **Rate Limiting**\n   - Each provider has different rate limits\n   - The tool automatically handles backoff\n   - Spread voices across TTS providers to avoid limits\n\n3. **Voice Configuration Errors**\n   - Use `sts-tts-provider-yaml validate` to check for missing/extra/duplicate speakers\n   - Use `--strict` flag to validate provider-specific fields\n   - Check voice IDs match provider requirements\n\n4. **Screenplay is parsed incorrectly**\n   - The parser is currently fairly fragile, and expects \"standard\" screenplay files with predictable margins and conventions. Additional configuration options, and automatic configuration, is planned for future releases\n\n5. **Headers/Footers Appearing in Parsed Output**\n   - Use `sts-detect-headers` to identify recurring patterns\n   - Apply detected patterns with `--remove` option during parsing\n   - Use `--text-only` to manually edit problematic content\n\nSee [TROUBLESHOOTING.md](docs/TROUBLESHOOTING.md) for more solutions.\n\n## Environment Variables\n\nRequired for TTS providers:\n\n- `OPENAI_API_KEY`: OpenAI API access\n- `ELEVEN_API_KEY`: ElevenLabs API access\n- `CARTESIA_API_KEY`: Cartesia API access\n- `MINIMAX_API_KEY`: Minimax API access\n- `MINIMAX_GROUP_ID`: Minimax Group ID\n- `ZONOS_API_KEY`: Zonos API access\n\n### Using .env Files (Recommended)\n\nFor local development, you can use a `.env` file to store your API keys instead of setting them as environment variables in your shell. This approach is more convenient and for developers, helps prevent accidental exposure of your keys.\n\n1. Copy the provided `.env.example` file to a new file named `.env` in the project root:\n   ```bash\n   cp .env.example .env\n   ```\n\n2. Edit the `.env` file and add your API keys:\n   ```\n   OPENAI_API_KEY=\"your-openai-key-here\"\n   ELEVEN_API_KEY=\"your-elevenlabs-key-here\"\n   # Add other keys as needed\n   ```\n\n3. The application will automatically load these variables when it starts.\n\n**Note**: The `.env` file is excluded from version control via `.gitignore` to prevent accidentally committing your API keys. Never commit your actual API keys to version control.\n\n## License\n\nMIT licensed. See [LICENSE](LICENSE) for more information","src/content/docs/readme.md","1eaae091e5c1bfd3",{"html":311,"metadata":312},"\u003Ch1 id=\"script-to-speech\">Script to Speech\u003C/h1>\n\u003Cp>Convert screenplays into multi-voiced audiobooks using various Text-to-Speech (TTS) providers.\u003C/p>\n\u003Cp>Script to Speech is available in two versions:\u003C/p>\n\u003Col>\n\u003Cli>\u003Cstrong>Desktop GUI (Experimental)\u003C/strong>: A modern, easy-to-use desktop application. Recommended for new users.\u003C/li>\n\u003Cli>\u003Cstrong>Command Line Interface (CLI)\u003C/strong>: The core, feature-complete tool. Recommended for advanced users and automation.\u003C/li>\n\u003C/ol>\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\u003Ctable>\u003Cthead>\u003Ctr>\u003Cth align=\"left\">Feature\u003C/th>\u003Cth align=\"left\">Desktop GUI\u003C/th>\u003Cth align=\"left\">CLI\u003C/th>\u003C/tr>\u003C/thead>\u003Ctbody>\u003Ctr>\u003Ctd align=\"left\">\u003Cstrong>Ease of Use\u003C/strong>\u003C/td>\u003Ctd align=\"left\">⭐⭐⭐⭐⭐\u003C/td>\u003Ctd align=\"left\">⭐⭐\u003C/td>\u003C/tr>\u003Ctr>\u003Ctd align=\"left\">\u003Cstrong>Features\u003C/strong>\u003C/td>\u003Ctd align=\"left\">Core Features\u003C/td>\u003Ctd align=\"left\">All Features\u003C/td>\u003C/tr>\u003Ctr>\u003Ctd align=\"left\">\u003Cstrong>Stability\u003C/strong>\u003C/td>\u003Ctd align=\"left\">Experimental\u003C/td>\u003Ctd align=\"left\">Stable\u003C/td>\u003C/tr>\u003Ctr>\u003Ctd align=\"left\">\u003Cstrong>Documentation\u003C/strong>\u003C/td>\u003Ctd align=\"left\">\u003Ca href=\"docs/GUI_USER_GUIDE.md\">GUI User Guide\u003C/a>\u003C/td>\u003Ctd align=\"left\">\u003Ca href=\"#cli-usage\">CLI Documentation\u003C/a>\u003C/td>\u003C/tr>\u003C/tbody>\u003C/table>\n\u003Chr>\n\u003Ch2 id=\"key-features\">Key Features\u003C/h2>\n\u003Cul>\n\u003Cli>\u003Cstrong>Multi-provider support\u003C/strong>: Use OpenAI, ElevenLabs, Cartesia, Minimax, Zonos, or custom TTS providers. TTS providers can be set at a per-speaker level\u003C/li>\n\u003Cli>\u003Cstrong>Text processing pipeline\u003C/strong>: Customize how text is processed before audio generation\u003C/li>\n\u003Cli>\u003Cstrong>Multi-threaded downloads\u003C/strong>: With separate queues per provider for faster generation\u003C/li>\n\u003Cli>\u003Cstrong>Silence detection\u003C/strong>: Identify and replace silent audio clips\u003C/li>\n\u003Cli>\u003Cstrong>Cache system\u003C/strong>: Resume interrupted generations and reuse audio. Change text / speaker assignments and only regenerte that specific audio\u003C/li>\n\u003Cli>\u003Cstrong>Voice casting assistance\u003C/strong>: Generate prompts for LLM-assisted character notes and voice library casting\u003C/li>\n\u003C/ul>\n\u003Ch2 id=\"privacy--data-handling\">Privacy &#x26; Data Handling\u003C/h2>\n\u003Cp>\u003Cstrong>Script to Speech Privacy\u003C/strong>: This tool operates entirely locally on your machine and collects no user data, has no telemetry, tracking, or analytics, and makes no network requests except to the services required for its core functionality.\u003C/p>\n\u003Cp>\u003Cstrong>Audio Generation\u003C/strong>: To convert your screenplay text into speech, Script to Speech sends individual dialogue chunks to TTS providers (OpenAI, ElevenLabs, etc.) you configure. Each provider receives only the specific text being converted to audio.\u003C/p>\n\u003Cp>\u003Cstrong>Voice Casting (Optional)\u003C/strong>: If you choose to use the LLM-assisted voice casting feature, your complete screenplay text and voice configuration are sent to the LLM service you select to generate casting recommendations.\u003C/p>\n\u003Cp>\u003Cstrong>Important\u003C/strong>: Before using any TTS provider or LLM service, review their privacy policies, data retention practices, and training data policies to ensure they align with your privacy requirements.\u003C/p>\n\u003Cp>See our \u003Ca href=\"PRIVACY.md\">Privacy Policy\u003C/a> for detailed information about data flows, recommendations for privacy-conscious usage, and contact information.\u003C/p>\n\u003Chr>\n\u003Ch2 id=\"cli-usage\">CLI Usage\u003C/h2>\n\u003Cp>The following documentation covers the \u003Cstrong>Command Line Interface\u003C/strong>. For GUI instructions, please see the \u003Ca href=\"docs/GUI_USER_GUIDE.md\">GUI User Guide\u003C/a>.\u003C/p>\n\u003Ch2 id=\"cli-commands\">CLI Commands\u003C/h2>\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\u003Ctable>\u003Cthead>\u003Ctr>\u003Cth>Command\u003C/th>\u003Cth>Description\u003C/th>\u003C/tr>\u003C/thead>\u003Ctbody>\u003Ctr>\u003Ctd>\u003Ccode>sts-parse-screenplay\u003C/code>\u003C/td>\u003Ctd>Parse PDF/TXT to JSON chunks\u003C/td>\u003C/tr>\u003Ctr>\u003Ctd>\u003Ccode>sts-detect-headers\u003C/code>\u003C/td>\u003Ctd>Detect header/footer patterns in PDFs\u003C/td>\u003C/tr>\u003Ctr>\u003Ctd>\u003Ccode>sts-generate-audio\u003C/code>\u003C/td>\u003Ctd>Generate audiobook from JSON\u003C/td>\u003C/tr>\u003Ctr>\u003Ctd>\u003Ccode>sts-generate-standalone-speech\u003C/code>\u003C/td>\u003Ctd>Create individual audio clips. See \u003Ca href=\"docs/STANDALONE_SPEECH.md\">Standalone Speech Generation\u003C/a> for more details.\u003C/td>\u003C/tr>\u003Ctr>\u003Ctd>\u003Ccode>sts-tts-provider-yaml\u003C/code>\u003C/td>\u003Ctd>Generate/populate provider configs\u003C/td>\u003C/tr>\u003Ctr>\u003Ctd>\u003Ccode>sts-analyze-json\u003C/code>\u003C/td>\u003Ctd>Analyze screenplay structure\u003C/td>\u003C/tr>\u003Ctr>\u003Ctd>\u003Ccode>sts-apply-text-processors-json\u003C/code>\u003C/td>\u003Ctd>Apply text transformations\u003C/td>\u003C/tr>\u003Ctr>\u003Ctd>\u003Ccode>sts-parse-regression-check-json\u003C/code>\u003C/td>\u003Ctd>Validate parser output\u003C/td>\u003C/tr>\u003Ctr>\u003Ctd>\u003Ccode>sts-generate-character-notes-prompt\u003C/code>\u003C/td>\u003Ctd>Generate LLM casting prompts\u003C/td>\u003C/tr>\u003Ctr>\u003Ctd>\u003Ccode>sts-generate-voice-library-casting-prompt\u003C/code>\u003C/td>\u003Ctd>Generate voice library casting prompts\u003C/td>\u003C/tr>\u003Ctr>\u003Ctd>\u003Ccode>sts-copy-to-clipboard\u003C/code>\u003C/td>\u003Ctd>Copy file contents to clipboard\u003C/td>\u003C/tr>\u003C/tbody>\u003C/table>\n\u003Ch2 id=\"quick-start\">Quick Start\u003C/h2>\n\u003Ch3 id=\"installation\">Installation\u003C/h3>\n\u003Col>\n\u003Cli>\n\u003Cp>\u003Cstrong>Install UV\u003C/strong> (package manager)\u003C/p>\n\u003Cpre class=\"astro-code github-dark\" style=\"background-color:#24292e;color:#e1e4e8; overflow-x: auto;\" tabindex=\"0\" data-language=\"bash\">\u003Ccode>\u003Cspan class=\"line\">\u003Cspan style=\"color:#B392F0\">pip\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> install\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> uv\u003C/span>\u003C/span>\u003C/code>\u003C/pre>\n\u003Cp>For alternate / more detailed UV installation instructions, see \u003Ca href=\"https://docs.astral.sh/uv/getting-started/installation/\">UV’s documentation\u003C/a>.\u003C/p>\n\u003C/li>\n\u003Cli>\n\u003Cp>\u003Cstrong>Create a copy of the project\u003C/strong>\nEither \u003Ca href=\"https://github.com/trentw/script-to-speech/archive/refs/heads/master.zip\">download\u003C/a> the project, or use git to clone it:\u003C/p>\n\u003Cpre class=\"astro-code github-dark\" style=\"background-color:#24292e;color:#e1e4e8; overflow-x: auto;\" tabindex=\"0\" data-language=\"bash\">\u003Ccode>\u003Cspan class=\"line\">\u003Cspan style=\"color:#B392F0\">git\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> clone\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> https://github.com/trentw/script-to-speech.git\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#79B8FF\">cd\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> script-to-speech\u003C/span>\u003C/span>\u003C/code>\u003C/pre>\n\u003C/li>\n\u003C/ol>\n\u003Ch3 id=\"for-basic-usage\">For Basic Usage\u003C/h3>\n\u003Cp>No additional installation needed! UV will automatically install dependencies on first use.\u003C/p>\n\u003Ch3 id=\"for-development\">For Development\u003C/h3>\n\u003Cp>Install the package in editable mode:\u003C/p>\n\u003Cpre class=\"astro-code github-dark\" style=\"background-color:#24292e;color:#e1e4e8; overflow-x: auto;\" tabindex=\"0\" data-language=\"bash\">\u003Ccode>\u003Cspan class=\"line\">\u003Cspan style=\"color:#B392F0\">uv\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> pip\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> install\u003C/span>\u003Cspan style=\"color:#79B8FF\"> -e\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> \".[dev]\"\u003C/span>\u003C/span>\u003C/code>\u003C/pre>\n\u003Ch2 id=\"basic-workflow\">Basic Workflow\u003C/h2>\n\u003Ch3 id=\"step-1-setup-accounts-with-tts-services-and-configure\">Step 1: Setup Accounts with TTS Services and Configure\u003C/h3>\n\u003Cp>Get an API key from at least one of the supported providers listed in the \u003Ca href=\"docs/TTS_PROVIDERS.md\">TTS Providers documentation\u003C/a> and add it to the project\u003C/p>\n\u003Cpre class=\"astro-code github-dark\" style=\"background-color:#24292e;color:#e1e4e8; overflow-x: auto;\" tabindex=\"0\" data-language=\"bash\">\u003Ccode>\u003Cspan class=\"line\">\u003Cspan style=\"color:#6A737D\"># OpenAI\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F97583\">export\u003C/span>\u003Cspan style=\"color:#E1E4E8\"> OPENAI_API_KEY\u003C/span>\u003Cspan style=\"color:#F97583\">=\u003C/span>\u003Cspan style=\"color:#9ECBFF\">\"your-api-key\"\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#6A737D\"># ElevenLabs\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F97583\">export\u003C/span>\u003Cspan style=\"color:#E1E4E8\"> ELEVEN_API_KEY\u003C/span>\u003Cspan style=\"color:#F97583\">=\u003C/span>\u003Cspan style=\"color:#9ECBFF\">\"your-api-key\"\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#6A737D\"># Cartesia\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F97583\">export\u003C/span>\u003Cspan style=\"color:#E1E4E8\"> CARTESIA_API_KEY\u003C/span>\u003Cspan style=\"color:#F97583\">=\u003C/span>\u003Cspan style=\"color:#9ECBFF\">\"your-api-key\"\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#6A737D\"># Minimax\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F97583\">export\u003C/span>\u003Cspan style=\"color:#E1E4E8\"> MINIMAX_API_KEY\u003C/span>\u003Cspan style=\"color:#F97583\">=\u003C/span>\u003Cspan style=\"color:#9ECBFF\">\"your-api-key\"\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F97583\">export\u003C/span>\u003Cspan style=\"color:#E1E4E8\"> MINIMAX_GROUP_ID\u003C/span>\u003Cspan style=\"color:#F97583\">=\u003C/span>\u003Cspan style=\"color:#9ECBFF\">\"your-group-id\"\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#6A737D\"># Zonos\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F97583\">export\u003C/span>\u003Cspan style=\"color:#E1E4E8\"> ZONOS_API_KEY\u003C/span>\u003Cspan style=\"color:#F97583\">=\u003C/span>\u003Cspan style=\"color:#9ECBFF\">\"your-api-key\"\u003C/span>\u003C/span>\u003C/code>\u003C/pre>\n\u003Ch3 id=\"step-2-add-screenplay\">Step 2: Add Screenplay\u003C/h3>\n\u003Cp>Place your screenplay PDF in the \u003Ccode>source_screenplays\u003C/code> directory.\u003C/p>\n\u003Ch3 id=\"step-3-parse-screenplay\">Step 3: Parse Screenplay\u003C/h3>\n\u003Cpre class=\"astro-code github-dark\" style=\"background-color:#24292e;color:#e1e4e8; overflow-x: auto;\" tabindex=\"0\" data-language=\"bash\">\u003Ccode>\u003Cspan class=\"line\">\u003Cspan style=\"color:#6A737D\"># Parse PDF to JSON dialogue chunks\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#B392F0\">uv\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> run\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> sts-parse-screenplay\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> source_screenplays/your_script.pdf\u003C/span>\u003C/span>\u003C/code>\u003C/pre>\n\u003Cp>This creates:\u003C/p>\n\u003Cul>\n\u003Cli>\u003Ccode>input/your_script/your_script.pdf\u003C/code> (copy of original)\u003C/li>\n\u003Cli>\u003Ccode>input/your_script/your_script.json\u003C/code> (parsed dialogue chunks)\u003C/li>\n\u003Cli>\u003Ccode>input/your_script/your_script_optional_config.yaml\u003C/code> (configuration file to set values like ID3 tags for .mp3 file)\u003C/li>\n\u003C/ul>\n\u003Ch3 id=\"step-4-generate-tts-provider-configuration\">Step 4: Generate TTS Provider Configuration\u003C/h3>\n\u003Cpre class=\"astro-code github-dark\" style=\"background-color:#24292e;color:#e1e4e8; overflow-x: auto;\" tabindex=\"0\" data-language=\"bash\">\u003Ccode>\u003Cspan class=\"line\">\u003Cspan style=\"color:#6A737D\"># Generate YAML config for a single provider\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#B392F0\">uv\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> run\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> sts-tts-provider-yaml\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> generate\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> input/your_script/your_script.json\u003C/span>\u003Cspan style=\"color:#79B8FF\"> --tts-provider\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> openai\u003C/span>\u003C/span>\u003C/code>\u003C/pre>\n\u003Cp>This creates \u003Ccode>input/your_script/your_script_voice_config.yaml\u003C/code>\u003C/p>\n\u003Ch3 id=\"step-5-configure-voices\">Step 5: Configure Voices\u003C/h3>\n\u003Cp>Edit the generated YAML file to assign voices to speakers (note that “default” is used for any items without an explicit speaker defined, such as scene headers, action lines, etc.):\u003C/p>\n\u003Cpre class=\"astro-code github-dark\" style=\"background-color:#24292e;color:#e1e4e8; overflow-x: auto;\" tabindex=\"0\" data-language=\"yaml\">\u003Ccode>\u003Cspan class=\"line\">\u003Cspan style=\"color:#85E89D\">default\u003C/span>\u003Cspan style=\"color:#E1E4E8\">:\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#85E89D\">  provider\u003C/span>\u003Cspan style=\"color:#E1E4E8\">: \u003C/span>\u003Cspan style=\"color:#9ECBFF\">openai\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#85E89D\">  voice\u003C/span>\u003Cspan style=\"color:#E1E4E8\">: \u003C/span>\u003Cspan style=\"color:#9ECBFF\">onyx\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#85E89D\">ALICE\u003C/span>\u003Cspan style=\"color:#E1E4E8\">:\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#85E89D\">  provider\u003C/span>\u003Cspan style=\"color:#E1E4E8\">: \u003C/span>\u003Cspan style=\"color:#9ECBFF\">openai\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#85E89D\">  voice\u003C/span>\u003Cspan style=\"color:#E1E4E8\">: \u003C/span>\u003Cspan style=\"color:#9ECBFF\">echo\u003C/span>\u003C/span>\u003C/code>\u003C/pre>\n\u003Ch3 id=\"step-6-configure-id3-tags-optional\">Step 6: Configure ID3 Tags (Optional)\u003C/h3>\n\u003Cp>Edit \u003Ccode>input/your_script/your_script_optional_config.yaml\u003C/code>:\u003C/p>\n\u003Cpre class=\"astro-code github-dark\" style=\"background-color:#24292e;color:#e1e4e8; overflow-x: auto;\" tabindex=\"0\" data-language=\"yaml\">\u003Ccode>\u003Cspan class=\"line\">\u003Cspan style=\"color:#85E89D\">id3_tag_config\u003C/span>\u003Cspan style=\"color:#E1E4E8\">:\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#85E89D\">  title\u003C/span>\u003Cspan style=\"color:#E1E4E8\">: \u003C/span>\u003Cspan style=\"color:#9ECBFF\">\"My Audiobook\"\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#85E89D\">  screenplay_author\u003C/span>\u003Cspan style=\"color:#E1E4E8\">: \u003C/span>\u003Cspan style=\"color:#9ECBFF\">\"Your Name\"\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#85E89D\">  date\u003C/span>\u003Cspan style=\"color:#E1E4E8\">: \u003C/span>\u003Cspan style=\"color:#9ECBFF\">\"2024\"\u003C/span>\u003C/span>\u003C/code>\u003C/pre>\n\u003Cp>These tags will be added to the output .mp3 file, and are displayed in audio / audio book player apps\u003C/p>\n\u003Ch3 id=\"step-7-generate-audio\">Step 7: Generate Audio\u003C/h3>\n\u003Cpre class=\"astro-code github-dark\" style=\"background-color:#24292e;color:#e1e4e8; overflow-x: auto;\" tabindex=\"0\" data-language=\"bash\">\u003Ccode>\u003Cspan class=\"line\">\u003Cspan style=\"color:#6A737D\"># Generate the audiobook\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#B392F0\">uv\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> run\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> sts-generate-audio\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> input/your_script/your_script.json\u003C/span>\u003Cspan style=\"color:#79B8FF\"> \\\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#9ECBFF\">  input/your_script/your_script_voice_config.yaml\u003C/span>\u003C/span>\u003C/code>\u003C/pre>\n\u003Cp>Your audiobook will be output at: \u003Ccode>output/your_script/your_script.mp3\u003C/code>\u003C/p>\n\u003Ch2 id=\"advanced-workflow\">Advanced Workflow\u003C/h2>\n\u003Cp>The basic workflow will handle most screenplay-to-audiobook conversions, but Script to Speech offers many advanced features for complex projects, quality optimization, and fine-tuned control. This section covers advanced techniques you can use as needed:\u003C/p>\n\u003Cul>\n\u003Cli>\u003Cstrong>Advanced parsing\u003C/strong> for non-standard screenplays\u003C/li>\n\u003Cli>\u003Cstrong>Multi-provider setups\u003C/strong> to optimize cost and voice variety\u003C/li>\n\u003Cli>\u003Cstrong>LLM-assisted casting\u003C/strong> for complex character rosters\u003C/li>\n\u003Cli>\u003Cstrong>Custom text processing\u003C/strong> for screenplay-specific formatting\u003C/li>\n\u003Cli>\u003Cstrong>Iterative generation\u003C/strong> to ensure quality before final output\u003C/li>\n\u003C/ul>\n\u003Cp>Each technique can be used independently based on your project’s needs.\u003C/p>\n\u003Ch3 id=\"advanced-screenplay-parsing\">Advanced Screenplay Parsing\u003C/h3>\n\u003Cp>Sometimes you’ll need more control over the parsing process, especially when dealing with non-standard screenplay formats or PDFs with headers/footers that interfere with parsing.\u003C/p>\n\u003Cp>\u003Cstrong>Modifying screenplay PDFs to remove unwanted elements:\u003C/strong>\u003C/p>\n\u003Cpre class=\"astro-code github-dark\" style=\"background-color:#24292e;color:#e1e4e8; overflow-x: auto;\" tabindex=\"0\" data-language=\"bash\">\u003Ccode>\u003Cspan class=\"line\">\u003Cspan style=\"color:#6A737D\"># Parse screenplay .pdf to text\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#B392F0\">uv\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> run\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> sts-parse-screenplay\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> source_screenplays/your_script.pdf\u003C/span>\u003Cspan style=\"color:#79B8FF\"> --text-only\u003C/span>\u003C/span>\u003C/code>\u003C/pre>\n\u003Cp>Manually edit \u003Ccode>input/your_script/your_script.txt\u003C/code> to remove headers, footers, page numbers, or any other elements that shouldn’t be part of the audio, then:\u003C/p>\n\u003Cpre class=\"astro-code github-dark\" style=\"background-color:#24292e;color:#e1e4e8; overflow-x: auto;\" tabindex=\"0\" data-language=\"bash\">\u003Ccode>\u003Cspan class=\"line\">\u003Cspan style=\"color:#6A737D\"># Create JSON dialogue chunks from edited text\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#B392F0\">uv\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> run\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> sts-parse-screenplay\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> input/your_script/your_script.txt\u003C/span>\u003C/span>\u003C/code>\u003C/pre>\n\u003Cp>\u003Cstrong>Detecting headers/footers automatically:\u003C/strong>\u003C/p>\n\u003Cp>Use \u003Ccode>sts-detect-headers\u003C/code> to identify recurring header/footer patterns before parsing:\u003C/p>\n\u003Cpre class=\"astro-code github-dark\" style=\"background-color:#24292e;color:#e1e4e8; overflow-x: auto;\" tabindex=\"0\" data-language=\"bash\">\u003Ccode>\u003Cspan class=\"line\">\u003Cspan style=\"color:#6A737D\"># Detect patterns in a PDF\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#B392F0\">uv\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> run\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> sts-detect-headers\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> source_screenplays/your_script.pdf\u003C/span>\u003C/span>\u003C/code>\u003C/pre>\n\u003Cp>The tool outputs detected patterns with occurrence percentages and a copy-paste \u003Ccode>--remove\u003C/code> string:\u003C/p>\n\u003Cpre class=\"astro-code github-dark\" style=\"background-color:#24292e;color:#e1e4e8; overflow-x: auto;\" tabindex=\"0\" data-language=\"plaintext\">\u003Ccode>\u003Cspan class=\"line\">\u003Cspan>HEADERS (sorted by occurrence):\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan>-----------------------------------\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan>[100.0%] \"MY SCREENPLAY - Rev. 10/\"\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan>        Found on 120/120 pages\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan>        Variations (2):\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan>          - \"MY SCREENPLAY - Rev. 10/15/24\"\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan>          - \"MY SCREENPLAY - Rev. 10/22/24\"\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan>\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan>Copy-paste for sts-parse-screenplay:\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan>----------------------------------------\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan>--remove 'MY SCREENPLAY - Rev. 10/15/24' --remove 'MY SCREENPLAY - Rev. 10/22/24'\u003C/span>\u003C/span>\u003C/code>\u003C/pre>\n\u003Cp>Apply the detected patterns during parsing:\u003C/p>\n\u003Cpre class=\"astro-code github-dark\" style=\"background-color:#24292e;color:#e1e4e8; overflow-x: auto;\" tabindex=\"0\" data-language=\"bash\">\u003Ccode>\u003Cspan class=\"line\">\u003Cspan style=\"color:#B392F0\">uv\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> run\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> sts-parse-screenplay\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> source_screenplays/your_script.pdf\u003C/span>\u003Cspan style=\"color:#79B8FF\"> \\\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#79B8FF\">  --remove\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> 'MY SCREENPLAY - Rev. 10/15/24'\u003C/span>\u003Cspan style=\"color:#79B8FF\"> --remove\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> 'MY SCREENPLAY - Rev. 10/22/24'\u003C/span>\u003C/span>\u003C/code>\u003C/pre>\n\u003Cp>Options:\u003C/p>\n\u003Cul>\n\u003Cli>\u003Ccode>--threshold PCT\u003C/code>: Minimum occurrence percentage to display (default: 30%)\u003C/li>\n\u003Cli>\u003Ccode>--lines N\u003C/code>: Lines to scan from top/bottom of each page (default: 2)\u003C/li>\n\u003Cli>\u003Ccode>--json\u003C/code>: Output as JSON for programmatic use\u003C/li>\n\u003Cli>\u003Ccode>--include-blacklisted\u003C/code>: Include patterns like “CONTINUED” in output\u003C/li>\n\u003C/ul>\n\u003Cp>\u003Cstrong>Analyzing the parsed screenplay:\u003C/strong>\u003C/p>\n\u003Cp>After parsing, it’s good practice to verify the results:\u003C/p>\n\u003Cpre class=\"astro-code github-dark\" style=\"background-color:#24292e;color:#e1e4e8; overflow-x: auto;\" tabindex=\"0\" data-language=\"bash\">\u003Ccode>\u003Cspan class=\"line\">\u003Cspan style=\"color:#6A737D\"># Check speakers and dialogue types\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#B392F0\">uv\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> run\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> sts-analyze-json\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> input/your_script/your_script.json\u003C/span>\u003C/span>\u003C/code>\u003C/pre>\n\u003Cp>This helps ensure the screenplay parsing worked as expected:\u003C/p>\n\u003Cul>\n\u003Cli>Do the speakers look correct?\u003C/li>\n\u003Cli>Is there the right number of scene headers?\u003C/li>\n\u003Cli>Are there corresponding numbers of dual-dialogue headers and bodies?\u003C/li>\n\u003Cli>Are any characters being split incorrectly (e.g., “BOB” vs “BOB (O.S.)”)?\u003C/li>\n\u003C/ul>\n\u003Ch3 id=\"multi-provider-voice-configuration\">Multi-Provider Voice Configuration\u003C/h3>\n\u003Cp>For larger projects, you may want to use different TTS providers for different characters to optimize cost, quality, or voice variety.\u003C/p>\n\u003Cp>\u003Cstrong>Generate a multi-provider template:\u003C/strong>\u003C/p>\n\u003Cp>Start by generating a configuration file that shows statistics for each speaker:\u003C/p>\n\u003Cpre class=\"astro-code github-dark\" style=\"background-color:#24292e;color:#e1e4e8; overflow-x: auto;\" tabindex=\"0\" data-language=\"bash\">\u003Ccode>\u003Cspan class=\"line\">\u003Cspan style=\"color:#6A737D\"># Generate multi-provider configuration\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#B392F0\">uv\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> run\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> sts-tts-provider-yaml\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> generate\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> input/your_script/your_script.json\u003C/span>\u003C/span>\u003C/code>\u003C/pre>\n\u003Cp>This creates a config with speaker statistics at \u003Ccode>input/your_script/your_script_voice_config.yaml\u003C/code>:\u003C/p>\n\u003Cpre class=\"astro-code github-dark\" style=\"background-color:#24292e;color:#e1e4e8; overflow-x: auto;\" tabindex=\"0\" data-language=\"yaml\">\u003Ccode>\u003Cspan class=\"line\">\u003Cspan style=\"color:#6A737D\"># default: 1556 lines - Used for all non-dialogue pieces\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#6A737D\"># Total characters: 104244, Longest dialogue: 2082 characters\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#85E89D\">default\u003C/span>\u003Cspan style=\"color:#E1E4E8\">:\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#85E89D\">  provider\u003C/span>\u003Cspan style=\"color:#E1E4E8\">:\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#6A737D\"># ALICE: 283 lines\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#6A737D\"># Total characters: 12181, Longest dialogue: 365 characters\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#85E89D\">ALICE\u003C/span>\u003Cspan style=\"color:#E1E4E8\">:\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#85E89D\">  provider\u003C/span>\u003Cspan style=\"color:#E1E4E8\">:\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#6A737D\"># BOB: 120 lines\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#6A737D\"># Total characters: 9123, Longest dialogue: 253 characters\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#85E89D\">BOB\u003C/span>\u003Cspan style=\"color:#E1E4E8\">:\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#85E89D\">  provider\u003C/span>\u003Cspan style=\"color:#E1E4E8\">:\u003C/span>\u003C/span>\u003C/code>\u003C/pre>\n\u003Cp>\u003Cstrong>Assign providers to speakers:\u003C/strong>\u003C/p>\n\u003Cp>Edit the file to assign TTS providers based on character importance, line count, and voice requirements. You can also add provider-specific fields at this stage:\u003C/p>\n\u003Cpre class=\"astro-code github-dark\" style=\"background-color:#24292e;color:#e1e4e8; overflow-x: auto;\" tabindex=\"0\" data-language=\"yaml\">\u003Ccode>\u003Cspan class=\"line\">\u003Cspan style=\"color:#6A737D\"># default: 1556 lines - Used for all non-dialogue pieces\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#6A737D\"># Total characters: 104244, Longest dialogue: 2082 characters\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#85E89D\">default\u003C/span>\u003Cspan style=\"color:#E1E4E8\">:\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#85E89D\">  provider\u003C/span>\u003Cspan style=\"color:#E1E4E8\">: \u003C/span>\u003Cspan style=\"color:#9ECBFF\">openai\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#6A737D\"># ALICE: 283 lines\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#6A737D\"># Total characters: 12181, Longest dialogue: 365 characters\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#85E89D\">ALICE\u003C/span>\u003Cspan style=\"color:#E1E4E8\">:\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#85E89D\">  provider\u003C/span>\u003Cspan style=\"color:#E1E4E8\">: \u003C/span>\u003Cspan style=\"color:#9ECBFF\">openai\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#85E89D\">  voice\u003C/span>\u003Cspan style=\"color:#E1E4E8\">: \u003C/span>\u003Cspan style=\"color:#9ECBFF\">alloy\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#6A737D\"># BOB: 120 lines\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#6A737D\"># Total characters: 9123, Longest dialogue: 253 characters\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#85E89D\">BOB\u003C/span>\u003Cspan style=\"color:#E1E4E8\">:\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#85E89D\">  provider\u003C/span>\u003Cspan style=\"color:#E1E4E8\">: \u003C/span>\u003Cspan style=\"color:#9ECBFF\">elevenlabs\u003C/span>\u003C/span>\u003C/code>\u003C/pre>\n\u003Cp>\u003Cstrong>Populate provider-specific fields:\u003C/strong>\u003C/p>\n\u003Cp>Once providers are assigned, populate the remaining provider-specific fields:\u003C/p>\n\u003Cpre class=\"astro-code github-dark\" style=\"background-color:#24292e;color:#e1e4e8; overflow-x: auto;\" tabindex=\"0\" data-language=\"bash\">\u003Ccode>\u003Cspan class=\"line\">\u003Cspan style=\"color:#B392F0\">uv\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> run\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> sts-tts-provider-yaml\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> populate\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> input/your_script/your_script.json\u003C/span>\u003Cspan style=\"color:#79B8FF\"> \\\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#9ECBFF\">  input/your_script/your_script_voice_config.yaml\u003C/span>\u003C/span>\u003C/code>\u003C/pre>\n\u003Cp>This creates \u003Ccode>input/your_script/your_script_voice_config_populated.yaml\u003C/code> with provider-specific fields grouped by provider. Fill in the required fields for each provider according to the instructions at the top of each section. For detailed provider information, see the \u003Ca href=\"docs/TTS_PROVIDERS.md\">TTS Providers documentation\u003C/a>.\u003C/p>\n\u003Ch3 id=\"optional-llm-assisted-voice-casting\">(Optional) LLM-Assisted Voice Casting\u003C/h3>\n\u003Cp>Script to Speech provides two LLM-assisted tools that work together to help cast voices for your screenplay characters:\u003C/p>\n\u003Col>\n\u003Cli>\u003Cstrong>Character Notes Generation\u003C/strong> - Analyzes your screenplay to create casting notes for each character\u003C/li>\n\u003Cli>\u003Cstrong>Voice Library Casting\u003C/strong> - Uses those notes to select specific voices from provider voice libraries\u003C/li>\n\u003C/ol>\n\u003Cblockquote>\n\u003Cp>\u003Cstrong>⚠️ PRIVACY WARNING\u003C/strong>:\u003C/p>\n\u003Cul>\n\u003Cli>\u003Ccode>sts-generate-character-notes-prompt\u003C/code> creates a prompt containing the \u003Cstrong>full text\u003C/strong> of your screenplay\u003C/li>\n\u003Cli>\u003Ccode>sts-generate-voice-library-casting-prompt\u003C/code> creates a prompt containing your character list and any casting notes (but not the screenplay text)\u003C/li>\n\u003C/ul>\n\u003Cp>Before using any cloud-based LLM service:\u003C/p>\n\u003Cul>\n\u003Cli>Review their privacy policy and data usage practices\u003C/li>\n\u003Cli>Ensure you’re comfortable sharing your content\u003C/li>\n\u003Cli>Consider whether the LLM provider uses uploaded content for training\u003C/li>\n\u003Cli>For sensitive content, consider using local LLM solutions or manually configuring voices\u003C/li>\n\u003C/ul>\n\u003Cp>See our \u003Ca href=\"PRIVACY.md\">Privacy Policy\u003C/a> for detailed guidance on privacy-conscious usage.\u003C/p>\n\u003C/blockquote>\n\u003Ch4 id=\"step-1-generate-character-notes-optional\">Step 1: Generate Character Notes (Optional)\u003C/h4>\n\u003Cp>For complex scripts with many characters, you can use an LLM to generate casting notes (gender, vocal qualities, role summary, etc.) for each speaker:\u003C/p>\n\u003Cpre class=\"astro-code github-dark\" style=\"background-color:#24292e;color:#e1e4e8; overflow-x: auto;\" tabindex=\"0\" data-language=\"bash\">\u003Ccode>\u003Cspan class=\"line\">\u003Cspan style=\"color:#6A737D\"># Generate a prompt file for LLM-assisted character analysis\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#B392F0\">uv\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> run\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> sts-generate-character-notes-prompt\u003C/span>\u003Cspan style=\"color:#79B8FF\"> \\\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#9ECBFF\">  source_screenplays/your_script.pdf\u003C/span>\u003Cspan style=\"color:#79B8FF\"> \\\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#9ECBFF\">  input/your_script/your_script_voice_config.yaml\u003C/span>\u003C/span>\u003C/code>\u003C/pre>\n\u003Cp>This creates \u003Ccode>input/your_script/your_script_character_notes_prompt.txt\u003C/code> containing:\u003C/p>\n\u003Cul>\n\u003Cli>Instructions for the LLM to provide casting notes for each character\u003C/li>\n\u003Cli>Your current voice configuration\u003C/li>\n\u003Cli>The full screenplay text\u003C/li>\n\u003C/ul>\n\u003Ch4 id=\"step-2-copy-prompt-to-clipboard\">Step 2: Copy Prompt to Clipboard\u003C/h4>\n\u003Cpre class=\"astro-code github-dark\" style=\"background-color:#24292e;color:#e1e4e8; overflow-x: auto;\" tabindex=\"0\" data-language=\"bash\">\u003Ccode>\u003Cspan class=\"line\">\u003Cspan style=\"color:#6A737D\"># Copy the generated prompt to your clipboard for easy pasting into an LLM\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#B392F0\">uv\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> run\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> sts-copy-to-clipboard\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> input/your_script/your_script_character_notes_prompt.txt\u003C/span>\u003C/span>\u003C/code>\u003C/pre>\n\u003Ch4 id=\"step-3-update-configuration-with-character-notes\">Step 3: Update Configuration with Character Notes\u003C/h4>\n\u003Cp>After receiving the LLM’s output with character notes added as YAML comments, save the updated configuration back to your voice config file.\u003C/p>\n\u003Ch4 id=\"step-4-cast-voices-from-library-optional\">Step 4: Cast Voices from Library (Optional)\u003C/h4>\n\u003Cp>Once you have character notes (either from the LLM or manually added), you can use voice library casting to automatically select appropriate voices:\u003C/p>\n\u003Cpre class=\"astro-code github-dark\" style=\"background-color:#24292e;color:#e1e4e8; overflow-x: auto;\" tabindex=\"0\" data-language=\"bash\">\u003Ccode>\u003Cspan class=\"line\">\u003Cspan style=\"color:#6A737D\"># Generate a prompt for voice library casting\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#B392F0\">uv\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> run\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> sts-generate-voice-library-casting-prompt\u003C/span>\u003Cspan style=\"color:#79B8FF\"> \\\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#9ECBFF\">  input/your_script/your_script_voice_config.yaml\u003C/span>\u003Cspan style=\"color:#79B8FF\"> \\\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#9ECBFF\">  openai\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> elevenlabs\u003C/span>\u003C/span>\u003C/code>\u003C/pre>\n\u003Cp>This creates \u003Ccode>input/your_script/your_script_voice_config_voice_library_casting_prompt.txt\u003C/code> containing:\u003C/p>\n\u003Cul>\n\u003Cli>Instructions for the LLM to select voices from the specified provider libraries\u003C/li>\n\u003Cli>Your voice configuration with character notes\u003C/li>\n\u003Cli>Voice library data for the specified providers\u003C/li>\n\u003C/ul>\n\u003Cp>Note: You can specify multiple providers (e.g., \u003Ccode>openai elevenlabs cartesia\u003C/code>) to cast from multiple voice libraries simultaneously.\u003C/p>\n\u003Ch4 id=\"step-5-apply-voice-selections\">Step 5: Apply Voice Selections\u003C/h4>\n\u003Cp>Copy the prompt to clipboard and paste into your LLM:\u003C/p>\n\u003Cpre class=\"astro-code github-dark\" style=\"background-color:#24292e;color:#e1e4e8; overflow-x: auto;\" tabindex=\"0\" data-language=\"bash\">\u003Ccode>\u003Cspan class=\"line\">\u003Cspan style=\"color:#B392F0\">uv\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> run\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> sts-copy-to-clipboard\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> input/your_script/your_script_voice_config_voice_library_casting_prompt.txt\u003C/span>\u003C/span>\u003C/code>\u003C/pre>\n\u003Cp>The LLM will return your configuration with \u003Ccode>sts_id\u003C/code> fields populated with specific voice selections from the libraries.\u003C/p>\n\u003Ch4 id=\"step-6-validate-configuration\">Step 6: Validate Configuration\u003C/h4>\n\u003Cp>After receiving updated voice configuration from the LLM, validate it:\u003C/p>\n\u003Cpre class=\"astro-code github-dark\" style=\"background-color:#24292e;color:#e1e4e8; overflow-x: auto;\" tabindex=\"0\" data-language=\"bash\">\u003Ccode>\u003Cspan class=\"line\">\u003Cspan style=\"color:#6A737D\"># Check for missing/extra/duplicate speakers and provider field issues\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#B392F0\">uv\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> run\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> sts-tts-provider-yaml\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> validate\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> input/your_script/your_script.json\u003C/span>\u003Cspan style=\"color:#79B8FF\"> \\\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#9ECBFF\">  input/your_script/your_script_voice_config.yaml\u003C/span>\u003Cspan style=\"color:#79B8FF\"> --strict\u003C/span>\u003C/span>\u003C/code>\u003C/pre>\n\u003Ch4 id=\"privacy-conscious-alternative-workflow\">Privacy-Conscious Alternative Workflow\u003C/h4>\n\u003Cp>For sensitive screenplays, you can skip character notes generation and manually add casting notes:\u003C/p>\n\u003Col>\n\u003Cli>Manually edit your voice configuration to add character descriptions as YAML comments\u003C/li>\n\u003Cli>Use only \u003Ccode>sts-generate-voice-library-casting-prompt\u003C/code> (which doesn’t include screenplay text)\u003C/li>\n\u003Cli>This way, only character names and your notes are shared with the LLM, not the screenplay content\u003C/li>\n\u003C/ol>\n\u003Ch3 id=\"custom-text-processing\">Custom Text Processing\u003C/h3>\n\u003Cp>Script to Speech allows you to customize how text is processed before being sent to TTS providers. This is useful for expanding abbreviations, handling special formatting, or adjusting capitalization.\u003C/p>\n\u003Cp>Custom text processor configurations will chain with the default configuration. By default, the program looks for a file named after your dialogue chunk file with \u003Ccode>_text_processor_config.yaml\u003C/code> appended.\u003C/p>\n\u003Cp>To create a custom config, create \u003Ccode>input/your_script/your_script_text_processor_config.yaml\u003C/code>:\u003C/p>\n\u003Cpre class=\"astro-code github-dark\" style=\"background-color:#24292e;color:#e1e4e8; overflow-x: auto;\" tabindex=\"0\" data-language=\"yaml\">\u003Ccode>\u003Cspan class=\"line\">\u003Cspan style=\"color:#85E89D\">processors\u003C/span>\u003Cspan style=\"color:#E1E4E8\">:\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#E1E4E8\">  - \u003C/span>\u003Cspan style=\"color:#85E89D\">name\u003C/span>\u003Cspan style=\"color:#E1E4E8\">: \u003C/span>\u003Cspan style=\"color:#9ECBFF\">text_substitution\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#85E89D\">    config\u003C/span>\u003Cspan style=\"color:#E1E4E8\">:\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#85E89D\">      substitutions\u003C/span>\u003Cspan style=\"color:#E1E4E8\">:\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#E1E4E8\">        - \u003C/span>\u003Cspan style=\"color:#85E89D\">from\u003C/span>\u003Cspan style=\"color:#E1E4E8\">: \u003C/span>\u003Cspan style=\"color:#9ECBFF\">\"CU\"\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#85E89D\">          to\u003C/span>\u003Cspan style=\"color:#E1E4E8\">: \u003C/span>\u003Cspan style=\"color:#9ECBFF\">\"close up\"\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#85E89D\">          fields\u003C/span>\u003Cspan style=\"color:#E1E4E8\">:\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#E1E4E8\">            - \u003C/span>\u003Cspan style=\"color:#9ECBFF\">text\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#E1E4E8\">        - \u003C/span>\u003Cspan style=\"color:#85E89D\">from\u003C/span>\u003Cspan style=\"color:#E1E4E8\">: \u003C/span>\u003Cspan style=\"color:#9ECBFF\">\"P.O.V\"\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#85E89D\">          to\u003C/span>\u003Cspan style=\"color:#E1E4E8\">: \u003C/span>\u003Cspan style=\"color:#9ECBFF\">\"point of view\"\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#85E89D\">          fields\u003C/span>\u003Cspan style=\"color:#E1E4E8\">:\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#E1E4E8\">            - \u003C/span>\u003Cspan style=\"color:#9ECBFF\">text\u003C/span>\u003C/span>\u003C/code>\u003C/pre>\n\u003Cp>For more information about text processor transformations and creating your own, see the \u003Ca href=\"docs/TEXT_PROCESSORS.md\">Text Processing Guide\u003C/a>.\u003C/p>\n\u003Ch3 id=\"iterative-audio-generation-with-run-modes\">Iterative Audio Generation with Run Modes\u003C/h3>\n\u003Cp>Script to Speech supports various run modes to test and iteratively refine your audiobook before generating the final output. This workflow is particularly useful for large projects where you want to ensure quality before committing to full generation.\u003C/p>\n\u003Cp>\u003Cstrong>Dry Run Testing\u003C/strong>\u003C/p>\n\u003Cp>Start by validating your configuration without generating any audio:\u003C/p>\n\u003Cpre class=\"astro-code github-dark\" style=\"background-color:#24292e;color:#e1e4e8; overflow-x: auto;\" tabindex=\"0\" data-language=\"bash\">\u003Ccode>\u003Cspan class=\"line\">\u003Cspan style=\"color:#B392F0\">uv\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> run\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> sts-generate-audio\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> input/your_script/your_script.json\u003C/span>\u003Cspan style=\"color:#79B8FF\"> \\\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#9ECBFF\">  input/your_script/your_script_voice_config.yaml\u003C/span>\u003Cspan style=\"color:#79B8FF\"> \\\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#79B8FF\">  --dry-run\u003C/span>\u003C/span>\u003C/code>\u003C/pre>\n\u003Cp>Use cases:\u003C/p>\n\u003Cul>\n\u003Cli>Validating configuration files\u003C/li>\n\u003Cli>Determining which audio files will be generated\u003C/li>\n\u003Cli>Checking for potential issues before spending on API calls\u003C/li>\n\u003C/ul>\n\u003Cp>\u003Cstrong>Building the Audio Cache\u003C/strong>\u003C/p>\n\u003Cp>Generate all audio clips without creating the final MP3:\u003C/p>\n\u003Cpre class=\"astro-code github-dark\" style=\"background-color:#24292e;color:#e1e4e8; overflow-x: auto;\" tabindex=\"0\" data-language=\"bash\">\u003Ccode>\u003Cspan class=\"line\">\u003Cspan style=\"color:#B392F0\">uv\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> run\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> sts-generate-audio\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> input/your_script/your_script.json\u003C/span>\u003Cspan style=\"color:#79B8FF\"> \\\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#9ECBFF\">  input/your_script/your_script_voice_config.yaml\u003C/span>\u003Cspan style=\"color:#79B8FF\"> \\\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#79B8FF\">  --populate-cache\u003C/span>\u003Cspan style=\"color:#79B8FF\"> --check-silence\u003C/span>\u003C/span>\u003C/code>\u003C/pre>\n\u003Cp>This approach allows you to:\u003C/p>\n\u003Cul>\n\u003Cli>Check for silent or problematic clips before final generation\u003C/li>\n\u003Cli>Build your cache incrementally (process can be resumed if interrupted)\u003C/li>\n\u003Cli>Review individual clips for quality\u003C/li>\n\u003Cli>Replace specific clips with better “takes”\u003C/li>\n\u003C/ul>\n\u003Cp>\u003Cstrong>Replacing Problem Audio\u003C/strong>\u003C/p>\n\u003Cp>If silent clips are detected or you want to re-record specific lines:\u003C/p>\n\u003Cpre class=\"astro-code github-dark\" style=\"background-color:#24292e;color:#e1e4e8; overflow-x: auto;\" tabindex=\"0\" data-language=\"bash\">\u003Ccode>\u003Cspan class=\"line\">\u003Cspan style=\"color:#6A737D\"># Generate replacement audio\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#B392F0\">uv\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> run\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> sts-generate-standalone-speech\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> openai\u003C/span>\u003Cspan style=\"color:#79B8FF\"> --voice\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> echo\u003C/span>\u003Cspan style=\"color:#79B8FF\"> \\\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#9ECBFF\">  \"Replace this silent text number 1\"\u003C/span>\u003Cspan style=\"color:#79B8FF\"> \\\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#9ECBFF\">  \"Replace this silent text number 2\"\u003C/span>\u003Cspan style=\"color:#79B8FF\"> \\\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#79B8FF\">  -v\u003C/span>\u003Cspan style=\"color:#79B8FF\"> 3\u003C/span>\u003Cspan style=\"color:#6A737D\">  # Generate 3 variations of each line\u003C/span>\u003C/span>\u003C/code>\u003C/pre>\n\u003Cp>Rename the generated file to match the cache filename (as reported in console output or logs):\u003C/p>\n\u003Cpre class=\"astro-code github-dark\" style=\"background-color:#24292e;color:#e1e4e8; overflow-x: auto;\" tabindex=\"0\" data-language=\"bash\">\u003Ccode>\u003Cspan class=\"line\">\u003Cspan style=\"color:#B392F0\">mv\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> standalone_speech/generated_file.mp3\u003C/span>\u003Cspan style=\"color:#79B8FF\"> \\\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#9ECBFF\">  standalone_speech/[original_cache_filename].mp3\u003C/span>\u003C/span>\u003C/code>\u003C/pre>\n\u003Cp>Apply the replacements:\u003C/p>\n\u003Cpre class=\"astro-code github-dark\" style=\"background-color:#24292e;color:#e1e4e8; overflow-x: auto;\" tabindex=\"0\" data-language=\"bash\">\u003Ccode>\u003Cspan class=\"line\">\u003Cspan style=\"color:#B392F0\">uv\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> run\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> sts-generate-audio\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> input/your_script/your_script.json\u003C/span>\u003Cspan style=\"color:#79B8FF\"> \\\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#9ECBFF\">  input/your_script/your_script_voice_config.yaml\u003C/span>\u003Cspan style=\"color:#79B8FF\"> \\\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#79B8FF\">  --populate-cache\u003C/span>\u003Cspan style=\"color:#79B8FF\"> --cache-overrides\u003C/span>\u003Cspan style=\"color:#79B8FF\"> --check-silence\u003C/span>\u003C/span>\u003C/code>\u003C/pre>\n\u003Cp>See \u003Ca href=\"docs/STANDALONE_SPEECH.md\">Standalone Speech Generation\u003C/a> for more details and usage options\u003C/p>\n\u003Cp>\u003Cstrong>Final Generation\u003C/strong>\u003C/p>\n\u003Cp>Once all audio is cached and verified:\u003C/p>\n\u003Cpre class=\"astro-code github-dark\" style=\"background-color:#24292e;color:#e1e4e8; overflow-x: auto;\" tabindex=\"0\" data-language=\"bash\">\u003Ccode>\u003Cspan class=\"line\">\u003Cspan style=\"color:#B392F0\">uv\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> run\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> sts-generate-audio\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> input/your_script/your_script.json\u003C/span>\u003Cspan style=\"color:#79B8FF\"> \\\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#9ECBFF\">  input/your_script/your_script_voice_config.yaml\u003C/span>\u003C/span>\u003C/code>\u003C/pre>\n\u003Cp>This combines all cached audio into the final audiobook with proper gaps and ID3 tags.\u003C/p>\n\u003Cp>For detailed information about all available run modes and options, see the \u003Ca href=\"docs/RUN_MODES.md\">Run Modes documentation\u003C/a>.\u003C/p>\n\u003Ch2 id=\"directory-structure\">Directory Structure\u003C/h2>\n\u003Cp>Script to Speech uses a number of default locations to simplify workflows. The following lists standard files you will likely encounter while running the program. Directories \u003Ccode>input/[screenplay_name]\u003C/code> and \u003Ccode>output/[screenplay_name]\u003C/code> will automatically be created when the screenplay is parsed.\u003C/p>\n\u003Cpre class=\"astro-code github-dark\" style=\"background-color:#24292e;color:#e1e4e8; overflow-x: auto;\" tabindex=\"0\" data-language=\"plaintext\">\u003Ccode>\u003Cspan class=\"line\">\u003Cspan>source_screenplays/                   # Original screenplay files\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan>input/\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan>└── [screenplay_name]/\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan>    ├── [screenplay_name].pdf         # Copied screenplay\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan>    ├── [screenplay_name].txt         # Extracted text (if parser run with --text-only)\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan>    ├── [screenplay_name].json        # Parsed dialogue chunks\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan>    ├── [screenplay_name]_optional_config.yaml          # ID3 tag configuration\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan>    ├── [screenplay_name]_text_processor_config.yaml    # (optional) Custom text processors\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan>    ├── [screenplay_name]_voice_config.yaml             # TTS provider config\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan>    ├── [screenplay_name]_voice_config_populated.yaml   # TTS provider config populated with multi-provider options\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan>    ├── [screenplay_name]_character_notes_prompt.txt      # (optional) LLM character notes prompt\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan>    └── [screenplay_name]_voice_config_voice_library_casting_prompt.txt  # (optional) LLM voice library casting prompt\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan>\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan>output/\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan>└── [screenplay_name]/\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan>    ├── [screenplay_name].mp3                  # Final audiobook\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan>    ├── [screenplay_name]-text-processed.json  # Dialogue chunks with text processors applied\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan>    ├── cache/                                 # Generated audio clips\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan>    └── logs/                                  # Parsing and generation logs\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan>\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan>standalone_speech/                             # Override audio files\u003C/span>\u003C/span>\u003C/code>\u003C/pre>\n\u003Ch2 id=\"run-modes\">Run Modes\u003C/h2>\n\u003Cul>\n\u003Cli>\u003Cstrong>Default\u003C/strong>: Generate complete audiobook\u003C/li>\n\u003Cli>\u003Cstrong>—dry-run\u003C/strong>: Test configuration without generating audio\u003C/li>\n\u003Cli>\u003Cstrong>—populate-cache\u003C/strong>: Generate and cache audio only (no final MP3)\u003C/li>\n\u003C/ul>\n\u003Cp>See \u003Ca href=\"doc/RUN_MODES.md\">RUN_MODES.md\u003C/a> for detailed information.\u003C/p>\n\u003Ch2 id=\"text-processing\">Text Processing\u003C/h2>\n\u003Cp>Script to Speech supports flexible text processing through preprocessors and processors:\u003C/p>\n\u003Cul>\n\u003Cli>\u003Cstrong>Preprocessors\u003C/strong>: Modify the dialogue structure\u003C/li>\n\u003Cli>\u003Cstrong>Processors\u003C/strong>: Transform individual text lines\u003C/li>\n\u003C/ul>\n\u003Cp>See \u003Ca href=\"docs/TEXT_PROCESSORS.md\">TEXT_PROCESSORS.md\u003C/a> for configuration details.\u003C/p>\n\u003Ch2 id=\"tts-providers\">TTS Providers\u003C/h2>\n\u003Cp>Supported TTS providers:\u003C/p>\n\u003Cul>\n\u003Cli>\u003Cstrong>OpenAI\u003C/strong>: Preview voices at \u003Ca href=\"https://www.openai.fm/\">openai.fm\u003C/a>\u003C/li>\n\u003Cli>\u003Cstrong>ElevenLabs\u003C/strong>: Requires “Creator” plan, uses public library voices\u003C/li>\n\u003Cli>\u003Cstrong>Cartesia\u003C/strong>: TTS with a free plan and a number of voices\u003C/li>\n\u003Cli>\u003Cstrong>Minimax\u003C/strong>: TTS with voice mixing capabilities and emotion control\u003C/li>\n\u003Cli>\u003Cstrong>Zonos\u003C/strong>: TTS service with a free plan and a few voices\u003C/li>\n\u003Cli>\u003Cstrong>Dummy\u003C/strong>: Testing only\u003C/li>\n\u003C/ul>\n\u003Cp>See \u003Ca href=\"docs/TTS_PROVIDERS.md\">TTS_PROVIDERS.md\u003C/a> for provider-specific configuration.\u003C/p>\n\u003Ch2 id=\"advanced-topics\">Advanced Topics\u003C/h2>\n\u003Ch3 id=\"sharing-cache-for-re-casting\">Sharing Cache for Re-casting\u003C/h3>\n\u003Cp>The \u003Ccode>input\u003C/code> and \u003Ccode>output\u003C/code> folders (including cache) can be shared between users to reuse audio when changing select voices:\u003C/p>\n\u003Col>\n\u003Cli>Share \u003Ccode>input/[screenplay_name]\u003C/code> and \u003Ccode>output/[screenplay_name]\u003C/code> folders\u003C/li>\n\u003Cli>Edit voice configuration for desired speakers\u003C/li>\n\u003Cli>Run with existing cache to preserve unchanged audio\u003C/li>\n\u003C/ol>\n\u003Ch3 id=\"multi-threaded-downloads\">Multi-threaded Downloads\u003C/h3>\n\u003Cp>Downloads are multi-threaded with separate queues per provider. Distributing voices across TTS providers speeds up generation.\u003C/p>\n\u003Ch3 id=\"cache-management\">Cache Management\u003C/h3>\n\u003Cp>Generated audio is cached in \u003Ccode>output/[screenplay_name]/cache/\u003C/code>. Cache files are uniquely named based on:\u003C/p>\n\u003Cul>\n\u003Cli>Speaker configuration\u003C/li>\n\u003Cli>TTS provider\u003C/li>\n\u003Cli>Text content\u003C/li>\n\u003Cli>Processing parameters\u003C/li>\n\u003C/ul>\n\u003Cp>Changes in any of the above will mark just the relevant clips for regeneration upon the next run\u003C/p>\n\u003Ch2 id=\"troubleshooting\">Troubleshooting\u003C/h2>\n\u003Ch3 id=\"common-issues\">Common Issues\u003C/h3>\n\u003Col>\n\u003Cli>\n\u003Cp>\u003Cstrong>Silent Audio Detected\u003C/strong>\u003C/p>\n\u003Cul>\n\u003Cli>Use \u003Ccode>--check-silence\u003C/code> to identify silent clips\u003C/li>\n\u003Cli>Generate replacements with \u003Ccode>sts-generate-standalone-speech\u003C/code>\u003C/li>\n\u003Cli>Apply with \u003Ccode>--cache-overrides\u003C/code>\u003C/li>\n\u003C/ul>\n\u003C/li>\n\u003Cli>\n\u003Cp>\u003Cstrong>Rate Limiting\u003C/strong>\u003C/p>\n\u003Cul>\n\u003Cli>Each provider has different rate limits\u003C/li>\n\u003Cli>The tool automatically handles backoff\u003C/li>\n\u003Cli>Spread voices across TTS providers to avoid limits\u003C/li>\n\u003C/ul>\n\u003C/li>\n\u003Cli>\n\u003Cp>\u003Cstrong>Voice Configuration Errors\u003C/strong>\u003C/p>\n\u003Cul>\n\u003Cli>Use \u003Ccode>sts-tts-provider-yaml validate\u003C/code> to check for missing/extra/duplicate speakers\u003C/li>\n\u003Cli>Use \u003Ccode>--strict\u003C/code> flag to validate provider-specific fields\u003C/li>\n\u003Cli>Check voice IDs match provider requirements\u003C/li>\n\u003C/ul>\n\u003C/li>\n\u003Cli>\n\u003Cp>\u003Cstrong>Screenplay is parsed incorrectly\u003C/strong>\u003C/p>\n\u003Cul>\n\u003Cli>The parser is currently fairly fragile, and expects “standard” screenplay files with predictable margins and conventions. Additional configuration options, and automatic configuration, is planned for future releases\u003C/li>\n\u003C/ul>\n\u003C/li>\n\u003Cli>\n\u003Cp>\u003Cstrong>Headers/Footers Appearing in Parsed Output\u003C/strong>\u003C/p>\n\u003Cul>\n\u003Cli>Use \u003Ccode>sts-detect-headers\u003C/code> to identify recurring patterns\u003C/li>\n\u003Cli>Apply detected patterns with \u003Ccode>--remove\u003C/code> option during parsing\u003C/li>\n\u003Cli>Use \u003Ccode>--text-only\u003C/code> to manually edit problematic content\u003C/li>\n\u003C/ul>\n\u003C/li>\n\u003C/ol>\n\u003Cp>See \u003Ca href=\"docs/TROUBLESHOOTING.md\">TROUBLESHOOTING.md\u003C/a> for more solutions.\u003C/p>\n\u003Ch2 id=\"environment-variables\">Environment Variables\u003C/h2>\n\u003Cp>Required for TTS providers:\u003C/p>\n\u003Cul>\n\u003Cli>\u003Ccode>OPENAI_API_KEY\u003C/code>: OpenAI API access\u003C/li>\n\u003Cli>\u003Ccode>ELEVEN_API_KEY\u003C/code>: ElevenLabs API access\u003C/li>\n\u003Cli>\u003Ccode>CARTESIA_API_KEY\u003C/code>: Cartesia API access\u003C/li>\n\u003Cli>\u003Ccode>MINIMAX_API_KEY\u003C/code>: Minimax API access\u003C/li>\n\u003Cli>\u003Ccode>MINIMAX_GROUP_ID\u003C/code>: Minimax Group ID\u003C/li>\n\u003Cli>\u003Ccode>ZONOS_API_KEY\u003C/code>: Zonos API access\u003C/li>\n\u003C/ul>\n\u003Ch3 id=\"using-env-files-recommended\">Using .env Files (Recommended)\u003C/h3>\n\u003Cp>For local development, you can use a \u003Ccode>.env\u003C/code> file to store your API keys instead of setting them as environment variables in your shell. This approach is more convenient and for developers, helps prevent accidental exposure of your keys.\u003C/p>\n\u003Col>\n\u003Cli>\n\u003Cp>Copy the provided \u003Ccode>.env.example\u003C/code> file to a new file named \u003Ccode>.env\u003C/code> in the project root:\u003C/p>\n\u003Cpre class=\"astro-code github-dark\" style=\"background-color:#24292e;color:#e1e4e8; overflow-x: auto;\" tabindex=\"0\" data-language=\"bash\">\u003Ccode>\u003Cspan class=\"line\">\u003Cspan style=\"color:#B392F0\">cp\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> .env.example\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> .env\u003C/span>\u003C/span>\u003C/code>\u003C/pre>\n\u003C/li>\n\u003Cli>\n\u003Cp>Edit the \u003Ccode>.env\u003C/code> file and add your API keys:\u003C/p>\n\u003Cpre class=\"astro-code github-dark\" style=\"background-color:#24292e;color:#e1e4e8; overflow-x: auto;\" tabindex=\"0\" data-language=\"plaintext\">\u003Ccode>\u003Cspan class=\"line\">\u003Cspan>OPENAI_API_KEY=\"your-openai-key-here\"\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan>ELEVEN_API_KEY=\"your-elevenlabs-key-here\"\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan># Add other keys as needed\u003C/span>\u003C/span>\u003C/code>\u003C/pre>\n\u003C/li>\n\u003Cli>\n\u003Cp>The application will automatically load these variables when it starts.\u003C/p>\n\u003C/li>\n\u003C/ol>\n\u003Cp>\u003Cstrong>Note\u003C/strong>: The \u003Ccode>.env\u003C/code> file is excluded from version control via \u003Ccode>.gitignore\u003C/code> to prevent accidentally committing your API keys. Never commit your actual API keys to version control.\u003C/p>\n\u003Ch2 id=\"license\">License\u003C/h2>\n\u003Cp>MIT licensed. See \u003Ca href=\"LICENSE\">LICENSE\u003C/a> for more information\u003C/p>",{"headings":313,"localImagePaths":435,"remoteImagePaths":436,"frontmatter":437,"imagePaths":438},[314,317,320,323,326,329,332,333,336,339,342,345,348,351,354,357,360,363,366,369,372,375,378,381,384,387,390,393,396,399,402,405,408,411,414,417,420,423,426,427,428,429,432],{"depth":22,"slug":315,"text":316},"script-to-speech","Script to Speech",{"depth":26,"slug":318,"text":319},"key-features","Key Features",{"depth":26,"slug":321,"text":322},"privacy--data-handling","Privacy & Data Handling",{"depth":26,"slug":324,"text":325},"cli-usage","CLI Usage",{"depth":26,"slug":327,"text":328},"cli-commands","CLI Commands",{"depth":26,"slug":330,"text":331},"quick-start","Quick Start",{"depth":30,"slug":31,"text":32},{"depth":30,"slug":334,"text":335},"for-basic-usage","For Basic Usage",{"depth":30,"slug":337,"text":338},"for-development","For Development",{"depth":26,"slug":340,"text":341},"basic-workflow","Basic Workflow",{"depth":30,"slug":343,"text":344},"step-1-setup-accounts-with-tts-services-and-configure","Step 1: Setup Accounts with TTS Services and Configure",{"depth":30,"slug":346,"text":347},"step-2-add-screenplay","Step 2: Add Screenplay",{"depth":30,"slug":349,"text":350},"step-3-parse-screenplay","Step 3: Parse Screenplay",{"depth":30,"slug":352,"text":353},"step-4-generate-tts-provider-configuration","Step 4: Generate TTS Provider Configuration",{"depth":30,"slug":355,"text":356},"step-5-configure-voices","Step 5: Configure Voices",{"depth":30,"slug":358,"text":359},"step-6-configure-id3-tags-optional","Step 6: Configure ID3 Tags (Optional)",{"depth":30,"slug":361,"text":362},"step-7-generate-audio","Step 7: Generate Audio",{"depth":26,"slug":364,"text":365},"advanced-workflow","Advanced Workflow",{"depth":30,"slug":367,"text":368},"advanced-screenplay-parsing","Advanced Screenplay Parsing",{"depth":30,"slug":370,"text":371},"multi-provider-voice-configuration","Multi-Provider Voice Configuration",{"depth":30,"slug":373,"text":374},"optional-llm-assisted-voice-casting","(Optional) LLM-Assisted Voice Casting",{"depth":259,"slug":376,"text":377},"step-1-generate-character-notes-optional","Step 1: Generate Character Notes (Optional)",{"depth":259,"slug":379,"text":380},"step-2-copy-prompt-to-clipboard","Step 2: Copy Prompt to Clipboard",{"depth":259,"slug":382,"text":383},"step-3-update-configuration-with-character-notes","Step 3: Update Configuration with Character Notes",{"depth":259,"slug":385,"text":386},"step-4-cast-voices-from-library-optional","Step 4: Cast Voices from Library (Optional)",{"depth":259,"slug":388,"text":389},"step-5-apply-voice-selections","Step 5: Apply Voice Selections",{"depth":259,"slug":391,"text":392},"step-6-validate-configuration","Step 6: Validate Configuration",{"depth":259,"slug":394,"text":395},"privacy-conscious-alternative-workflow","Privacy-Conscious Alternative Workflow",{"depth":30,"slug":397,"text":398},"custom-text-processing","Custom Text Processing",{"depth":30,"slug":400,"text":401},"iterative-audio-generation-with-run-modes","Iterative Audio Generation with Run Modes",{"depth":26,"slug":403,"text":404},"directory-structure","Directory Structure",{"depth":26,"slug":406,"text":407},"run-modes","Run Modes",{"depth":26,"slug":409,"text":410},"text-processing","Text Processing",{"depth":26,"slug":412,"text":413},"tts-providers","TTS Providers",{"depth":26,"slug":415,"text":416},"advanced-topics","Advanced Topics",{"depth":30,"slug":418,"text":419},"sharing-cache-for-re-casting","Sharing Cache for Re-casting",{"depth":30,"slug":421,"text":422},"multi-threaded-downloads","Multi-threaded Downloads",{"depth":30,"slug":424,"text":425},"cache-management","Cache Management",{"depth":26,"slug":64,"text":65},{"depth":30,"slug":294,"text":295},{"depth":26,"slug":199,"text":200},{"depth":30,"slug":430,"text":431},"using-env-files-recommended","Using .env Files (Recommended)",{"depth":26,"slug":433,"text":434},"license","License",[],[],{},[],"readme.md",{"id":64,"data":441,"body":442,"filePath":443,"digest":444,"rendered":445,"legacyId":514},{},"# Troubleshooting Guide\n\nThis guide helps resolve common issues when using Script to Speech.\n\n## Common Issues\n\n### 1. Silent Audio Detection\n\n**Problem**: Generated audio clips are silent or nearly silent. This seems to occur most frequently with short / single-word clips in TTS providers other than ElevenLabs\n\n**Symptoms**:\n- Warnings about silent clips in logs\n- Audio files with low dBFS readings\n- Partially silent audiobooks\n\n**Solutions**:\n\n1. **Identify Silent Clips**\n   ```bash\n   uv run sts-generate-audio script.json config.yaml \\\n     --populate-cache --check-silence\n   ```\n\n2. **Generate Replacements**\nRunning `sts-generate-audio` with the `--check-silence` flag will generate pre-populated `sts-generate-standalone-speech` commands which just need to be copy and pasted. See the [Standalone Speech Generation Guide](STANDALONE_SPEECH.md) for more details.\n   ```bash\n   # Copy reported text exactly\n   # -v flag controls how many generations versions of each clip to generate\n   uv run sts-generate-standalone-speech openai --voice echo \\\n     \"silent text 1\" \"silent text 2\" -v 3\n   ```\n\n3. **Manual Rename**\n   ```bash\n   # Match exact cache filename from report\n   mv standalone_speech/generated_file.mp3 \\\n     standalone_speech/[original_cache_filename].mp3\n   ```\n\n4. **Apply Overrides**\nThis will move any cache-matching files from standalone_speech to the screenplay's cache directory\n   ```bash\n   uv run sts-generate-audio script.json config.yaml \\\n     --populate-cache --cache-overrides\n   ```\n\n**Prevention**:\n- Use `--check-silence` during initial generation\n- Consider alternative TTS providers for troublesome text (ElevenLabs rarely seems to have issues with silent clips)\n\n### 2. Rate Limiting\n\n**Problem**: API requests are being rate limited.\n\n**Symptoms**:\n- Rate limit error messages\n- Delayed audio generation\n- Automatic retries and backoff\n\n**Solutions**:\n\n1. **Automatic Handling**\n   - The system automatically retries with exponential backoff\n   - Each provider has separate rate limit handling\n   - Future versions of Script to Speech will allow for more manual control of thread limits and backoff behavior\n\n2. **Reduce Global Concurrent Downloads\nNote that this will limit the overall (cross-provider) maximum concurrent downloads\n   ```bash\n   uv run sts-generate-audio --max-workers 5\n   ```\n\n2. **Distribute Across TTS Providers**\n   ```yaml\n   # Split voices across multiple TTS providers\n   NARRATOR:\n     provider: openai\n   MAIN_CHARACTER:\n     provider: elevenlabs\n   SIDE_CHARACTER:\n     provider: zonos\n   ```\n\n**Prevention**:\n- Use multiple TTS providers\n- Monitor provider-specific limits\n\n### 3. API Key Issues\n\n**Problem**: API authentication failures.\n\n**Symptoms**:\n- \"API key not set\" errors\n- Authentication failed messages\n- 401 Unauthorized errors\n\n**Solutions**:\n\n1. **Check Environment Variables**\n   ```bash\n   # Verify keys are set\n   echo $OPENAI_API_KEY\n   echo $ELEVEN_API_KEY\n   echo $CARTESIA_API_KEY\n   echo $MINIMAX_API_KEY\n   echo $MINIMAX_GROUP_ID\n   echo $ZONOS_API_KEY\n   ```\n\n2. **Set Keys Properly**\n   ```bash\n   # In terminal session\n   export OPENAI_API_KEY=\"your-key-here\"\n   \n   # Or in .env file\n   OPENAI_API_KEY=your-key-here\n   ELEVEN_API_KEY=your-key-here\n   ```\n\n3. **Validate Key Format**\n    - OpenAI: Starts with `sk-`\n    - ElevenLabs: 32-character string\n    - Cartesia: Starts with `sk_car_`\n    - Minimax (API key): Bearer token format, long string\n    - Minimax (Group ID): String of digits\n    - Zonos: Starts with `zsk-`\n\n**Prevention**:\n- Use `.env` file for persistent keys\n- Check API dashboard for key validity\n\n### 4. Voice Configuration Errors\n\n**Problem**: Voice not found or invalid configuration.\n\n**Symptoms**:\n- Voice ID errors\n- Missing provider configuration\n- Invalid voice parameters\n- Required fields missing\n\n**Solutions**:\n\n1. **Validate Configuration**\n   ```bash\n   # Check for missing/extra/duplicate speakers\n   uv run sts-tts-provider-yaml validate script.json config.yaml\n   \n   # Strict validation including provider field validation\n   uv run sts-tts-provider-yaml validate script.json config.yaml --strict\n   ```\n\n2. **OpenAI**\n- Ensure a valid voice option is being used\n   ```bash\n   # Valid voice options\n   voices: [alloy, ash, coral, echo, fable, onyx, nova, sage, shimmer]\n   ```\n\n3. **ElevenLabs**\n- Check voice ID is from public voice library (https://elevenlabs.io/app/voice-library) and not the \"My voices\" library (https://elevenlabs.io/app/voice-lab)\n- Search for voice ID in the [public voice library](https://elevenlabs.io/app/voice-library) to make sure it still exists.  Voices are some times removed from ElevenLabs\n   ```bash\n   # Voice ID format: 21-character string\n   voice_id: ErXwobaYiN019PkySvjV  # ID must be from public library\n   ```\n\n4. **Minimax**\n    ```bash\n    # Validate voice_id is one of the valid voice IDs\n    voice_id: Casual_Guy  # Must be one of system voices\n    \n    # If using voice_mix, ensure proper structure\n    voice_mix:\n      - voice_id: Casual_Guy  # Must be valid voice ID\n        weight: 70  # Must be 1-100\n      - voice_id: Deep_Voice_Man\n        weight: 30\n    ```\n\n5. **Zonos**\n    ```bash\n    # Validate voice is one of the default_voice_name from zonos documentation\n    default_voice_name: american_male  # Must be one of 9 default voices\n    ```\n\n**Prevention**:\n- Use `sts-tts-provider-yaml generate` for templates\n- Validate configuration with `--dry-run` run mode and / or `sts-tts-provider-yaml validate`\n- Keep backup of working configurations\n\n### 5. Memory and Disk Space Issues\n\n**Problem**: System running out of memory or disk space.\n\n**Symptoms**:\n- Generation stops unexpectedly\n- System slowdown\n- \"No space left on device\" errors\n\n**Solutions**:\n\n1. **Reduce Batch Size**\nFor memory constrained systems, reducing the concatenation batch size can help performance when combining audio segments\n   ```bash\n   uv run sts-generate-audio --concat-batch-size 150\n   ```\n\n2. **Reduce Maximum Concurrent Downloads**\nReducing the amount of concurrent downloads can help reduce memory usage\n   ```bash\n   uv run sts-generate-audio --max-workers 5\n   ```\n\n3. **Process in Segments**\n   ```bash\n   # Process chapters separately\n   uv run sts-generate-audio chapter1.json --populate-cache\n   uv run sts-generate-audio chapter2.json --populate-cache\n   # Manually combine later\n   ```\n\n4. **Clean Unnecessary Files**\n   ```bash\n   # Remove temporary files\n   rm -rf output/*/logs/old_logs_*.txt\n   rm -rf standalone_speech/unused_*.mp3\n   ```\n\n**Prevention**:\n- Monitor disk space before large projects\n- Use `--populate-cache` for gradual processing\n- Consider processing on systems with adequate resources\n\n### 6. Text Processor Configuration Issues\n\n**Problem**: Text processors not working as expected.\n\n**Symptoms**:\n- Text not being transformed\n- Wrong text processor precedence\n- Validation errors\n\n**Solutions**:\n\n1. **Check Text Processor Order**\n- All preprocessors from all configs, will be run before processors\n- Multiple will be processed in order\n- Within a config, (pre)processors will be run top to bottom\n- Pay attention to \"chain\" mode (pre)processors (output of one (pre)processor becomes input of next) vs. \"override\" mode (last instance takes precedence) \n\n   ```yaml\n   # config 1\n   preprocessors:\n     - name: extract_dialogue_parentheticals\n   processors:\n     - name: text_substitution\n     - name: capitalization_transform_processor\n   ```\n\n   ```yaml\n   # config 2\n   preprocessors:\n     - name: speaker_merge_preprocessor\n   processors:\n     - name: pattern_replace_processor\n   ```\n\n   ```yaml\n   # Resultant processing pipeline ordering:\n   # extract_dialogue_parentheticals -> speaker_merge_preprocessor -> text_substitution ->\n   #  capitalization_transform_processor -> pattern_replace_processor\n   ```\n\n\n\n2. **Validate Configuration**\n   ```bash\n   # Test text processor configuration\n   uv run sts-apply-text-processors-json script.json \\\n     --text-processor-configs test_config.yaml\n   ```\n\n3. **Fix Syntax Errors**\n   - Check YAML indentation\n   - Verify field names match exactly\n   - Ensure required fields are present (check log output)\n\n**Prevention**:\n- Start with default configuration\n- Add custom processors incrementally\n- Test with small examples first\n\n### 7. Cache-Related Issues\n\n**Problem**: Unexpected cache behavior.\n\n**Symptoms**:\n- Audio not being reused\n- Cache files overwriting each other\n- Missing cache files\n\n**Solutions**:\n\n1. **Verify Cache Naming**\n   ```bash\n   # Cache filename structure:\n   # [original_hash]~~[processed_hash]~~[provider_id]~~[speaker_id].mp3\n   ```\n\n2. **Check File Paths**\n   ```bash\n   # Ensure cache directory exists\n   ls -la output/[script]/cache/\n   ```\n\n3. **Clear Problematic Cache**\n   ```bash\n   # Remove specific cache files\n   rm output/[script]/cache/problematic_*.mp3\n   # Or clear all cache\n   rm -rf output/[script]/cache/\n   ```\n\n**Prevention**:\n- Avoid modifying text processors / parser between runs of a screenplay\n- Maintain separate cache directories for different versions\n\n### 8. ElevenLabs-Specific Issues\n\n**Problem**: ElevenLabs voice management errors.\n\n**Symptoms**:\n- \"Voice not found in registry\" errors\n- 30 voice limit exceeded\n- Monthly add/remove quota reached\n\n**Solutions**:\n\n1. **Use Public Library Voices**\n   ```yaml\n   # Only use public library voice IDs\n   SPEAKER:\n     provider: elevenlabs\n     voice_id: ErXwobaYiN019PkySvjV  # Public library ID\n   ```\n\n2. **Monitor Voice Usage**\n   - Provider automatically manages 30 voice limit\n   - Check if monthly quota is exceeded (check log file)\n\n3. **Alternative Approach**\n   ```bash\n   # If ElevenLabs issues persist, switch provider temporarily\n   uv run sts-generate-audio backup_config.yaml\n   ```\n\n**Prevention**:\n- Minimize voice changes during development\n- Use recommended voice tags (narrative & story, conversational)\n- Plan voice allocation before large projects; try to reuse same 30 voices, as going above this will result in voice swapping from the library\n\n### 9. Parser Issues\n\n*Note: Screenplay parsing is currently fragile. It works best with movie screenplays with \"standard\" formatting. Support of scanned in / OCR'd scripts is currently poor. Additional configuration, and better handling of edge-cases, is planned for a future release*\n\n**Problem**: Screenplay parsing errors.\n\n**Symptoms**:\n- Incorrect speaker attribution\n- Merged dialogues\n- Missing text chunks\n\n**Solutions**:\n\n1. **Manual Text Extraction**\n   ```bash\n   # Extract to text first for manual editing\n   uv run sts-parse-screenplay script.pdf --text-only\n   # Edit text file to remove headers/footers\n   # Then parse cleaned text\n   uv run sts-parse-screenplay cleaned_script.txt\n   ```\n\n2. **Check Parser Output**\n   ```bash\n   # Analyze parsed structure\n   uv run sts-analyze-json script.json\n   ```\n\n3. **Validate any Custom Parser Changes**\n   ```bash\n   # When making changes to the parser, show differences in output between\n   # parser version used to originally generate script.json and current parser logic\n   uv run sts-parse-regression-check-json script.json\n   ```\n\n**Prevention**:\n- Clean PDF before parsing\n- Verify screenplay formatting\n- Review parsed output before audio generation\n\n### 10. Network Connectivity Issues\n\n**Problem**: Network errors during API calls.\n\n**Symptoms**:\n- Connection timeout errors\n- Intermittent failures\n- SSL/TLS errors\n\n**Solutions**:\n\n1. **Retry with Backoff**\n   - System automatically retries failed requests\n   - Check network stability\n\n2. **Test Connectivity**\n   ```bash\n   # Test basic connectivity to each provider\n   curl https://api.openai.com/v1/models\n   curl https://api.elevenlabs.io/v1/voices\n   ```\n\n3. **Configure Timeouts**\n   - Network issues are handled automatically\n   - Consider VPN if regional restrictions apply\n\n**Prevention**:\n- Stable internet connection\n- Use `--populate-cache` run mode to ensure all files downloaded before generation\n- Use local cache when possible\n\n### 11. LLM Voice Casting Issues\n\n**Problem**: Issues with LLM-assisted voice casting workflow.\n\n**Symptoms**:\n- LLM returns invalid YAML\n- Missing speakers in LLM output\n- Configuration validation errors\n- Voice library IDs not recognized\n\n**Solutions**:\n\n#### For Character Notes Generation:\n1. **Try a different LLM**\n   - Certain LLM providers / models struggle with the task of adding .yaml comments while leaving the rest of the structure intact\n   - Claude Sonnet and Gemini Pro seem to work well\n\n2. **Generate Proper Casting Prompt**\n   ```bash\n   # Ensure prompt includes current configuration\n   uv run sts-generate-character-notes-prompt \\\n     source_screenplays/script.pdf \\\n     input/script/script_voice_config.yaml\n   ```\n\n3. **Validate LLM Output**\n   ```bash\n   # Check for structural issues\n   uv run sts-tts-provider-yaml validate input/script/script.json \\\n     input/script/script_voice_config.yaml\n   \n   # Strict validation for provider fields\n   uv run sts-tts-provider-yaml validate input/script/script.json \\\n     input/script/script_voice_config.yaml --strict\n   ```\n#### For Voice Library Casting:\n1. **Ensure Character Notes Exist**\n   - Voice library casting works best when character descriptions are present as YAML comments\n   - Either use character notes generation first, or manually add notes\n\n2. **Generate Voice Library Casting Prompt**\n   ```bash\n   # Include all providers you want to cast from\n   uv run sts-generate-voice-library-casting-prompt \\\n     input/script/script_voice_config.yaml \\\n     openai elevenlabs cartesia\n   ```\n\n3. **Validate Voice Library IDs**\n   - LLM must use valid `sts_id` values from the voice libraries\n   - Check that returned IDs exist in the provider's voice library\n   - Use `--strict` validation to catch invalid voice configurations\n\n4. **Common Voice Library Casting Issues**\n   - Invalid sts_id: LLM may invent voice IDs not in the library\n   - Missing sts_id: LLM may forget to add the sts_id field\n   - Wrong provider: LLM may assign voices from wrong provider's library\n   - Overwriting config: LLM may remove existing provider-specific fields\n\n**Prevention**:\n- Use the two-step workflow: character notes first, then voice library casting\n- For privacy-conscious workflows, manually add character notes instead of using LLM\n- Always validate configuration before proceeding with audio generation\n- Keep backup of working configurations\n- Try a reasoning LLM model if voice casting is producing incorrect / sub-par results\n\n## Debugging Tools\n\n### Command Line Tools\n\n1. **Standalone Speech Testing**\n   ```bash\n   # Test individual voice configurations\n   uv run sts-generate-standalone-speech openai --voice echo \"Test text\"\n   ```\n\n2. **Dry Run Validation**\n   ```bash\n   # Validate configuration without generation\n   uv run sts-generate-audio script.json config.yaml --dry-run\n   ```\n\n3. **Configuration Validation**\n   ```bash\n   # Check voice configuration against script\n   uv run sts-tts-provider-yaml validate script.json config.yaml\n   \n   # Strict validation including provider fields\n   uv run sts-tts-provider-yaml validate script.json config.yaml --strict\n   ```\n\n4. **Processor Testing**\n   ```bash\n   # Test text processors independently\n   uv run sts-apply-text-processors-json script.json \\\n     --text-processor-configs test_config.yaml \\\n     --output-path debug_output.json\n   ```\n\n5. **Parser Regression Testing**\n   ```bash\n   # When making changes to the parser, show differences in output between\n   # parser version used to originally generate script.json and current parser logic\n   uv run sts-parse-regression-check-json script.json\n   ```\n\n6. **Voice Casting Utilities**\n   ```bash\n   # Generate LLM prompt for voice casting\n   uv run sts-generate-character-notes-prompt script.pdf config.yaml\n   \n   # Copy any file to clipboard\n   uv run sts-copy-to-clipboard file.txt\n   ```\n\n### Log Analysis\n\n1. **Check Detailed Logs**\n   ```bash\n   # View recent logs\n   tail -f output/[script]/logs/[run mode]_log_YYYYMMDD_HHMMSS.txt\n   ```\n\n2. **Filter Errors**\n   ```bash\n   # Find errors in logs\n   grep -i error output/[script]/logs/[run mode]_log_*.txt\n   grep -i warning output/[script]/logs/[run mode]_log_*.txt\n   ```\n\n## Getting Help\n\n### Information to Include\n\nWhen reporting issues, include:\n1. Full error message\n2. Command used\n3. Log file from output/[script]/logs\n4. Configuration files (tts config, any additional processor configs, dialogue chunk .json)\n5. System information (OS, Python version)\n6. UV version: `uv --version`\n\n\n## Best Practices for Avoiding Issues\n\n1. **Incremental Development**\n   - Test with small scripts first\n   - Build up to full-length projects\n   - Use `--dry-run` frequently\n\n2. **Configuration Management**\n   - Keep backup configurations\n   - Version control YAML files\n   - Document custom changes\n   - Use `sts-tts-provider-yaml validate` to check configurations\n\n3. **Resource Management**\n   - Monitor disk space\n   - Use appropriate batch sizes\n   - Clean up old files regularly\n\n4. **Quality Assurance**\n   - Validate dialogue .json with `sts-analyze-json`\n   - Use `--populate-cache` during audio generation to ensure all files downloaded without issue\n   - Use `--check-silence` during audio generation\n   - Use `sts-generate-standalone-speech` to test new voices and TTS providers\n   - Validate voice configurations with `sts-tts-provider-yaml validate`\n\n5. **Error Prevention**\n   - Set up API keys properly\n   - Follow naming conventions\n   - Use provided templates\n   - Validate configurations before audio generation\n\n6. **LLM-Assisted Workflows**\n   - Use `sts-generate-character-notes-prompt` for consistent prompts\n   - Always validate LLM output with `sts-tts-provider-yaml validate`\n   - Keep backup configurations before making LLM-suggested changes","src/content/docs/troubleshooting.md","1429ae1052277a2f",{"html":446,"metadata":447},"\u003Ch1 id=\"troubleshooting-guide\">Troubleshooting Guide\u003C/h1>\n\u003Cp>This guide helps resolve common issues when using Script to Speech.\u003C/p>\n\u003Ch2 id=\"common-issues\">Common Issues\u003C/h2>\n\u003Ch3 id=\"1-silent-audio-detection\">1. Silent Audio Detection\u003C/h3>\n\u003Cp>\u003Cstrong>Problem\u003C/strong>: Generated audio clips are silent or nearly silent. This seems to occur most frequently with short / single-word clips in TTS providers other than ElevenLabs\u003C/p>\n\u003Cp>\u003Cstrong>Symptoms\u003C/strong>:\u003C/p>\n\u003Cul>\n\u003Cli>Warnings about silent clips in logs\u003C/li>\n\u003Cli>Audio files with low dBFS readings\u003C/li>\n\u003Cli>Partially silent audiobooks\u003C/li>\n\u003C/ul>\n\u003Cp>\u003Cstrong>Solutions\u003C/strong>:\u003C/p>\n\u003Col>\n\u003Cli>\n\u003Cp>\u003Cstrong>Identify Silent Clips\u003C/strong>\u003C/p>\n\u003Cpre class=\"astro-code github-dark\" style=\"background-color:#24292e;color:#e1e4e8; overflow-x: auto;\" tabindex=\"0\" data-language=\"bash\">\u003Ccode>\u003Cspan class=\"line\">\u003Cspan style=\"color:#B392F0\">uv\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> run\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> sts-generate-audio\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> script.json\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> config.yaml\u003C/span>\u003Cspan style=\"color:#79B8FF\"> \\\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#79B8FF\">  --populate-cache\u003C/span>\u003Cspan style=\"color:#79B8FF\"> --check-silence\u003C/span>\u003C/span>\u003C/code>\u003C/pre>\n\u003C/li>\n\u003Cli>\n\u003Cp>\u003Cstrong>Generate Replacements\u003C/strong>\nRunning \u003Ccode>sts-generate-audio\u003C/code> with the \u003Ccode>--check-silence\u003C/code> flag will generate pre-populated \u003Ccode>sts-generate-standalone-speech\u003C/code> commands which just need to be copy and pasted. See the \u003Ca href=\"STANDALONE_SPEECH.md\">Standalone Speech Generation Guide\u003C/a> for more details.\u003C/p>\n\u003Cpre class=\"astro-code github-dark\" style=\"background-color:#24292e;color:#e1e4e8; overflow-x: auto;\" tabindex=\"0\" data-language=\"bash\">\u003Ccode>\u003Cspan class=\"line\">\u003Cspan style=\"color:#6A737D\"># Copy reported text exactly\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#6A737D\"># -v flag controls how many generations versions of each clip to generate\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#B392F0\">uv\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> run\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> sts-generate-standalone-speech\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> openai\u003C/span>\u003Cspan style=\"color:#79B8FF\"> --voice\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> echo\u003C/span>\u003Cspan style=\"color:#79B8FF\"> \\\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#9ECBFF\">  \"silent text 1\"\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> \"silent text 2\"\u003C/span>\u003Cspan style=\"color:#79B8FF\"> -v\u003C/span>\u003Cspan style=\"color:#79B8FF\"> 3\u003C/span>\u003C/span>\u003C/code>\u003C/pre>\n\u003C/li>\n\u003Cli>\n\u003Cp>\u003Cstrong>Manual Rename\u003C/strong>\u003C/p>\n\u003Cpre class=\"astro-code github-dark\" style=\"background-color:#24292e;color:#e1e4e8; overflow-x: auto;\" tabindex=\"0\" data-language=\"bash\">\u003Ccode>\u003Cspan class=\"line\">\u003Cspan style=\"color:#6A737D\"># Match exact cache filename from report\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#B392F0\">mv\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> standalone_speech/generated_file.mp3\u003C/span>\u003Cspan style=\"color:#79B8FF\"> \\\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#9ECBFF\">  standalone_speech/[original_cache_filename].mp3\u003C/span>\u003C/span>\u003C/code>\u003C/pre>\n\u003C/li>\n\u003Cli>\n\u003Cp>\u003Cstrong>Apply Overrides\u003C/strong>\nThis will move any cache-matching files from standalone_speech to the screenplay’s cache directory\u003C/p>\n\u003Cpre class=\"astro-code github-dark\" style=\"background-color:#24292e;color:#e1e4e8; overflow-x: auto;\" tabindex=\"0\" data-language=\"bash\">\u003Ccode>\u003Cspan class=\"line\">\u003Cspan style=\"color:#B392F0\">uv\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> run\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> sts-generate-audio\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> script.json\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> config.yaml\u003C/span>\u003Cspan style=\"color:#79B8FF\"> \\\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#79B8FF\">  --populate-cache\u003C/span>\u003Cspan style=\"color:#79B8FF\"> --cache-overrides\u003C/span>\u003C/span>\u003C/code>\u003C/pre>\n\u003C/li>\n\u003C/ol>\n\u003Cp>\u003Cstrong>Prevention\u003C/strong>:\u003C/p>\n\u003Cul>\n\u003Cli>Use \u003Ccode>--check-silence\u003C/code> during initial generation\u003C/li>\n\u003Cli>Consider alternative TTS providers for troublesome text (ElevenLabs rarely seems to have issues with silent clips)\u003C/li>\n\u003C/ul>\n\u003Ch3 id=\"2-rate-limiting\">2. Rate Limiting\u003C/h3>\n\u003Cp>\u003Cstrong>Problem\u003C/strong>: API requests are being rate limited.\u003C/p>\n\u003Cp>\u003Cstrong>Symptoms\u003C/strong>:\u003C/p>\n\u003Cul>\n\u003Cli>Rate limit error messages\u003C/li>\n\u003Cli>Delayed audio generation\u003C/li>\n\u003Cli>Automatic retries and backoff\u003C/li>\n\u003C/ul>\n\u003Cp>\u003Cstrong>Solutions\u003C/strong>:\u003C/p>\n\u003Col>\n\u003Cli>\n\u003Cp>\u003Cstrong>Automatic Handling\u003C/strong>\u003C/p>\n\u003Cul>\n\u003Cli>The system automatically retries with exponential backoff\u003C/li>\n\u003Cli>Each provider has separate rate limit handling\u003C/li>\n\u003Cli>Future versions of Script to Speech will allow for more manual control of thread limits and backoff behavior\u003C/li>\n\u003C/ul>\n\u003C/li>\n\u003Cli>\n\u003Cp>**Reduce Global Concurrent Downloads\nNote that this will limit the overall (cross-provider) maximum concurrent downloads\u003C/p>\n\u003Cpre class=\"astro-code github-dark\" style=\"background-color:#24292e;color:#e1e4e8; overflow-x: auto;\" tabindex=\"0\" data-language=\"bash\">\u003Ccode>\u003Cspan class=\"line\">\u003Cspan style=\"color:#B392F0\">uv\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> run\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> sts-generate-audio\u003C/span>\u003Cspan style=\"color:#79B8FF\"> --max-workers\u003C/span>\u003Cspan style=\"color:#79B8FF\"> 5\u003C/span>\u003C/span>\u003C/code>\u003C/pre>\n\u003C/li>\n\u003Cli>\n\u003Cp>\u003Cstrong>Distribute Across TTS Providers\u003C/strong>\u003C/p>\n\u003Cpre class=\"astro-code github-dark\" style=\"background-color:#24292e;color:#e1e4e8; overflow-x: auto;\" tabindex=\"0\" data-language=\"yaml\">\u003Ccode>\u003Cspan class=\"line\">\u003Cspan style=\"color:#6A737D\"># Split voices across multiple TTS providers\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#85E89D\">NARRATOR\u003C/span>\u003Cspan style=\"color:#E1E4E8\">:\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#85E89D\">  provider\u003C/span>\u003Cspan style=\"color:#E1E4E8\">: \u003C/span>\u003Cspan style=\"color:#9ECBFF\">openai\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#85E89D\">MAIN_CHARACTER\u003C/span>\u003Cspan style=\"color:#E1E4E8\">:\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#85E89D\">  provider\u003C/span>\u003Cspan style=\"color:#E1E4E8\">: \u003C/span>\u003Cspan style=\"color:#9ECBFF\">elevenlabs\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#85E89D\">SIDE_CHARACTER\u003C/span>\u003Cspan style=\"color:#E1E4E8\">:\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#85E89D\">  provider\u003C/span>\u003Cspan style=\"color:#E1E4E8\">: \u003C/span>\u003Cspan style=\"color:#9ECBFF\">zonos\u003C/span>\u003C/span>\u003C/code>\u003C/pre>\n\u003C/li>\n\u003C/ol>\n\u003Cp>\u003Cstrong>Prevention\u003C/strong>:\u003C/p>\n\u003Cul>\n\u003Cli>Use multiple TTS providers\u003C/li>\n\u003Cli>Monitor provider-specific limits\u003C/li>\n\u003C/ul>\n\u003Ch3 id=\"3-api-key-issues\">3. API Key Issues\u003C/h3>\n\u003Cp>\u003Cstrong>Problem\u003C/strong>: API authentication failures.\u003C/p>\n\u003Cp>\u003Cstrong>Symptoms\u003C/strong>:\u003C/p>\n\u003Cul>\n\u003Cli>“API key not set” errors\u003C/li>\n\u003Cli>Authentication failed messages\u003C/li>\n\u003Cli>401 Unauthorized errors\u003C/li>\n\u003C/ul>\n\u003Cp>\u003Cstrong>Solutions\u003C/strong>:\u003C/p>\n\u003Col>\n\u003Cli>\n\u003Cp>\u003Cstrong>Check Environment Variables\u003C/strong>\u003C/p>\n\u003Cpre class=\"astro-code github-dark\" style=\"background-color:#24292e;color:#e1e4e8; overflow-x: auto;\" tabindex=\"0\" data-language=\"bash\">\u003Ccode>\u003Cspan class=\"line\">\u003Cspan style=\"color:#6A737D\"># Verify keys are set\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#79B8FF\">echo\u003C/span>\u003Cspan style=\"color:#E1E4E8\"> $OPENAI_API_KEY\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#79B8FF\">echo\u003C/span>\u003Cspan style=\"color:#E1E4E8\"> $ELEVEN_API_KEY\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#79B8FF\">echo\u003C/span>\u003Cspan style=\"color:#E1E4E8\"> $CARTESIA_API_KEY\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#79B8FF\">echo\u003C/span>\u003Cspan style=\"color:#E1E4E8\"> $MINIMAX_API_KEY\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#79B8FF\">echo\u003C/span>\u003Cspan style=\"color:#E1E4E8\"> $MINIMAX_GROUP_ID\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#79B8FF\">echo\u003C/span>\u003Cspan style=\"color:#E1E4E8\"> $ZONOS_API_KEY\u003C/span>\u003C/span>\u003C/code>\u003C/pre>\n\u003C/li>\n\u003Cli>\n\u003Cp>\u003Cstrong>Set Keys Properly\u003C/strong>\u003C/p>\n\u003Cpre class=\"astro-code github-dark\" style=\"background-color:#24292e;color:#e1e4e8; overflow-x: auto;\" tabindex=\"0\" data-language=\"bash\">\u003Ccode>\u003Cspan class=\"line\">\u003Cspan style=\"color:#6A737D\"># In terminal session\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#F97583\">export\u003C/span>\u003Cspan style=\"color:#E1E4E8\"> OPENAI_API_KEY\u003C/span>\u003Cspan style=\"color:#F97583\">=\u003C/span>\u003Cspan style=\"color:#9ECBFF\">\"your-key-here\"\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#6A737D\"># Or in .env file\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#E1E4E8\">OPENAI_API_KEY\u003C/span>\u003Cspan style=\"color:#F97583\">=\u003C/span>\u003Cspan style=\"color:#9ECBFF\">your-key-here\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#E1E4E8\">ELEVEN_API_KEY\u003C/span>\u003Cspan style=\"color:#F97583\">=\u003C/span>\u003Cspan style=\"color:#9ECBFF\">your-key-here\u003C/span>\u003C/span>\u003C/code>\u003C/pre>\n\u003C/li>\n\u003Cli>\n\u003Cp>\u003Cstrong>Validate Key Format\u003C/strong>\u003C/p>\n\u003Cul>\n\u003Cli>OpenAI: Starts with \u003Ccode>sk-\u003C/code>\u003C/li>\n\u003Cli>ElevenLabs: 32-character string\u003C/li>\n\u003Cli>Cartesia: Starts with \u003Ccode>sk_car_\u003C/code>\u003C/li>\n\u003Cli>Minimax (API key): Bearer token format, long string\u003C/li>\n\u003Cli>Minimax (Group ID): String of digits\u003C/li>\n\u003Cli>Zonos: Starts with \u003Ccode>zsk-\u003C/code>\u003C/li>\n\u003C/ul>\n\u003C/li>\n\u003C/ol>\n\u003Cp>\u003Cstrong>Prevention\u003C/strong>:\u003C/p>\n\u003Cul>\n\u003Cli>Use \u003Ccode>.env\u003C/code> file for persistent keys\u003C/li>\n\u003Cli>Check API dashboard for key validity\u003C/li>\n\u003C/ul>\n\u003Ch3 id=\"4-voice-configuration-errors\">4. Voice Configuration Errors\u003C/h3>\n\u003Cp>\u003Cstrong>Problem\u003C/strong>: Voice not found or invalid configuration.\u003C/p>\n\u003Cp>\u003Cstrong>Symptoms\u003C/strong>:\u003C/p>\n\u003Cul>\n\u003Cli>Voice ID errors\u003C/li>\n\u003Cli>Missing provider configuration\u003C/li>\n\u003Cli>Invalid voice parameters\u003C/li>\n\u003Cli>Required fields missing\u003C/li>\n\u003C/ul>\n\u003Cp>\u003Cstrong>Solutions\u003C/strong>:\u003C/p>\n\u003Col>\n\u003Cli>\n\u003Cp>\u003Cstrong>Validate Configuration\u003C/strong>\u003C/p>\n\u003Cpre class=\"astro-code github-dark\" style=\"background-color:#24292e;color:#e1e4e8; overflow-x: auto;\" tabindex=\"0\" data-language=\"bash\">\u003Ccode>\u003Cspan class=\"line\">\u003Cspan style=\"color:#6A737D\"># Check for missing/extra/duplicate speakers\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#B392F0\">uv\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> run\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> sts-tts-provider-yaml\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> validate\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> script.json\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> config.yaml\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#6A737D\"># Strict validation including provider field validation\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#B392F0\">uv\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> run\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> sts-tts-provider-yaml\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> validate\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> script.json\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> config.yaml\u003C/span>\u003Cspan style=\"color:#79B8FF\"> --strict\u003C/span>\u003C/span>\u003C/code>\u003C/pre>\n\u003C/li>\n\u003Cli>\n\u003Cp>\u003Cstrong>OpenAI\u003C/strong>\u003C/p>\n\u003C/li>\n\u003C/ol>\n\u003Cul>\n\u003Cli>Ensure a valid voice option is being used\n\u003Cpre class=\"astro-code github-dark\" style=\"background-color:#24292e;color:#e1e4e8; overflow-x: auto;\" tabindex=\"0\" data-language=\"bash\">\u003Ccode>\u003Cspan class=\"line\">\u003Cspan style=\"color:#6A737D\"># Valid voice options\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#B392F0\">voices:\u003C/span>\u003Cspan style=\"color:#E1E4E8\"> [alloy, \u003C/span>\u003Cspan style=\"color:#9ECBFF\">ash,\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> coral,\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> echo,\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> fable,\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> onyx,\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> nova,\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> sage,\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> shimmer]\u003C/span>\u003C/span>\u003C/code>\u003C/pre>\n\u003C/li>\n\u003C/ul>\n\u003Col start=\"3\">\n\u003Cli>\u003Cstrong>ElevenLabs\u003C/strong>\u003C/li>\n\u003C/ol>\n\u003Cul>\n\u003Cli>Check voice ID is from public voice library (\u003Ca href=\"https://elevenlabs.io/app/voice-library\">https://elevenlabs.io/app/voice-library\u003C/a>) and not the “My voices” library (\u003Ca href=\"https://elevenlabs.io/app/voice-lab\">https://elevenlabs.io/app/voice-lab\u003C/a>)\u003C/li>\n\u003Cli>Search for voice ID in the \u003Ca href=\"https://elevenlabs.io/app/voice-library\">public voice library\u003C/a> to make sure it still exists.  Voices are some times removed from ElevenLabs\n\u003Cpre class=\"astro-code github-dark\" style=\"background-color:#24292e;color:#e1e4e8; overflow-x: auto;\" tabindex=\"0\" data-language=\"bash\">\u003Ccode>\u003Cspan class=\"line\">\u003Cspan style=\"color:#6A737D\"># Voice ID format: 21-character string\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#B392F0\">voice_id:\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> ErXwobaYiN019PkySvjV\u003C/span>\u003Cspan style=\"color:#6A737D\">  # ID must be from public library\u003C/span>\u003C/span>\u003C/code>\u003C/pre>\n\u003C/li>\n\u003C/ul>\n\u003Col start=\"4\">\n\u003Cli>\n\u003Cp>\u003Cstrong>Minimax\u003C/strong>\u003C/p>\n\u003Cpre class=\"astro-code github-dark\" style=\"background-color:#24292e;color:#e1e4e8; overflow-x: auto;\" tabindex=\"0\" data-language=\"bash\">\u003Ccode>\u003Cspan class=\"line\">\u003Cspan style=\"color:#6A737D\"># Validate voice_id is one of the valid voice IDs\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#B392F0\">voice_id:\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> Casual_Guy\u003C/span>\u003Cspan style=\"color:#6A737D\">  # Must be one of system voices\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#6A737D\"># If using voice_mix, ensure proper structure\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#B392F0\">voice_mix:\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#B392F0\">  -\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> voice_id:\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> Casual_Guy\u003C/span>\u003Cspan style=\"color:#6A737D\">  # Must be valid voice ID\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#B392F0\">    weight:\u003C/span>\u003Cspan style=\"color:#79B8FF\"> 70\u003C/span>\u003Cspan style=\"color:#6A737D\">  # Must be 1-100\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#B392F0\">  -\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> voice_id:\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> Deep_Voice_Man\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#B392F0\">    weight:\u003C/span>\u003Cspan style=\"color:#79B8FF\"> 30\u003C/span>\u003C/span>\u003C/code>\u003C/pre>\n\u003C/li>\n\u003Cli>\n\u003Cp>\u003Cstrong>Zonos\u003C/strong>\u003C/p>\n\u003Cpre class=\"astro-code github-dark\" style=\"background-color:#24292e;color:#e1e4e8; overflow-x: auto;\" tabindex=\"0\" data-language=\"bash\">\u003Ccode>\u003Cspan class=\"line\">\u003Cspan style=\"color:#6A737D\"># Validate voice is one of the default_voice_name from zonos documentation\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#B392F0\">default_voice_name:\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> american_male\u003C/span>\u003Cspan style=\"color:#6A737D\">  # Must be one of 9 default voices\u003C/span>\u003C/span>\u003C/code>\u003C/pre>\n\u003C/li>\n\u003C/ol>\n\u003Cp>\u003Cstrong>Prevention\u003C/strong>:\u003C/p>\n\u003Cul>\n\u003Cli>Use \u003Ccode>sts-tts-provider-yaml generate\u003C/code> for templates\u003C/li>\n\u003Cli>Validate configuration with \u003Ccode>--dry-run\u003C/code> run mode and / or \u003Ccode>sts-tts-provider-yaml validate\u003C/code>\u003C/li>\n\u003Cli>Keep backup of working configurations\u003C/li>\n\u003C/ul>\n\u003Ch3 id=\"5-memory-and-disk-space-issues\">5. Memory and Disk Space Issues\u003C/h3>\n\u003Cp>\u003Cstrong>Problem\u003C/strong>: System running out of memory or disk space.\u003C/p>\n\u003Cp>\u003Cstrong>Symptoms\u003C/strong>:\u003C/p>\n\u003Cul>\n\u003Cli>Generation stops unexpectedly\u003C/li>\n\u003Cli>System slowdown\u003C/li>\n\u003Cli>“No space left on device” errors\u003C/li>\n\u003C/ul>\n\u003Cp>\u003Cstrong>Solutions\u003C/strong>:\u003C/p>\n\u003Col>\n\u003Cli>\n\u003Cp>\u003Cstrong>Reduce Batch Size\u003C/strong>\nFor memory constrained systems, reducing the concatenation batch size can help performance when combining audio segments\u003C/p>\n\u003Cpre class=\"astro-code github-dark\" style=\"background-color:#24292e;color:#e1e4e8; overflow-x: auto;\" tabindex=\"0\" data-language=\"bash\">\u003Ccode>\u003Cspan class=\"line\">\u003Cspan style=\"color:#B392F0\">uv\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> run\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> sts-generate-audio\u003C/span>\u003Cspan style=\"color:#79B8FF\"> --concat-batch-size\u003C/span>\u003Cspan style=\"color:#79B8FF\"> 150\u003C/span>\u003C/span>\u003C/code>\u003C/pre>\n\u003C/li>\n\u003Cli>\n\u003Cp>\u003Cstrong>Reduce Maximum Concurrent Downloads\u003C/strong>\nReducing the amount of concurrent downloads can help reduce memory usage\u003C/p>\n\u003Cpre class=\"astro-code github-dark\" style=\"background-color:#24292e;color:#e1e4e8; overflow-x: auto;\" tabindex=\"0\" data-language=\"bash\">\u003Ccode>\u003Cspan class=\"line\">\u003Cspan style=\"color:#B392F0\">uv\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> run\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> sts-generate-audio\u003C/span>\u003Cspan style=\"color:#79B8FF\"> --max-workers\u003C/span>\u003Cspan style=\"color:#79B8FF\"> 5\u003C/span>\u003C/span>\u003C/code>\u003C/pre>\n\u003C/li>\n\u003Cli>\n\u003Cp>\u003Cstrong>Process in Segments\u003C/strong>\u003C/p>\n\u003Cpre class=\"astro-code github-dark\" style=\"background-color:#24292e;color:#e1e4e8; overflow-x: auto;\" tabindex=\"0\" data-language=\"bash\">\u003Ccode>\u003Cspan class=\"line\">\u003Cspan style=\"color:#6A737D\"># Process chapters separately\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#B392F0\">uv\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> run\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> sts-generate-audio\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> chapter1.json\u003C/span>\u003Cspan style=\"color:#79B8FF\"> --populate-cache\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#B392F0\">uv\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> run\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> sts-generate-audio\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> chapter2.json\u003C/span>\u003Cspan style=\"color:#79B8FF\"> --populate-cache\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#6A737D\"># Manually combine later\u003C/span>\u003C/span>\u003C/code>\u003C/pre>\n\u003C/li>\n\u003Cli>\n\u003Cp>\u003Cstrong>Clean Unnecessary Files\u003C/strong>\u003C/p>\n\u003Cpre class=\"astro-code github-dark\" style=\"background-color:#24292e;color:#e1e4e8; overflow-x: auto;\" tabindex=\"0\" data-language=\"bash\">\u003Ccode>\u003Cspan class=\"line\">\u003Cspan style=\"color:#6A737D\"># Remove temporary files\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#B392F0\">rm\u003C/span>\u003Cspan style=\"color:#79B8FF\"> -rf\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> output/\u003C/span>\u003Cspan style=\"color:#79B8FF\">*\u003C/span>\u003Cspan style=\"color:#9ECBFF\">/logs/old_logs_\u003C/span>\u003Cspan style=\"color:#79B8FF\">*\u003C/span>\u003Cspan style=\"color:#9ECBFF\">.txt\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#B392F0\">rm\u003C/span>\u003Cspan style=\"color:#79B8FF\"> -rf\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> standalone_speech/unused_\u003C/span>\u003Cspan style=\"color:#79B8FF\">*\u003C/span>\u003Cspan style=\"color:#9ECBFF\">.mp3\u003C/span>\u003C/span>\u003C/code>\u003C/pre>\n\u003C/li>\n\u003C/ol>\n\u003Cp>\u003Cstrong>Prevention\u003C/strong>:\u003C/p>\n\u003Cul>\n\u003Cli>Monitor disk space before large projects\u003C/li>\n\u003Cli>Use \u003Ccode>--populate-cache\u003C/code> for gradual processing\u003C/li>\n\u003Cli>Consider processing on systems with adequate resources\u003C/li>\n\u003C/ul>\n\u003Ch3 id=\"6-text-processor-configuration-issues\">6. Text Processor Configuration Issues\u003C/h3>\n\u003Cp>\u003Cstrong>Problem\u003C/strong>: Text processors not working as expected.\u003C/p>\n\u003Cp>\u003Cstrong>Symptoms\u003C/strong>:\u003C/p>\n\u003Cul>\n\u003Cli>Text not being transformed\u003C/li>\n\u003Cli>Wrong text processor precedence\u003C/li>\n\u003Cli>Validation errors\u003C/li>\n\u003C/ul>\n\u003Cp>\u003Cstrong>Solutions\u003C/strong>:\u003C/p>\n\u003Col>\n\u003Cli>\u003Cstrong>Check Text Processor Order\u003C/strong>\u003C/li>\n\u003C/ol>\n\u003Cul>\n\u003Cli>\n\u003Cp>All preprocessors from all configs, will be run before processors\u003C/p>\n\u003C/li>\n\u003Cli>\n\u003Cp>Multiple will be processed in order\u003C/p>\n\u003C/li>\n\u003Cli>\n\u003Cp>Within a config, (pre)processors will be run top to bottom\u003C/p>\n\u003C/li>\n\u003Cli>\n\u003Cp>Pay attention to “chain” mode (pre)processors (output of one (pre)processor becomes input of next) vs. “override” mode (last instance takes precedence)\u003C/p>\n\u003Cpre class=\"astro-code github-dark\" style=\"background-color:#24292e;color:#e1e4e8; overflow-x: auto;\" tabindex=\"0\" data-language=\"yaml\">\u003Ccode>\u003Cspan class=\"line\">\u003Cspan style=\"color:#6A737D\"># config 1\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#85E89D\">preprocessors\u003C/span>\u003Cspan style=\"color:#E1E4E8\">:\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#E1E4E8\">  - \u003C/span>\u003Cspan style=\"color:#85E89D\">name\u003C/span>\u003Cspan style=\"color:#E1E4E8\">: \u003C/span>\u003Cspan style=\"color:#9ECBFF\">extract_dialogue_parentheticals\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#85E89D\">processors\u003C/span>\u003Cspan style=\"color:#E1E4E8\">:\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#E1E4E8\">  - \u003C/span>\u003Cspan style=\"color:#85E89D\">name\u003C/span>\u003Cspan style=\"color:#E1E4E8\">: \u003C/span>\u003Cspan style=\"color:#9ECBFF\">text_substitution\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#E1E4E8\">  - \u003C/span>\u003Cspan style=\"color:#85E89D\">name\u003C/span>\u003Cspan style=\"color:#E1E4E8\">: \u003C/span>\u003Cspan style=\"color:#9ECBFF\">capitalization_transform_processor\u003C/span>\u003C/span>\u003C/code>\u003C/pre>\n\u003Cpre class=\"astro-code github-dark\" style=\"background-color:#24292e;color:#e1e4e8; overflow-x: auto;\" tabindex=\"0\" data-language=\"yaml\">\u003Ccode>\u003Cspan class=\"line\">\u003Cspan style=\"color:#6A737D\"># config 2\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#85E89D\">preprocessors\u003C/span>\u003Cspan style=\"color:#E1E4E8\">:\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#E1E4E8\">  - \u003C/span>\u003Cspan style=\"color:#85E89D\">name\u003C/span>\u003Cspan style=\"color:#E1E4E8\">: \u003C/span>\u003Cspan style=\"color:#9ECBFF\">speaker_merge_preprocessor\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#85E89D\">processors\u003C/span>\u003Cspan style=\"color:#E1E4E8\">:\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#E1E4E8\">  - \u003C/span>\u003Cspan style=\"color:#85E89D\">name\u003C/span>\u003Cspan style=\"color:#E1E4E8\">: \u003C/span>\u003Cspan style=\"color:#9ECBFF\">pattern_replace_processor\u003C/span>\u003C/span>\u003C/code>\u003C/pre>\n\u003Cpre class=\"astro-code github-dark\" style=\"background-color:#24292e;color:#e1e4e8; overflow-x: auto;\" tabindex=\"0\" data-language=\"yaml\">\u003Ccode>\u003Cspan class=\"line\">\u003Cspan style=\"color:#6A737D\"># Resultant processing pipeline ordering:\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#6A737D\"># extract_dialogue_parentheticals -> speaker_merge_preprocessor -> text_substitution ->\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#6A737D\">#  capitalization_transform_processor -> pattern_replace_processor\u003C/span>\u003C/span>\u003C/code>\u003C/pre>\n\u003C/li>\n\u003C/ul>\n\u003Col start=\"2\">\n\u003Cli>\n\u003Cp>\u003Cstrong>Validate Configuration\u003C/strong>\u003C/p>\n\u003Cpre class=\"astro-code github-dark\" style=\"background-color:#24292e;color:#e1e4e8; overflow-x: auto;\" tabindex=\"0\" data-language=\"bash\">\u003Ccode>\u003Cspan class=\"line\">\u003Cspan style=\"color:#6A737D\"># Test text processor configuration\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#B392F0\">uv\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> run\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> sts-apply-text-processors-json\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> script.json\u003C/span>\u003Cspan style=\"color:#79B8FF\"> \\\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#79B8FF\">  --text-processor-configs\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> test_config.yaml\u003C/span>\u003C/span>\u003C/code>\u003C/pre>\n\u003C/li>\n\u003Cli>\n\u003Cp>\u003Cstrong>Fix Syntax Errors\u003C/strong>\u003C/p>\n\u003Cul>\n\u003Cli>Check YAML indentation\u003C/li>\n\u003Cli>Verify field names match exactly\u003C/li>\n\u003Cli>Ensure required fields are present (check log output)\u003C/li>\n\u003C/ul>\n\u003C/li>\n\u003C/ol>\n\u003Cp>\u003Cstrong>Prevention\u003C/strong>:\u003C/p>\n\u003Cul>\n\u003Cli>Start with default configuration\u003C/li>\n\u003Cli>Add custom processors incrementally\u003C/li>\n\u003Cli>Test with small examples first\u003C/li>\n\u003C/ul>\n\u003Ch3 id=\"7-cache-related-issues\">7. Cache-Related Issues\u003C/h3>\n\u003Cp>\u003Cstrong>Problem\u003C/strong>: Unexpected cache behavior.\u003C/p>\n\u003Cp>\u003Cstrong>Symptoms\u003C/strong>:\u003C/p>\n\u003Cul>\n\u003Cli>Audio not being reused\u003C/li>\n\u003Cli>Cache files overwriting each other\u003C/li>\n\u003Cli>Missing cache files\u003C/li>\n\u003C/ul>\n\u003Cp>\u003Cstrong>Solutions\u003C/strong>:\u003C/p>\n\u003Col>\n\u003Cli>\n\u003Cp>\u003Cstrong>Verify Cache Naming\u003C/strong>\u003C/p>\n\u003Cpre class=\"astro-code github-dark\" style=\"background-color:#24292e;color:#e1e4e8; overflow-x: auto;\" tabindex=\"0\" data-language=\"bash\">\u003Ccode>\u003Cspan class=\"line\">\u003Cspan style=\"color:#6A737D\"># Cache filename structure:\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#6A737D\"># [original_hash]~~[processed_hash]~~[provider_id]~~[speaker_id].mp3\u003C/span>\u003C/span>\u003C/code>\u003C/pre>\n\u003C/li>\n\u003Cli>\n\u003Cp>\u003Cstrong>Check File Paths\u003C/strong>\u003C/p>\n\u003Cpre class=\"astro-code github-dark\" style=\"background-color:#24292e;color:#e1e4e8; overflow-x: auto;\" tabindex=\"0\" data-language=\"bash\">\u003Ccode>\u003Cspan class=\"line\">\u003Cspan style=\"color:#6A737D\"># Ensure cache directory exists\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#B392F0\">ls\u003C/span>\u003Cspan style=\"color:#79B8FF\"> -la\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> output/[script]/cache/\u003C/span>\u003C/span>\u003C/code>\u003C/pre>\n\u003C/li>\n\u003Cli>\n\u003Cp>\u003Cstrong>Clear Problematic Cache\u003C/strong>\u003C/p>\n\u003Cpre class=\"astro-code github-dark\" style=\"background-color:#24292e;color:#e1e4e8; overflow-x: auto;\" tabindex=\"0\" data-language=\"bash\">\u003Ccode>\u003Cspan class=\"line\">\u003Cspan style=\"color:#6A737D\"># Remove specific cache files\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#B392F0\">rm\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> output/[script]/cache/problematic_\u003C/span>\u003Cspan style=\"color:#79B8FF\">*\u003C/span>\u003Cspan style=\"color:#9ECBFF\">.mp3\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#6A737D\"># Or clear all cache\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#B392F0\">rm\u003C/span>\u003Cspan style=\"color:#79B8FF\"> -rf\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> output/[script]/cache/\u003C/span>\u003C/span>\u003C/code>\u003C/pre>\n\u003C/li>\n\u003C/ol>\n\u003Cp>\u003Cstrong>Prevention\u003C/strong>:\u003C/p>\n\u003Cul>\n\u003Cli>Avoid modifying text processors / parser between runs of a screenplay\u003C/li>\n\u003Cli>Maintain separate cache directories for different versions\u003C/li>\n\u003C/ul>\n\u003Ch3 id=\"8-elevenlabs-specific-issues\">8. ElevenLabs-Specific Issues\u003C/h3>\n\u003Cp>\u003Cstrong>Problem\u003C/strong>: ElevenLabs voice management errors.\u003C/p>\n\u003Cp>\u003Cstrong>Symptoms\u003C/strong>:\u003C/p>\n\u003Cul>\n\u003Cli>“Voice not found in registry” errors\u003C/li>\n\u003Cli>30 voice limit exceeded\u003C/li>\n\u003Cli>Monthly add/remove quota reached\u003C/li>\n\u003C/ul>\n\u003Cp>\u003Cstrong>Solutions\u003C/strong>:\u003C/p>\n\u003Col>\n\u003Cli>\n\u003Cp>\u003Cstrong>Use Public Library Voices\u003C/strong>\u003C/p>\n\u003Cpre class=\"astro-code github-dark\" style=\"background-color:#24292e;color:#e1e4e8; overflow-x: auto;\" tabindex=\"0\" data-language=\"yaml\">\u003Ccode>\u003Cspan class=\"line\">\u003Cspan style=\"color:#6A737D\"># Only use public library voice IDs\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#85E89D\">SPEAKER\u003C/span>\u003Cspan style=\"color:#E1E4E8\">:\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#85E89D\">  provider\u003C/span>\u003Cspan style=\"color:#E1E4E8\">: \u003C/span>\u003Cspan style=\"color:#9ECBFF\">elevenlabs\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#85E89D\">  voice_id\u003C/span>\u003Cspan style=\"color:#E1E4E8\">: \u003C/span>\u003Cspan style=\"color:#9ECBFF\">ErXwobaYiN019PkySvjV\u003C/span>\u003Cspan style=\"color:#6A737D\">  # Public library ID\u003C/span>\u003C/span>\u003C/code>\u003C/pre>\n\u003C/li>\n\u003Cli>\n\u003Cp>\u003Cstrong>Monitor Voice Usage\u003C/strong>\u003C/p>\n\u003Cul>\n\u003Cli>Provider automatically manages 30 voice limit\u003C/li>\n\u003Cli>Check if monthly quota is exceeded (check log file)\u003C/li>\n\u003C/ul>\n\u003C/li>\n\u003Cli>\n\u003Cp>\u003Cstrong>Alternative Approach\u003C/strong>\u003C/p>\n\u003Cpre class=\"astro-code github-dark\" style=\"background-color:#24292e;color:#e1e4e8; overflow-x: auto;\" tabindex=\"0\" data-language=\"bash\">\u003Ccode>\u003Cspan class=\"line\">\u003Cspan style=\"color:#6A737D\"># If ElevenLabs issues persist, switch provider temporarily\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#B392F0\">uv\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> run\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> sts-generate-audio\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> backup_config.yaml\u003C/span>\u003C/span>\u003C/code>\u003C/pre>\n\u003C/li>\n\u003C/ol>\n\u003Cp>\u003Cstrong>Prevention\u003C/strong>:\u003C/p>\n\u003Cul>\n\u003Cli>Minimize voice changes during development\u003C/li>\n\u003Cli>Use recommended voice tags (narrative &#x26; story, conversational)\u003C/li>\n\u003Cli>Plan voice allocation before large projects; try to reuse same 30 voices, as going above this will result in voice swapping from the library\u003C/li>\n\u003C/ul>\n\u003Ch3 id=\"9-parser-issues\">9. Parser Issues\u003C/h3>\n\u003Cp>\u003Cem>Note: Screenplay parsing is currently fragile. It works best with movie screenplays with “standard” formatting. Support of scanned in / OCR’d scripts is currently poor. Additional configuration, and better handling of edge-cases, is planned for a future release\u003C/em>\u003C/p>\n\u003Cp>\u003Cstrong>Problem\u003C/strong>: Screenplay parsing errors.\u003C/p>\n\u003Cp>\u003Cstrong>Symptoms\u003C/strong>:\u003C/p>\n\u003Cul>\n\u003Cli>Incorrect speaker attribution\u003C/li>\n\u003Cli>Merged dialogues\u003C/li>\n\u003Cli>Missing text chunks\u003C/li>\n\u003C/ul>\n\u003Cp>\u003Cstrong>Solutions\u003C/strong>:\u003C/p>\n\u003Col>\n\u003Cli>\n\u003Cp>\u003Cstrong>Manual Text Extraction\u003C/strong>\u003C/p>\n\u003Cpre class=\"astro-code github-dark\" style=\"background-color:#24292e;color:#e1e4e8; overflow-x: auto;\" tabindex=\"0\" data-language=\"bash\">\u003Ccode>\u003Cspan class=\"line\">\u003Cspan style=\"color:#6A737D\"># Extract to text first for manual editing\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#B392F0\">uv\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> run\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> sts-parse-screenplay\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> script.pdf\u003C/span>\u003Cspan style=\"color:#79B8FF\"> --text-only\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#6A737D\"># Edit text file to remove headers/footers\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#6A737D\"># Then parse cleaned text\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#B392F0\">uv\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> run\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> sts-parse-screenplay\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> cleaned_script.txt\u003C/span>\u003C/span>\u003C/code>\u003C/pre>\n\u003C/li>\n\u003Cli>\n\u003Cp>\u003Cstrong>Check Parser Output\u003C/strong>\u003C/p>\n\u003Cpre class=\"astro-code github-dark\" style=\"background-color:#24292e;color:#e1e4e8; overflow-x: auto;\" tabindex=\"0\" data-language=\"bash\">\u003Ccode>\u003Cspan class=\"line\">\u003Cspan style=\"color:#6A737D\"># Analyze parsed structure\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#B392F0\">uv\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> run\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> sts-analyze-json\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> script.json\u003C/span>\u003C/span>\u003C/code>\u003C/pre>\n\u003C/li>\n\u003Cli>\n\u003Cp>\u003Cstrong>Validate any Custom Parser Changes\u003C/strong>\u003C/p>\n\u003Cpre class=\"astro-code github-dark\" style=\"background-color:#24292e;color:#e1e4e8; overflow-x: auto;\" tabindex=\"0\" data-language=\"bash\">\u003Ccode>\u003Cspan class=\"line\">\u003Cspan style=\"color:#6A737D\"># When making changes to the parser, show differences in output between\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#6A737D\"># parser version used to originally generate script.json and current parser logic\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#B392F0\">uv\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> run\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> sts-parse-regression-check-json\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> script.json\u003C/span>\u003C/span>\u003C/code>\u003C/pre>\n\u003C/li>\n\u003C/ol>\n\u003Cp>\u003Cstrong>Prevention\u003C/strong>:\u003C/p>\n\u003Cul>\n\u003Cli>Clean PDF before parsing\u003C/li>\n\u003Cli>Verify screenplay formatting\u003C/li>\n\u003Cli>Review parsed output before audio generation\u003C/li>\n\u003C/ul>\n\u003Ch3 id=\"10-network-connectivity-issues\">10. Network Connectivity Issues\u003C/h3>\n\u003Cp>\u003Cstrong>Problem\u003C/strong>: Network errors during API calls.\u003C/p>\n\u003Cp>\u003Cstrong>Symptoms\u003C/strong>:\u003C/p>\n\u003Cul>\n\u003Cli>Connection timeout errors\u003C/li>\n\u003Cli>Intermittent failures\u003C/li>\n\u003Cli>SSL/TLS errors\u003C/li>\n\u003C/ul>\n\u003Cp>\u003Cstrong>Solutions\u003C/strong>:\u003C/p>\n\u003Col>\n\u003Cli>\n\u003Cp>\u003Cstrong>Retry with Backoff\u003C/strong>\u003C/p>\n\u003Cul>\n\u003Cli>System automatically retries failed requests\u003C/li>\n\u003Cli>Check network stability\u003C/li>\n\u003C/ul>\n\u003C/li>\n\u003Cli>\n\u003Cp>\u003Cstrong>Test Connectivity\u003C/strong>\u003C/p>\n\u003Cpre class=\"astro-code github-dark\" style=\"background-color:#24292e;color:#e1e4e8; overflow-x: auto;\" tabindex=\"0\" data-language=\"bash\">\u003Ccode>\u003Cspan class=\"line\">\u003Cspan style=\"color:#6A737D\"># Test basic connectivity to each provider\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#B392F0\">curl\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> https://api.openai.com/v1/models\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#B392F0\">curl\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> https://api.elevenlabs.io/v1/voices\u003C/span>\u003C/span>\u003C/code>\u003C/pre>\n\u003C/li>\n\u003Cli>\n\u003Cp>\u003Cstrong>Configure Timeouts\u003C/strong>\u003C/p>\n\u003Cul>\n\u003Cli>Network issues are handled automatically\u003C/li>\n\u003Cli>Consider VPN if regional restrictions apply\u003C/li>\n\u003C/ul>\n\u003C/li>\n\u003C/ol>\n\u003Cp>\u003Cstrong>Prevention\u003C/strong>:\u003C/p>\n\u003Cul>\n\u003Cli>Stable internet connection\u003C/li>\n\u003Cli>Use \u003Ccode>--populate-cache\u003C/code> run mode to ensure all files downloaded before generation\u003C/li>\n\u003Cli>Use local cache when possible\u003C/li>\n\u003C/ul>\n\u003Ch3 id=\"11-llm-voice-casting-issues\">11. LLM Voice Casting Issues\u003C/h3>\n\u003Cp>\u003Cstrong>Problem\u003C/strong>: Issues with LLM-assisted voice casting workflow.\u003C/p>\n\u003Cp>\u003Cstrong>Symptoms\u003C/strong>:\u003C/p>\n\u003Cul>\n\u003Cli>LLM returns invalid YAML\u003C/li>\n\u003Cli>Missing speakers in LLM output\u003C/li>\n\u003Cli>Configuration validation errors\u003C/li>\n\u003Cli>Voice library IDs not recognized\u003C/li>\n\u003C/ul>\n\u003Cp>\u003Cstrong>Solutions\u003C/strong>:\u003C/p>\n\u003Ch4 id=\"for-character-notes-generation\">For Character Notes Generation:\u003C/h4>\n\u003Col>\n\u003Cli>\n\u003Cp>\u003Cstrong>Try a different LLM\u003C/strong>\u003C/p>\n\u003Cul>\n\u003Cli>Certain LLM providers / models struggle with the task of adding .yaml comments while leaving the rest of the structure intact\u003C/li>\n\u003Cli>Claude Sonnet and Gemini Pro seem to work well\u003C/li>\n\u003C/ul>\n\u003C/li>\n\u003Cli>\n\u003Cp>\u003Cstrong>Generate Proper Casting Prompt\u003C/strong>\u003C/p>\n\u003Cpre class=\"astro-code github-dark\" style=\"background-color:#24292e;color:#e1e4e8; overflow-x: auto;\" tabindex=\"0\" data-language=\"bash\">\u003Ccode>\u003Cspan class=\"line\">\u003Cspan style=\"color:#6A737D\"># Ensure prompt includes current configuration\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#B392F0\">uv\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> run\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> sts-generate-character-notes-prompt\u003C/span>\u003Cspan style=\"color:#79B8FF\"> \\\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#9ECBFF\">  source_screenplays/script.pdf\u003C/span>\u003Cspan style=\"color:#79B8FF\"> \\\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#9ECBFF\">  input/script/script_voice_config.yaml\u003C/span>\u003C/span>\u003C/code>\u003C/pre>\n\u003C/li>\n\u003Cli>\n\u003Cp>\u003Cstrong>Validate LLM Output\u003C/strong>\u003C/p>\n\u003Cpre class=\"astro-code github-dark\" style=\"background-color:#24292e;color:#e1e4e8; overflow-x: auto;\" tabindex=\"0\" data-language=\"bash\">\u003Ccode>\u003Cspan class=\"line\">\u003Cspan style=\"color:#6A737D\"># Check for structural issues\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#B392F0\">uv\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> run\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> sts-tts-provider-yaml\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> validate\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> input/script/script.json\u003C/span>\u003Cspan style=\"color:#79B8FF\"> \\\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#9ECBFF\">  input/script/script_voice_config.yaml\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#6A737D\"># Strict validation for provider fields\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#B392F0\">uv\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> run\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> sts-tts-provider-yaml\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> validate\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> input/script/script.json\u003C/span>\u003Cspan style=\"color:#79B8FF\"> \\\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#9ECBFF\">  input/script/script_voice_config.yaml\u003C/span>\u003Cspan style=\"color:#79B8FF\"> --strict\u003C/span>\u003C/span>\u003C/code>\u003C/pre>\n\u003C/li>\n\u003C/ol>\n\u003Ch4 id=\"for-voice-library-casting\">For Voice Library Casting:\u003C/h4>\n\u003Col>\n\u003Cli>\n\u003Cp>\u003Cstrong>Ensure Character Notes Exist\u003C/strong>\u003C/p>\n\u003Cul>\n\u003Cli>Voice library casting works best when character descriptions are present as YAML comments\u003C/li>\n\u003Cli>Either use character notes generation first, or manually add notes\u003C/li>\n\u003C/ul>\n\u003C/li>\n\u003Cli>\n\u003Cp>\u003Cstrong>Generate Voice Library Casting Prompt\u003C/strong>\u003C/p>\n\u003Cpre class=\"astro-code github-dark\" style=\"background-color:#24292e;color:#e1e4e8; overflow-x: auto;\" tabindex=\"0\" data-language=\"bash\">\u003Ccode>\u003Cspan class=\"line\">\u003Cspan style=\"color:#6A737D\"># Include all providers you want to cast from\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#B392F0\">uv\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> run\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> sts-generate-voice-library-casting-prompt\u003C/span>\u003Cspan style=\"color:#79B8FF\"> \\\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#9ECBFF\">  input/script/script_voice_config.yaml\u003C/span>\u003Cspan style=\"color:#79B8FF\"> \\\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#9ECBFF\">  openai\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> elevenlabs\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> cartesia\u003C/span>\u003C/span>\u003C/code>\u003C/pre>\n\u003C/li>\n\u003Cli>\n\u003Cp>\u003Cstrong>Validate Voice Library IDs\u003C/strong>\u003C/p>\n\u003Cul>\n\u003Cli>LLM must use valid \u003Ccode>sts_id\u003C/code> values from the voice libraries\u003C/li>\n\u003Cli>Check that returned IDs exist in the provider’s voice library\u003C/li>\n\u003Cli>Use \u003Ccode>--strict\u003C/code> validation to catch invalid voice configurations\u003C/li>\n\u003C/ul>\n\u003C/li>\n\u003Cli>\n\u003Cp>\u003Cstrong>Common Voice Library Casting Issues\u003C/strong>\u003C/p>\n\u003Cul>\n\u003Cli>Invalid sts_id: LLM may invent voice IDs not in the library\u003C/li>\n\u003Cli>Missing sts_id: LLM may forget to add the sts_id field\u003C/li>\n\u003Cli>Wrong provider: LLM may assign voices from wrong provider’s library\u003C/li>\n\u003Cli>Overwriting config: LLM may remove existing provider-specific fields\u003C/li>\n\u003C/ul>\n\u003C/li>\n\u003C/ol>\n\u003Cp>\u003Cstrong>Prevention\u003C/strong>:\u003C/p>\n\u003Cul>\n\u003Cli>Use the two-step workflow: character notes first, then voice library casting\u003C/li>\n\u003Cli>For privacy-conscious workflows, manually add character notes instead of using LLM\u003C/li>\n\u003Cli>Always validate configuration before proceeding with audio generation\u003C/li>\n\u003Cli>Keep backup of working configurations\u003C/li>\n\u003Cli>Try a reasoning LLM model if voice casting is producing incorrect / sub-par results\u003C/li>\n\u003C/ul>\n\u003Ch2 id=\"debugging-tools\">Debugging Tools\u003C/h2>\n\u003Ch3 id=\"command-line-tools\">Command Line Tools\u003C/h3>\n\u003Col>\n\u003Cli>\n\u003Cp>\u003Cstrong>Standalone Speech Testing\u003C/strong>\u003C/p>\n\u003Cpre class=\"astro-code github-dark\" style=\"background-color:#24292e;color:#e1e4e8; overflow-x: auto;\" tabindex=\"0\" data-language=\"bash\">\u003Ccode>\u003Cspan class=\"line\">\u003Cspan style=\"color:#6A737D\"># Test individual voice configurations\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#B392F0\">uv\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> run\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> sts-generate-standalone-speech\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> openai\u003C/span>\u003Cspan style=\"color:#79B8FF\"> --voice\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> echo\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> \"Test text\"\u003C/span>\u003C/span>\u003C/code>\u003C/pre>\n\u003C/li>\n\u003Cli>\n\u003Cp>\u003Cstrong>Dry Run Validation\u003C/strong>\u003C/p>\n\u003Cpre class=\"astro-code github-dark\" style=\"background-color:#24292e;color:#e1e4e8; overflow-x: auto;\" tabindex=\"0\" data-language=\"bash\">\u003Ccode>\u003Cspan class=\"line\">\u003Cspan style=\"color:#6A737D\"># Validate configuration without generation\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#B392F0\">uv\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> run\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> sts-generate-audio\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> script.json\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> config.yaml\u003C/span>\u003Cspan style=\"color:#79B8FF\"> --dry-run\u003C/span>\u003C/span>\u003C/code>\u003C/pre>\n\u003C/li>\n\u003Cli>\n\u003Cp>\u003Cstrong>Configuration Validation\u003C/strong>\u003C/p>\n\u003Cpre class=\"astro-code github-dark\" style=\"background-color:#24292e;color:#e1e4e8; overflow-x: auto;\" tabindex=\"0\" data-language=\"bash\">\u003Ccode>\u003Cspan class=\"line\">\u003Cspan style=\"color:#6A737D\"># Check voice configuration against script\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#B392F0\">uv\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> run\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> sts-tts-provider-yaml\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> validate\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> script.json\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> config.yaml\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#6A737D\"># Strict validation including provider fields\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#B392F0\">uv\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> run\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> sts-tts-provider-yaml\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> validate\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> script.json\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> config.yaml\u003C/span>\u003Cspan style=\"color:#79B8FF\"> --strict\u003C/span>\u003C/span>\u003C/code>\u003C/pre>\n\u003C/li>\n\u003Cli>\n\u003Cp>\u003Cstrong>Processor Testing\u003C/strong>\u003C/p>\n\u003Cpre class=\"astro-code github-dark\" style=\"background-color:#24292e;color:#e1e4e8; overflow-x: auto;\" tabindex=\"0\" data-language=\"bash\">\u003Ccode>\u003Cspan class=\"line\">\u003Cspan style=\"color:#6A737D\"># Test text processors independently\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#B392F0\">uv\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> run\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> sts-apply-text-processors-json\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> script.json\u003C/span>\u003Cspan style=\"color:#79B8FF\"> \\\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#79B8FF\">  --text-processor-configs\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> test_config.yaml\u003C/span>\u003Cspan style=\"color:#79B8FF\"> \\\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#79B8FF\">  --output-path\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> debug_output.json\u003C/span>\u003C/span>\u003C/code>\u003C/pre>\n\u003C/li>\n\u003Cli>\n\u003Cp>\u003Cstrong>Parser Regression Testing\u003C/strong>\u003C/p>\n\u003Cpre class=\"astro-code github-dark\" style=\"background-color:#24292e;color:#e1e4e8; overflow-x: auto;\" tabindex=\"0\" data-language=\"bash\">\u003Ccode>\u003Cspan class=\"line\">\u003Cspan style=\"color:#6A737D\"># When making changes to the parser, show differences in output between\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#6A737D\"># parser version used to originally generate script.json and current parser logic\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#B392F0\">uv\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> run\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> sts-parse-regression-check-json\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> script.json\u003C/span>\u003C/span>\u003C/code>\u003C/pre>\n\u003C/li>\n\u003Cli>\n\u003Cp>\u003Cstrong>Voice Casting Utilities\u003C/strong>\u003C/p>\n\u003Cpre class=\"astro-code github-dark\" style=\"background-color:#24292e;color:#e1e4e8; overflow-x: auto;\" tabindex=\"0\" data-language=\"bash\">\u003Ccode>\u003Cspan class=\"line\">\u003Cspan style=\"color:#6A737D\"># Generate LLM prompt for voice casting\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#B392F0\">uv\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> run\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> sts-generate-character-notes-prompt\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> script.pdf\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> config.yaml\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#6A737D\"># Copy any file to clipboard\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#B392F0\">uv\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> run\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> sts-copy-to-clipboard\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> file.txt\u003C/span>\u003C/span>\u003C/code>\u003C/pre>\n\u003C/li>\n\u003C/ol>\n\u003Ch3 id=\"log-analysis\">Log Analysis\u003C/h3>\n\u003Col>\n\u003Cli>\n\u003Cp>\u003Cstrong>Check Detailed Logs\u003C/strong>\u003C/p>\n\u003Cpre class=\"astro-code github-dark\" style=\"background-color:#24292e;color:#e1e4e8; overflow-x: auto;\" tabindex=\"0\" data-language=\"bash\">\u003Ccode>\u003Cspan class=\"line\">\u003Cspan style=\"color:#6A737D\"># View recent logs\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#B392F0\">tail\u003C/span>\u003Cspan style=\"color:#79B8FF\"> -f\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> output/[script]/logs/[run\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> mode]_log_YYYYMMDD_HHMMSS.txt\u003C/span>\u003C/span>\u003C/code>\u003C/pre>\n\u003C/li>\n\u003Cli>\n\u003Cp>\u003Cstrong>Filter Errors\u003C/strong>\u003C/p>\n\u003Cpre class=\"astro-code github-dark\" style=\"background-color:#24292e;color:#e1e4e8; overflow-x: auto;\" tabindex=\"0\" data-language=\"bash\">\u003Ccode>\u003Cspan class=\"line\">\u003Cspan style=\"color:#6A737D\"># Find errors in logs\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#B392F0\">grep\u003C/span>\u003Cspan style=\"color:#79B8FF\"> -i\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> error\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> output/[script]/logs/[run\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> mode]_log_\u003C/span>\u003Cspan style=\"color:#79B8FF\">*\u003C/span>\u003Cspan style=\"color:#9ECBFF\">.txt\u003C/span>\u003C/span>\n\u003Cspan class=\"line\">\u003Cspan style=\"color:#B392F0\">grep\u003C/span>\u003Cspan style=\"color:#79B8FF\"> -i\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> warning\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> output/[script]/logs/[run\u003C/span>\u003Cspan style=\"color:#9ECBFF\"> mode]_log_\u003C/span>\u003Cspan style=\"color:#79B8FF\">*\u003C/span>\u003Cspan style=\"color:#9ECBFF\">.txt\u003C/span>\u003C/span>\u003C/code>\u003C/pre>\n\u003C/li>\n\u003C/ol>\n\u003Ch2 id=\"getting-help\">Getting Help\u003C/h2>\n\u003Ch3 id=\"information-to-include\">Information to Include\u003C/h3>\n\u003Cp>When reporting issues, include:\u003C/p>\n\u003Col>\n\u003Cli>Full error message\u003C/li>\n\u003Cli>Command used\u003C/li>\n\u003Cli>Log file from output/[script]/logs\u003C/li>\n\u003Cli>Configuration files (tts config, any additional processor configs, dialogue chunk .json)\u003C/li>\n\u003Cli>System information (OS, Python version)\u003C/li>\n\u003Cli>UV version: \u003Ccode>uv --version\u003C/code>\u003C/li>\n\u003C/ol>\n\u003Ch2 id=\"best-practices-for-avoiding-issues\">Best Practices for Avoiding Issues\u003C/h2>\n\u003Col>\n\u003Cli>\n\u003Cp>\u003Cstrong>Incremental Development\u003C/strong>\u003C/p>\n\u003Cul>\n\u003Cli>Test with small scripts first\u003C/li>\n\u003Cli>Build up to full-length projects\u003C/li>\n\u003Cli>Use \u003Ccode>--dry-run\u003C/code> frequently\u003C/li>\n\u003C/ul>\n\u003C/li>\n\u003Cli>\n\u003Cp>\u003Cstrong>Configuration Management\u003C/strong>\u003C/p>\n\u003Cul>\n\u003Cli>Keep backup configurations\u003C/li>\n\u003Cli>Version control YAML files\u003C/li>\n\u003Cli>Document custom changes\u003C/li>\n\u003Cli>Use \u003Ccode>sts-tts-provider-yaml validate\u003C/code> to check configurations\u003C/li>\n\u003C/ul>\n\u003C/li>\n\u003Cli>\n\u003Cp>\u003Cstrong>Resource Management\u003C/strong>\u003C/p>\n\u003Cul>\n\u003Cli>Monitor disk space\u003C/li>\n\u003Cli>Use appropriate batch sizes\u003C/li>\n\u003Cli>Clean up old files regularly\u003C/li>\n\u003C/ul>\n\u003C/li>\n\u003Cli>\n\u003Cp>\u003Cstrong>Quality Assurance\u003C/strong>\u003C/p>\n\u003Cul>\n\u003Cli>Validate dialogue .json with \u003Ccode>sts-analyze-json\u003C/code>\u003C/li>\n\u003Cli>Use \u003Ccode>--populate-cache\u003C/code> during audio generation to ensure all files downloaded without issue\u003C/li>\n\u003Cli>Use \u003Ccode>--check-silence\u003C/code> during audio generation\u003C/li>\n\u003Cli>Use \u003Ccode>sts-generate-standalone-speech\u003C/code> to test new voices and TTS providers\u003C/li>\n\u003Cli>Validate voice configurations with \u003Ccode>sts-tts-provider-yaml validate\u003C/code>\u003C/li>\n\u003C/ul>\n\u003C/li>\n\u003Cli>\n\u003Cp>\u003Cstrong>Error Prevention\u003C/strong>\u003C/p>\n\u003Cul>\n\u003Cli>Set up API keys properly\u003C/li>\n\u003Cli>Follow naming conventions\u003C/li>\n\u003Cli>Use provided templates\u003C/li>\n\u003Cli>Validate configurations before audio generation\u003C/li>\n\u003C/ul>\n\u003C/li>\n\u003Cli>\n\u003Cp>\u003Cstrong>LLM-Assisted Workflows\u003C/strong>\u003C/p>\n\u003Cul>\n\u003Cli>Use \u003Ccode>sts-generate-character-notes-prompt\u003C/code> for consistent prompts\u003C/li>\n\u003Cli>Always validate LLM output with \u003Ccode>sts-tts-provider-yaml validate\u003C/code>\u003C/li>\n\u003Cli>Keep backup configurations before making LLM-suggested changes\u003C/li>\n\u003C/ul>\n\u003C/li>\n\u003C/ol>",{"headings":448,"localImagePaths":510,"remoteImagePaths":511,"frontmatter":512,"imagePaths":513},[449,452,453,456,459,462,465,468,471,474,477,480,483,486,489,492,495,498,501,504,507],{"depth":22,"slug":450,"text":451},"troubleshooting-guide","Troubleshooting Guide",{"depth":26,"slug":294,"text":295},{"depth":30,"slug":454,"text":455},"1-silent-audio-detection","1. Silent Audio Detection",{"depth":30,"slug":457,"text":458},"2-rate-limiting","2. Rate Limiting",{"depth":30,"slug":460,"text":461},"3-api-key-issues","3. API Key Issues",{"depth":30,"slug":463,"text":464},"4-voice-configuration-errors","4. Voice Configuration Errors",{"depth":30,"slug":466,"text":467},"5-memory-and-disk-space-issues","5. Memory and Disk Space Issues",{"depth":30,"slug":469,"text":470},"6-text-processor-configuration-issues","6. Text Processor Configuration Issues",{"depth":30,"slug":472,"text":473},"7-cache-related-issues","7. Cache-Related Issues",{"depth":30,"slug":475,"text":476},"8-elevenlabs-specific-issues","8. ElevenLabs-Specific Issues",{"depth":30,"slug":478,"text":479},"9-parser-issues","9. Parser Issues",{"depth":30,"slug":481,"text":482},"10-network-connectivity-issues","10. Network Connectivity Issues",{"depth":30,"slug":484,"text":485},"11-llm-voice-casting-issues","11. LLM Voice Casting Issues",{"depth":259,"slug":487,"text":488},"for-character-notes-generation","For Character Notes Generation:",{"depth":259,"slug":490,"text":491},"for-voice-library-casting","For Voice Library Casting:",{"depth":26,"slug":493,"text":494},"debugging-tools","Debugging Tools",{"depth":30,"slug":496,"text":497},"command-line-tools","Command Line Tools",{"depth":30,"slug":499,"text":500},"log-analysis","Log Analysis",{"depth":26,"slug":502,"text":503},"getting-help","Getting Help",{"depth":30,"slug":505,"text":506},"information-to-include","Information to Include",{"depth":26,"slug":508,"text":509},"best-practices-for-avoiding-issues","Best Practices for Avoiding Issues",[],[],{},[],"troubleshooting.md"]